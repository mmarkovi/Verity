{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../preprocessing/') #need this in order to get to the other file in other directory\n",
    "\n",
    "#can comment out the ones you aren't using to save a little bit of time\n",
    "from covidPreprocess import getCoronaVocabulary, getCoronaText\n",
    "from liarPreprocess import getLiarVocabulary, getLiarText\n",
    "from fnnPreprocess import getFNNVocabulary, getFNNText\n",
    "# from fnnCovidCombinedPreprocess import getFNNCoronaVocabulary, getFNNCoronaText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNeuralNet(nn.Module):\n",
    "    # Simple Feed Forward Neural Network with One Hidden Layer that Outputs One Neuron (Binary Classification, can't handle more than 2 classes)\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        #Written based off of the tutorial at\n",
    "        #https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/01-basics/feedforward_neural_network/main.py#L37-L49\n",
    "        self.hidden1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()   \n",
    "        self.oupt = nn.Linear(hidden_size, 1)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.tanh(self.hidden1(x))\n",
    "        out = torch.sigmoid(self.oupt(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndTestSimpleModel(dataset: str, num_epochs = 5, learning_rate = 0.001, print_epoch_mod = 5):\n",
    "    '''\n",
    "    Used this article for help in writing the tensor parts of code so it works with the model\n",
    "    https://medium.com/analytics-vidhya/part-1-sentiment-analysis-in-pytorch-82b35edb40b8\n",
    "    \n",
    "    Train and tests, calculates both training and test accuracy, models that use SimpleNeuralNet.\n",
    "    '''\n",
    "    torch.manual_seed(1)\n",
    "    if dataset == 'corona':\n",
    "        X,Y = getCoronaText() #this function will give us the text array (not document term matrix) and Y\n",
    "        X_train,Y_train, vectorizer_train = getCoronaVocabulary(True)\n",
    "    elif dataset == 'liar':\n",
    "        X,Y = getLiarText()\n",
    "        X_train,Y_train, vectorizer_train = getLiarVocabulary(True)\n",
    "    elif dataset == 'fnn':\n",
    "        X,Y = getFNNText()\n",
    "        X_train,Y_train, vectorizer_train = getFNNVocabulary(True)\n",
    "    \n",
    "    #transform our testing dataset to match the vocabulary for the training dataset\n",
    "    #transform will return the document-term matrix for X based on training dataset\n",
    "    x_test = vectorizer_train.transform(X)\n",
    "    \n",
    "    vocabsize = X_train.shape[1]\n",
    "    \n",
    "    \n",
    "    #transform our training and test data into tensors for the classifier to learn off of\n",
    "    X_tensor = torch.from_numpy(X_train.todense()).float()\n",
    "    Y_tensor = torch.from_numpy(np.array(Y_train)).float()\n",
    "    \n",
    "    X_test_tensor = torch.from_numpy(x_test.todense()).float()\n",
    "    Y_test_tensor = torch.from_numpy(np.array(Y))\n",
    "    \n",
    "    device = torch.device('cpu')\n",
    "    #use TensorDataset to be able to use our DataLoader\n",
    "    train_data = torch.utils.data.TensorDataset(X_tensor, Y_tensor)\n",
    "    train_loader = torch.utils.data.DataLoader(train_data,batch_size=16, shuffle=False)\n",
    "    train_loader_batch_size_1 = torch.utils.data.DataLoader(train_data,batch_size=1, shuffle=False)\n",
    "    \n",
    "    test_data = torch.utils.data.TensorDataset(X_test_tensor, Y_test_tensor)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data,batch_size=1, shuffle=False)\n",
    "    \n",
    "    #initialize our model\n",
    "    model = SimpleNeuralNet(vocabsize, 200).to(device)\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "    \n",
    "    \n",
    "    total_step = len(train_loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (x_batch, labels) in enumerate(train_loader):\n",
    "    \n",
    "            # Forward pass\n",
    "            # The forward process computes the loss of each iteration on each sample\n",
    "            model.train()\n",
    "            y_pred = model(x_batch)\n",
    "            loss = loss_fn(y_pred, labels.reshape(-1, 1))\n",
    "    \n",
    "            # Backward pass, using the optimizer to update the parameters\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()    #compute gradients\n",
    "            optimizer.step()   #initiate gradient descent\n",
    "    \n",
    "     \n",
    "            # Below, an epoch corresponds to one pass through all of the samples.\n",
    "            # Each training step corresponds to a parameter update using \n",
    "            # a gradient computed on a minibatch of 100 samples \n",
    "            if (i + 1) % print_epoch_mod == 0: \n",
    "                #leaving it on 5 for corona dataset, probably want to change to % 50 or % 100\n",
    "                # for the other datasets so don't get spammed \n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "    \n",
    "    # Test the model\n",
    "    # In the test phase, we don't need to compute gradients (the model has already been learned)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, label in test_loader:\n",
    "            output = model(inputs)\n",
    "            total += 1\n",
    "            if label >= 0.5 and output >= 0.5:\n",
    "                correct += 1\n",
    "            elif label < 0.5 and output < 0.5:\n",
    "                correct += 1\n",
    "            \n",
    "        print('Test accuracy of the network: {} %'.format(100 * correct / total))\n",
    "        test_accuracy = 100 * correct / total\n",
    "        \n",
    "    # Print out training accuracy\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, label in train_loader_batch_size_1:\n",
    "            output = model(inputs)\n",
    "            total += 1\n",
    "            if label >= 0.5 and output >= 0.5:\n",
    "                correct += 1\n",
    "            elif label < 0.5 and output < 0.5:\n",
    "                correct += 1\n",
    "                \n",
    "        print('Train accuracy of the network: {} %'.format(100 * correct / total))\n",
    "        train_accuracy = 100 * correct / total\n",
    "    \n",
    "    return test_accuracy, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [5/19], Loss: 0.3543\n",
      "Epoch [1/50], Step [10/19], Loss: 0.5111\n",
      "Epoch [1/50], Step [15/19], Loss: 0.2169\n",
      "Epoch [2/50], Step [5/19], Loss: 0.0395\n",
      "Epoch [2/50], Step [10/19], Loss: 0.1832\n",
      "Epoch [2/50], Step [15/19], Loss: 0.0935\n",
      "Epoch [3/50], Step [5/19], Loss: 0.0094\n",
      "Epoch [3/50], Step [10/19], Loss: 0.0684\n",
      "Epoch [3/50], Step [15/19], Loss: 0.0311\n",
      "Epoch [4/50], Step [5/19], Loss: 0.0038\n",
      "Epoch [4/50], Step [10/19], Loss: 0.0362\n",
      "Epoch [4/50], Step [15/19], Loss: 0.0157\n",
      "Epoch [5/50], Step [5/19], Loss: 0.0021\n",
      "Epoch [5/50], Step [10/19], Loss: 0.0217\n",
      "Epoch [5/50], Step [15/19], Loss: 0.0092\n",
      "Epoch [6/50], Step [5/19], Loss: 0.0013\n",
      "Epoch [6/50], Step [10/19], Loss: 0.0140\n",
      "Epoch [6/50], Step [15/19], Loss: 0.0059\n",
      "Epoch [7/50], Step [5/19], Loss: 0.0009\n",
      "Epoch [7/50], Step [10/19], Loss: 0.0097\n",
      "Epoch [7/50], Step [15/19], Loss: 0.0041\n",
      "Epoch [8/50], Step [5/19], Loss: 0.0007\n",
      "Epoch [8/50], Step [10/19], Loss: 0.0071\n",
      "Epoch [8/50], Step [15/19], Loss: 0.0030\n",
      "Epoch [9/50], Step [5/19], Loss: 0.0005\n",
      "Epoch [9/50], Step [10/19], Loss: 0.0054\n",
      "Epoch [9/50], Step [15/19], Loss: 0.0023\n",
      "Epoch [10/50], Step [5/19], Loss: 0.0004\n",
      "Epoch [10/50], Step [10/19], Loss: 0.0042\n",
      "Epoch [10/50], Step [15/19], Loss: 0.0018\n",
      "Epoch [11/50], Step [5/19], Loss: 0.0003\n",
      "Epoch [11/50], Step [10/19], Loss: 0.0034\n",
      "Epoch [11/50], Step [15/19], Loss: 0.0015\n",
      "Epoch [12/50], Step [5/19], Loss: 0.0003\n",
      "Epoch [12/50], Step [10/19], Loss: 0.0028\n",
      "Epoch [12/50], Step [15/19], Loss: 0.0012\n",
      "Epoch [13/50], Step [5/19], Loss: 0.0002\n",
      "Epoch [13/50], Step [10/19], Loss: 0.0024\n",
      "Epoch [13/50], Step [15/19], Loss: 0.0010\n",
      "Epoch [14/50], Step [5/19], Loss: 0.0002\n",
      "Epoch [14/50], Step [10/19], Loss: 0.0020\n",
      "Epoch [14/50], Step [15/19], Loss: 0.0009\n",
      "Epoch [15/50], Step [5/19], Loss: 0.0002\n",
      "Epoch [15/50], Step [10/19], Loss: 0.0017\n",
      "Epoch [15/50], Step [15/19], Loss: 0.0008\n",
      "Epoch [16/50], Step [5/19], Loss: 0.0002\n",
      "Epoch [16/50], Step [10/19], Loss: 0.0015\n",
      "Epoch [16/50], Step [15/19], Loss: 0.0007\n",
      "Epoch [17/50], Step [5/19], Loss: 0.0001\n",
      "Epoch [17/50], Step [10/19], Loss: 0.0013\n",
      "Epoch [17/50], Step [15/19], Loss: 0.0006\n",
      "Epoch [18/50], Step [5/19], Loss: 0.0001\n",
      "Epoch [18/50], Step [10/19], Loss: 0.0012\n",
      "Epoch [18/50], Step [15/19], Loss: 0.0005\n",
      "Epoch [19/50], Step [5/19], Loss: 0.0001\n",
      "Epoch [19/50], Step [10/19], Loss: 0.0011\n",
      "Epoch [19/50], Step [15/19], Loss: 0.0005\n",
      "Epoch [20/50], Step [5/19], Loss: 0.0001\n",
      "Epoch [20/50], Step [10/19], Loss: 0.0010\n",
      "Epoch [20/50], Step [15/19], Loss: 0.0004\n",
      "Epoch [21/50], Step [5/19], Loss: 0.0001\n",
      "Epoch [21/50], Step [10/19], Loss: 0.0009\n",
      "Epoch [21/50], Step [15/19], Loss: 0.0004\n",
      "Epoch [22/50], Step [5/19], Loss: 0.0001\n",
      "Epoch [22/50], Step [10/19], Loss: 0.0008\n",
      "Epoch [22/50], Step [15/19], Loss: 0.0004\n",
      "Epoch [23/50], Step [5/19], Loss: 0.0001\n",
      "Epoch [23/50], Step [10/19], Loss: 0.0007\n",
      "Epoch [23/50], Step [15/19], Loss: 0.0003\n",
      "Epoch [24/50], Step [5/19], Loss: 0.0001\n",
      "Epoch [24/50], Step [10/19], Loss: 0.0007\n",
      "Epoch [24/50], Step [15/19], Loss: 0.0003\n",
      "Epoch [25/50], Step [5/19], Loss: 0.0001\n",
      "Epoch [25/50], Step [10/19], Loss: 0.0006\n",
      "Epoch [25/50], Step [15/19], Loss: 0.0003\n",
      "Epoch [26/50], Step [5/19], Loss: 0.0001\n",
      "Epoch [26/50], Step [10/19], Loss: 0.0006\n",
      "Epoch [26/50], Step [15/19], Loss: 0.0003\n",
      "Epoch [27/50], Step [5/19], Loss: 0.0001\n",
      "Epoch [27/50], Step [10/19], Loss: 0.0005\n",
      "Epoch [27/50], Step [15/19], Loss: 0.0002\n",
      "Epoch [28/50], Step [5/19], Loss: 0.0001\n",
      "Epoch [28/50], Step [10/19], Loss: 0.0005\n",
      "Epoch [28/50], Step [15/19], Loss: 0.0002\n",
      "Epoch [29/50], Step [5/19], Loss: 0.0001\n",
      "Epoch [29/50], Step [10/19], Loss: 0.0005\n",
      "Epoch [29/50], Step [15/19], Loss: 0.0002\n",
      "Epoch [30/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [30/50], Step [10/19], Loss: 0.0004\n",
      "Epoch [30/50], Step [15/19], Loss: 0.0002\n",
      "Epoch [31/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [31/50], Step [10/19], Loss: 0.0004\n",
      "Epoch [31/50], Step [15/19], Loss: 0.0002\n",
      "Epoch [32/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [32/50], Step [10/19], Loss: 0.0004\n",
      "Epoch [32/50], Step [15/19], Loss: 0.0002\n",
      "Epoch [33/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [33/50], Step [10/19], Loss: 0.0004\n",
      "Epoch [33/50], Step [15/19], Loss: 0.0002\n",
      "Epoch [34/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [34/50], Step [10/19], Loss: 0.0003\n",
      "Epoch [34/50], Step [15/19], Loss: 0.0002\n",
      "Epoch [35/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [35/50], Step [10/19], Loss: 0.0003\n",
      "Epoch [35/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [36/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [36/50], Step [10/19], Loss: 0.0003\n",
      "Epoch [36/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [37/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [37/50], Step [10/19], Loss: 0.0003\n",
      "Epoch [37/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [38/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [38/50], Step [10/19], Loss: 0.0003\n",
      "Epoch [38/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [39/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [39/50], Step [10/19], Loss: 0.0003\n",
      "Epoch [39/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [40/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [40/50], Step [10/19], Loss: 0.0002\n",
      "Epoch [40/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [41/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [41/50], Step [10/19], Loss: 0.0002\n",
      "Epoch [41/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [42/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [42/50], Step [10/19], Loss: 0.0002\n",
      "Epoch [42/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [43/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [43/50], Step [10/19], Loss: 0.0002\n",
      "Epoch [43/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [44/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [44/50], Step [10/19], Loss: 0.0002\n",
      "Epoch [44/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [45/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [45/50], Step [10/19], Loss: 0.0002\n",
      "Epoch [45/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [46/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [46/50], Step [10/19], Loss: 0.0002\n",
      "Epoch [46/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [47/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [47/50], Step [10/19], Loss: 0.0002\n",
      "Epoch [47/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [48/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [48/50], Step [10/19], Loss: 0.0002\n",
      "Epoch [48/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [49/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [49/50], Step [10/19], Loss: 0.0002\n",
      "Epoch [49/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [50/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [50/50], Step [10/19], Loss: 0.0002\n",
      "Epoch [50/50], Step [15/19], Loss: 0.0001\n",
      "Test accuracy of the network: 90.14891179839634 %\n",
      "Train accuracy of the network: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "test_accuracy, train_accuracy, model, vectorizer_train = trainAndTestSimpleModel('corona', num_epochs=50)\n",
    "torch.save(model, 'covid_saved_model')\n",
    "pickle.dump(vectorizer_train, open('covid_vec.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs_used = [1, 5, 10, 20, 30, 40, 50, 60, 75, 100]\n",
    "corona_test_accuracies = []\n",
    "corona_train_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [5/19], Loss: 0.3543\n",
      "Epoch [1/1], Step [10/19], Loss: 0.5111\n",
      "Epoch [1/1], Step [15/19], Loss: 0.2169\n",
      "Test accuracy of the network: 86.71248568155785 %\n",
      "Train accuracy of the network: 97.2508591065292 %\n",
      "Epoch [1/5], Step [5/19], Loss: 0.3543\n",
      "Epoch [1/5], Step [10/19], Loss: 0.5111\n",
      "Epoch [1/5], Step [15/19], Loss: 0.2169\n",
      "Epoch [2/5], Step [5/19], Loss: 0.0395\n",
      "Epoch [2/5], Step [10/19], Loss: 0.1832\n",
      "Epoch [2/5], Step [15/19], Loss: 0.0935\n",
      "Epoch [3/5], Step [5/19], Loss: 0.0094\n",
      "Epoch [3/5], Step [10/19], Loss: 0.0684\n",
      "Epoch [3/5], Step [15/19], Loss: 0.0311\n",
      "Epoch [4/5], Step [5/19], Loss: 0.0038\n",
      "Epoch [4/5], Step [10/19], Loss: 0.0362\n",
      "Epoch [4/5], Step [15/19], Loss: 0.0157\n",
      "Epoch [5/5], Step [5/19], Loss: 0.0021\n",
      "Epoch [5/5], Step [10/19], Loss: 0.0217\n",
      "Epoch [5/5], Step [15/19], Loss: 0.0092\n",
      "Test accuracy of the network: 88.77434135166094 %\n",
      "Train accuracy of the network: 100.0 %\n",
      "Epoch [1/10], Step [5/19], Loss: 0.3543\n",
      "Epoch [1/10], Step [10/19], Loss: 0.5111\n",
      "Epoch [1/10], Step [15/19], Loss: 0.2169\n",
      "Epoch [2/10], Step [5/19], Loss: 0.0395\n",
      "Epoch [2/10], Step [10/19], Loss: 0.1832\n",
      "Epoch [2/10], Step [15/19], Loss: 0.0935\n",
      "Epoch [3/10], Step [5/19], Loss: 0.0094\n",
      "Epoch [3/10], Step [10/19], Loss: 0.0684\n",
      "Epoch [3/10], Step [15/19], Loss: 0.0311\n",
      "Epoch [4/10], Step [5/19], Loss: 0.0038\n",
      "Epoch [4/10], Step [10/19], Loss: 0.0362\n",
      "Epoch [4/10], Step [15/19], Loss: 0.0157\n",
      "Epoch [5/10], Step [5/19], Loss: 0.0021\n",
      "Epoch [5/10], Step [10/19], Loss: 0.0217\n",
      "Epoch [5/10], Step [15/19], Loss: 0.0092\n",
      "Epoch [6/10], Step [5/19], Loss: 0.0013\n",
      "Epoch [6/10], Step [10/19], Loss: 0.0140\n",
      "Epoch [6/10], Step [15/19], Loss: 0.0059\n",
      "Epoch [7/10], Step [5/19], Loss: 0.0009\n",
      "Epoch [7/10], Step [10/19], Loss: 0.0097\n",
      "Epoch [7/10], Step [15/19], Loss: 0.0041\n",
      "Epoch [8/10], Step [5/19], Loss: 0.0007\n",
      "Epoch [8/10], Step [10/19], Loss: 0.0071\n",
      "Epoch [8/10], Step [15/19], Loss: 0.0030\n",
      "Epoch [9/10], Step [5/19], Loss: 0.0005\n",
      "Epoch [9/10], Step [10/19], Loss: 0.0054\n",
      "Epoch [9/10], Step [15/19], Loss: 0.0023\n",
      "Epoch [10/10], Step [5/19], Loss: 0.0004\n",
      "Epoch [10/10], Step [10/19], Loss: 0.0042\n",
      "Epoch [10/10], Step [15/19], Loss: 0.0018\n",
      "Test accuracy of the network: 89.57617411225658 %\n",
      "Train accuracy of the network: 100.0 %\n",
      "Epoch [1/20], Step [5/19], Loss: 0.3543\n",
      "Epoch [1/20], Step [10/19], Loss: 0.5111\n",
      "Epoch [1/20], Step [15/19], Loss: 0.2169\n",
      "Epoch [2/20], Step [5/19], Loss: 0.0395\n",
      "Epoch [2/20], Step [10/19], Loss: 0.1832\n",
      "Epoch [2/20], Step [15/19], Loss: 0.0935\n",
      "Epoch [3/20], Step [5/19], Loss: 0.0094\n",
      "Epoch [3/20], Step [10/19], Loss: 0.0684\n",
      "Epoch [3/20], Step [15/19], Loss: 0.0311\n",
      "Epoch [4/20], Step [5/19], Loss: 0.0038\n",
      "Epoch [4/20], Step [10/19], Loss: 0.0362\n",
      "Epoch [4/20], Step [15/19], Loss: 0.0157\n",
      "Epoch [5/20], Step [5/19], Loss: 0.0021\n",
      "Epoch [5/20], Step [10/19], Loss: 0.0217\n",
      "Epoch [5/20], Step [15/19], Loss: 0.0092\n",
      "Epoch [6/20], Step [5/19], Loss: 0.0013\n",
      "Epoch [6/20], Step [10/19], Loss: 0.0140\n",
      "Epoch [6/20], Step [15/19], Loss: 0.0059\n",
      "Epoch [7/20], Step [5/19], Loss: 0.0009\n",
      "Epoch [7/20], Step [10/19], Loss: 0.0097\n",
      "Epoch [7/20], Step [15/19], Loss: 0.0041\n",
      "Epoch [8/20], Step [5/19], Loss: 0.0007\n",
      "Epoch [8/20], Step [10/19], Loss: 0.0071\n",
      "Epoch [8/20], Step [15/19], Loss: 0.0030\n",
      "Epoch [9/20], Step [5/19], Loss: 0.0005\n",
      "Epoch [9/20], Step [10/19], Loss: 0.0054\n",
      "Epoch [9/20], Step [15/19], Loss: 0.0023\n",
      "Epoch [10/20], Step [5/19], Loss: 0.0004\n",
      "Epoch [10/20], Step [10/19], Loss: 0.0042\n",
      "Epoch [10/20], Step [15/19], Loss: 0.0018\n",
      "Epoch [11/20], Step [5/19], Loss: 0.0003\n",
      "Epoch [11/20], Step [10/19], Loss: 0.0034\n",
      "Epoch [11/20], Step [15/19], Loss: 0.0015\n",
      "Epoch [12/20], Step [5/19], Loss: 0.0003\n",
      "Epoch [12/20], Step [10/19], Loss: 0.0028\n",
      "Epoch [12/20], Step [15/19], Loss: 0.0012\n",
      "Epoch [13/20], Step [5/19], Loss: 0.0002\n",
      "Epoch [13/20], Step [10/19], Loss: 0.0024\n",
      "Epoch [13/20], Step [15/19], Loss: 0.0010\n",
      "Epoch [14/20], Step [5/19], Loss: 0.0002\n",
      "Epoch [14/20], Step [10/19], Loss: 0.0020\n",
      "Epoch [14/20], Step [15/19], Loss: 0.0009\n",
      "Epoch [15/20], Step [5/19], Loss: 0.0002\n",
      "Epoch [15/20], Step [10/19], Loss: 0.0017\n",
      "Epoch [15/20], Step [15/19], Loss: 0.0008\n",
      "Epoch [16/20], Step [5/19], Loss: 0.0002\n",
      "Epoch [16/20], Step [10/19], Loss: 0.0015\n",
      "Epoch [16/20], Step [15/19], Loss: 0.0007\n",
      "Epoch [17/20], Step [5/19], Loss: 0.0001\n",
      "Epoch [17/20], Step [10/19], Loss: 0.0013\n",
      "Epoch [17/20], Step [15/19], Loss: 0.0006\n",
      "Epoch [18/20], Step [5/19], Loss: 0.0001\n",
      "Epoch [18/20], Step [10/19], Loss: 0.0012\n",
      "Epoch [18/20], Step [15/19], Loss: 0.0005\n",
      "Epoch [19/20], Step [5/19], Loss: 0.0001\n",
      "Epoch [19/20], Step [10/19], Loss: 0.0011\n",
      "Epoch [19/20], Step [15/19], Loss: 0.0005\n",
      "Epoch [20/20], Step [5/19], Loss: 0.0001\n",
      "Epoch [20/20], Step [10/19], Loss: 0.0010\n",
      "Epoch [20/20], Step [15/19], Loss: 0.0004\n",
      "Test accuracy of the network: 89.91981672394043 %\n",
      "Train accuracy of the network: 100.0 %\n",
      "Epoch [1/30], Step [5/19], Loss: 0.3543\n",
      "Epoch [1/30], Step [10/19], Loss: 0.5111\n",
      "Epoch [1/30], Step [15/19], Loss: 0.2169\n",
      "Epoch [2/30], Step [5/19], Loss: 0.0395\n",
      "Epoch [2/30], Step [10/19], Loss: 0.1832\n",
      "Epoch [2/30], Step [15/19], Loss: 0.0935\n",
      "Epoch [3/30], Step [5/19], Loss: 0.0094\n",
      "Epoch [3/30], Step [10/19], Loss: 0.0684\n",
      "Epoch [3/30], Step [15/19], Loss: 0.0311\n",
      "Epoch [4/30], Step [5/19], Loss: 0.0038\n",
      "Epoch [4/30], Step [10/19], Loss: 0.0362\n",
      "Epoch [4/30], Step [15/19], Loss: 0.0157\n",
      "Epoch [5/30], Step [5/19], Loss: 0.0021\n",
      "Epoch [5/30], Step [10/19], Loss: 0.0217\n",
      "Epoch [5/30], Step [15/19], Loss: 0.0092\n",
      "Epoch [6/30], Step [5/19], Loss: 0.0013\n",
      "Epoch [6/30], Step [10/19], Loss: 0.0140\n",
      "Epoch [6/30], Step [15/19], Loss: 0.0059\n",
      "Epoch [7/30], Step [5/19], Loss: 0.0009\n",
      "Epoch [7/30], Step [10/19], Loss: 0.0097\n",
      "Epoch [7/30], Step [15/19], Loss: 0.0041\n",
      "Epoch [8/30], Step [5/19], Loss: 0.0007\n",
      "Epoch [8/30], Step [10/19], Loss: 0.0071\n",
      "Epoch [8/30], Step [15/19], Loss: 0.0030\n",
      "Epoch [9/30], Step [5/19], Loss: 0.0005\n",
      "Epoch [9/30], Step [10/19], Loss: 0.0054\n",
      "Epoch [9/30], Step [15/19], Loss: 0.0023\n",
      "Epoch [10/30], Step [5/19], Loss: 0.0004\n",
      "Epoch [10/30], Step [10/19], Loss: 0.0042\n",
      "Epoch [10/30], Step [15/19], Loss: 0.0018\n",
      "Epoch [11/30], Step [5/19], Loss: 0.0003\n",
      "Epoch [11/30], Step [10/19], Loss: 0.0034\n",
      "Epoch [11/30], Step [15/19], Loss: 0.0015\n",
      "Epoch [12/30], Step [5/19], Loss: 0.0003\n",
      "Epoch [12/30], Step [10/19], Loss: 0.0028\n",
      "Epoch [12/30], Step [15/19], Loss: 0.0012\n",
      "Epoch [13/30], Step [5/19], Loss: 0.0002\n",
      "Epoch [13/30], Step [10/19], Loss: 0.0024\n",
      "Epoch [13/30], Step [15/19], Loss: 0.0010\n",
      "Epoch [14/30], Step [5/19], Loss: 0.0002\n",
      "Epoch [14/30], Step [10/19], Loss: 0.0020\n",
      "Epoch [14/30], Step [15/19], Loss: 0.0009\n",
      "Epoch [15/30], Step [5/19], Loss: 0.0002\n",
      "Epoch [15/30], Step [10/19], Loss: 0.0017\n",
      "Epoch [15/30], Step [15/19], Loss: 0.0008\n",
      "Epoch [16/30], Step [5/19], Loss: 0.0002\n",
      "Epoch [16/30], Step [10/19], Loss: 0.0015\n",
      "Epoch [16/30], Step [15/19], Loss: 0.0007\n",
      "Epoch [17/30], Step [5/19], Loss: 0.0001\n",
      "Epoch [17/30], Step [10/19], Loss: 0.0013\n",
      "Epoch [17/30], Step [15/19], Loss: 0.0006\n",
      "Epoch [18/30], Step [5/19], Loss: 0.0001\n",
      "Epoch [18/30], Step [10/19], Loss: 0.0012\n",
      "Epoch [18/30], Step [15/19], Loss: 0.0005\n",
      "Epoch [19/30], Step [5/19], Loss: 0.0001\n",
      "Epoch [19/30], Step [10/19], Loss: 0.0011\n",
      "Epoch [19/30], Step [15/19], Loss: 0.0005\n",
      "Epoch [20/30], Step [5/19], Loss: 0.0001\n",
      "Epoch [20/30], Step [10/19], Loss: 0.0010\n",
      "Epoch [20/30], Step [15/19], Loss: 0.0004\n",
      "Epoch [21/30], Step [5/19], Loss: 0.0001\n",
      "Epoch [21/30], Step [10/19], Loss: 0.0009\n",
      "Epoch [21/30], Step [15/19], Loss: 0.0004\n",
      "Epoch [22/30], Step [5/19], Loss: 0.0001\n",
      "Epoch [22/30], Step [10/19], Loss: 0.0008\n",
      "Epoch [22/30], Step [15/19], Loss: 0.0004\n",
      "Epoch [23/30], Step [5/19], Loss: 0.0001\n",
      "Epoch [23/30], Step [10/19], Loss: 0.0007\n",
      "Epoch [23/30], Step [15/19], Loss: 0.0003\n",
      "Epoch [24/30], Step [5/19], Loss: 0.0001\n",
      "Epoch [24/30], Step [10/19], Loss: 0.0007\n",
      "Epoch [24/30], Step [15/19], Loss: 0.0003\n",
      "Epoch [25/30], Step [5/19], Loss: 0.0001\n",
      "Epoch [25/30], Step [10/19], Loss: 0.0006\n",
      "Epoch [25/30], Step [15/19], Loss: 0.0003\n",
      "Epoch [26/30], Step [5/19], Loss: 0.0001\n",
      "Epoch [26/30], Step [10/19], Loss: 0.0006\n",
      "Epoch [26/30], Step [15/19], Loss: 0.0003\n",
      "Epoch [27/30], Step [5/19], Loss: 0.0001\n",
      "Epoch [27/30], Step [10/19], Loss: 0.0005\n",
      "Epoch [27/30], Step [15/19], Loss: 0.0002\n",
      "Epoch [28/30], Step [5/19], Loss: 0.0001\n",
      "Epoch [28/30], Step [10/19], Loss: 0.0005\n",
      "Epoch [28/30], Step [15/19], Loss: 0.0002\n",
      "Epoch [29/30], Step [5/19], Loss: 0.0001\n",
      "Epoch [29/30], Step [10/19], Loss: 0.0005\n",
      "Epoch [29/30], Step [15/19], Loss: 0.0002\n",
      "Epoch [30/30], Step [5/19], Loss: 0.0000\n",
      "Epoch [30/30], Step [10/19], Loss: 0.0004\n",
      "Epoch [30/30], Step [15/19], Loss: 0.0002\n",
      "Test accuracy of the network: 89.69072164948453 %\n",
      "Train accuracy of the network: 100.0 %\n",
      "Epoch [1/40], Step [5/19], Loss: 0.3543\n",
      "Epoch [1/40], Step [10/19], Loss: 0.5111\n",
      "Epoch [1/40], Step [15/19], Loss: 0.2169\n",
      "Epoch [2/40], Step [5/19], Loss: 0.0395\n",
      "Epoch [2/40], Step [10/19], Loss: 0.1832\n",
      "Epoch [2/40], Step [15/19], Loss: 0.0935\n",
      "Epoch [3/40], Step [5/19], Loss: 0.0094\n",
      "Epoch [3/40], Step [10/19], Loss: 0.0684\n",
      "Epoch [3/40], Step [15/19], Loss: 0.0311\n",
      "Epoch [4/40], Step [5/19], Loss: 0.0038\n",
      "Epoch [4/40], Step [10/19], Loss: 0.0362\n",
      "Epoch [4/40], Step [15/19], Loss: 0.0157\n",
      "Epoch [5/40], Step [5/19], Loss: 0.0021\n",
      "Epoch [5/40], Step [10/19], Loss: 0.0217\n",
      "Epoch [5/40], Step [15/19], Loss: 0.0092\n",
      "Epoch [6/40], Step [5/19], Loss: 0.0013\n",
      "Epoch [6/40], Step [10/19], Loss: 0.0140\n",
      "Epoch [6/40], Step [15/19], Loss: 0.0059\n",
      "Epoch [7/40], Step [5/19], Loss: 0.0009\n",
      "Epoch [7/40], Step [10/19], Loss: 0.0097\n",
      "Epoch [7/40], Step [15/19], Loss: 0.0041\n",
      "Epoch [8/40], Step [5/19], Loss: 0.0007\n",
      "Epoch [8/40], Step [10/19], Loss: 0.0071\n",
      "Epoch [8/40], Step [15/19], Loss: 0.0030\n",
      "Epoch [9/40], Step [5/19], Loss: 0.0005\n",
      "Epoch [9/40], Step [10/19], Loss: 0.0054\n",
      "Epoch [9/40], Step [15/19], Loss: 0.0023\n",
      "Epoch [10/40], Step [5/19], Loss: 0.0004\n",
      "Epoch [10/40], Step [10/19], Loss: 0.0042\n",
      "Epoch [10/40], Step [15/19], Loss: 0.0018\n",
      "Epoch [11/40], Step [5/19], Loss: 0.0003\n",
      "Epoch [11/40], Step [10/19], Loss: 0.0034\n",
      "Epoch [11/40], Step [15/19], Loss: 0.0015\n",
      "Epoch [12/40], Step [5/19], Loss: 0.0003\n",
      "Epoch [12/40], Step [10/19], Loss: 0.0028\n",
      "Epoch [12/40], Step [15/19], Loss: 0.0012\n",
      "Epoch [13/40], Step [5/19], Loss: 0.0002\n",
      "Epoch [13/40], Step [10/19], Loss: 0.0024\n",
      "Epoch [13/40], Step [15/19], Loss: 0.0010\n",
      "Epoch [14/40], Step [5/19], Loss: 0.0002\n",
      "Epoch [14/40], Step [10/19], Loss: 0.0020\n",
      "Epoch [14/40], Step [15/19], Loss: 0.0009\n",
      "Epoch [15/40], Step [5/19], Loss: 0.0002\n",
      "Epoch [15/40], Step [10/19], Loss: 0.0017\n",
      "Epoch [15/40], Step [15/19], Loss: 0.0008\n",
      "Epoch [16/40], Step [5/19], Loss: 0.0002\n",
      "Epoch [16/40], Step [10/19], Loss: 0.0015\n",
      "Epoch [16/40], Step [15/19], Loss: 0.0007\n",
      "Epoch [17/40], Step [5/19], Loss: 0.0001\n",
      "Epoch [17/40], Step [10/19], Loss: 0.0013\n",
      "Epoch [17/40], Step [15/19], Loss: 0.0006\n",
      "Epoch [18/40], Step [5/19], Loss: 0.0001\n",
      "Epoch [18/40], Step [10/19], Loss: 0.0012\n",
      "Epoch [18/40], Step [15/19], Loss: 0.0005\n",
      "Epoch [19/40], Step [5/19], Loss: 0.0001\n",
      "Epoch [19/40], Step [10/19], Loss: 0.0011\n",
      "Epoch [19/40], Step [15/19], Loss: 0.0005\n",
      "Epoch [20/40], Step [5/19], Loss: 0.0001\n",
      "Epoch [20/40], Step [10/19], Loss: 0.0010\n",
      "Epoch [20/40], Step [15/19], Loss: 0.0004\n",
      "Epoch [21/40], Step [5/19], Loss: 0.0001\n",
      "Epoch [21/40], Step [10/19], Loss: 0.0009\n",
      "Epoch [21/40], Step [15/19], Loss: 0.0004\n",
      "Epoch [22/40], Step [5/19], Loss: 0.0001\n",
      "Epoch [22/40], Step [10/19], Loss: 0.0008\n",
      "Epoch [22/40], Step [15/19], Loss: 0.0004\n",
      "Epoch [23/40], Step [5/19], Loss: 0.0001\n",
      "Epoch [23/40], Step [10/19], Loss: 0.0007\n",
      "Epoch [23/40], Step [15/19], Loss: 0.0003\n",
      "Epoch [24/40], Step [5/19], Loss: 0.0001\n",
      "Epoch [24/40], Step [10/19], Loss: 0.0007\n",
      "Epoch [24/40], Step [15/19], Loss: 0.0003\n",
      "Epoch [25/40], Step [5/19], Loss: 0.0001\n",
      "Epoch [25/40], Step [10/19], Loss: 0.0006\n",
      "Epoch [25/40], Step [15/19], Loss: 0.0003\n",
      "Epoch [26/40], Step [5/19], Loss: 0.0001\n",
      "Epoch [26/40], Step [10/19], Loss: 0.0006\n",
      "Epoch [26/40], Step [15/19], Loss: 0.0003\n",
      "Epoch [27/40], Step [5/19], Loss: 0.0001\n",
      "Epoch [27/40], Step [10/19], Loss: 0.0005\n",
      "Epoch [27/40], Step [15/19], Loss: 0.0002\n",
      "Epoch [28/40], Step [5/19], Loss: 0.0001\n",
      "Epoch [28/40], Step [10/19], Loss: 0.0005\n",
      "Epoch [28/40], Step [15/19], Loss: 0.0002\n",
      "Epoch [29/40], Step [5/19], Loss: 0.0001\n",
      "Epoch [29/40], Step [10/19], Loss: 0.0005\n",
      "Epoch [29/40], Step [15/19], Loss: 0.0002\n",
      "Epoch [30/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [30/40], Step [10/19], Loss: 0.0004\n",
      "Epoch [30/40], Step [15/19], Loss: 0.0002\n",
      "Epoch [31/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [31/40], Step [10/19], Loss: 0.0004\n",
      "Epoch [31/40], Step [15/19], Loss: 0.0002\n",
      "Epoch [32/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [32/40], Step [10/19], Loss: 0.0004\n",
      "Epoch [32/40], Step [15/19], Loss: 0.0002\n",
      "Epoch [33/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [33/40], Step [10/19], Loss: 0.0004\n",
      "Epoch [33/40], Step [15/19], Loss: 0.0002\n",
      "Epoch [34/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [34/40], Step [10/19], Loss: 0.0003\n",
      "Epoch [34/40], Step [15/19], Loss: 0.0002\n",
      "Epoch [35/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [35/40], Step [10/19], Loss: 0.0003\n",
      "Epoch [35/40], Step [15/19], Loss: 0.0001\n",
      "Epoch [36/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [36/40], Step [10/19], Loss: 0.0003\n",
      "Epoch [36/40], Step [15/19], Loss: 0.0001\n",
      "Epoch [37/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [37/40], Step [10/19], Loss: 0.0003\n",
      "Epoch [37/40], Step [15/19], Loss: 0.0001\n",
      "Epoch [38/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [38/40], Step [10/19], Loss: 0.0003\n",
      "Epoch [38/40], Step [15/19], Loss: 0.0001\n",
      "Epoch [39/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [39/40], Step [10/19], Loss: 0.0003\n",
      "Epoch [39/40], Step [15/19], Loss: 0.0001\n",
      "Epoch [40/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [40/40], Step [10/19], Loss: 0.0002\n",
      "Epoch [40/40], Step [15/19], Loss: 0.0001\n",
      "Test accuracy of the network: 90.03436426116839 %\n",
      "Train accuracy of the network: 100.0 %\n",
      "Epoch [1/50], Step [5/19], Loss: 0.3543\n",
      "Epoch [1/50], Step [10/19], Loss: 0.5111\n",
      "Epoch [1/50], Step [15/19], Loss: 0.2169\n",
      "Epoch [2/50], Step [5/19], Loss: 0.0395\n",
      "Epoch [2/50], Step [10/19], Loss: 0.1832\n",
      "Epoch [2/50], Step [15/19], Loss: 0.0935\n",
      "Epoch [3/50], Step [5/19], Loss: 0.0094\n",
      "Epoch [3/50], Step [10/19], Loss: 0.0684\n",
      "Epoch [3/50], Step [15/19], Loss: 0.0311\n",
      "Epoch [4/50], Step [5/19], Loss: 0.0038\n",
      "Epoch [4/50], Step [10/19], Loss: 0.0362\n",
      "Epoch [4/50], Step [15/19], Loss: 0.0157\n",
      "Epoch [5/50], Step [5/19], Loss: 0.0021\n",
      "Epoch [5/50], Step [10/19], Loss: 0.0217\n",
      "Epoch [5/50], Step [15/19], Loss: 0.0092\n",
      "Epoch [6/50], Step [5/19], Loss: 0.0013\n",
      "Epoch [6/50], Step [10/19], Loss: 0.0140\n",
      "Epoch [6/50], Step [15/19], Loss: 0.0059\n",
      "Epoch [7/50], Step [5/19], Loss: 0.0009\n",
      "Epoch [7/50], Step [10/19], Loss: 0.0097\n",
      "Epoch [7/50], Step [15/19], Loss: 0.0041\n",
      "Epoch [8/50], Step [5/19], Loss: 0.0007\n",
      "Epoch [8/50], Step [10/19], Loss: 0.0071\n",
      "Epoch [8/50], Step [15/19], Loss: 0.0030\n",
      "Epoch [9/50], Step [5/19], Loss: 0.0005\n",
      "Epoch [9/50], Step [10/19], Loss: 0.0054\n",
      "Epoch [9/50], Step [15/19], Loss: 0.0023\n",
      "Epoch [10/50], Step [5/19], Loss: 0.0004\n",
      "Epoch [10/50], Step [10/19], Loss: 0.0042\n",
      "Epoch [10/50], Step [15/19], Loss: 0.0018\n",
      "Epoch [11/50], Step [5/19], Loss: 0.0003\n",
      "Epoch [11/50], Step [10/19], Loss: 0.0034\n",
      "Epoch [11/50], Step [15/19], Loss: 0.0015\n",
      "Epoch [12/50], Step [5/19], Loss: 0.0003\n",
      "Epoch [12/50], Step [10/19], Loss: 0.0028\n",
      "Epoch [12/50], Step [15/19], Loss: 0.0012\n",
      "Epoch [13/50], Step [5/19], Loss: 0.0002\n",
      "Epoch [13/50], Step [10/19], Loss: 0.0024\n",
      "Epoch [13/50], Step [15/19], Loss: 0.0010\n",
      "Epoch [14/50], Step [5/19], Loss: 0.0002\n",
      "Epoch [14/50], Step [10/19], Loss: 0.0020\n",
      "Epoch [14/50], Step [15/19], Loss: 0.0009\n",
      "Epoch [15/50], Step [5/19], Loss: 0.0002\n",
      "Epoch [15/50], Step [10/19], Loss: 0.0017\n",
      "Epoch [15/50], Step [15/19], Loss: 0.0008\n",
      "Epoch [16/50], Step [5/19], Loss: 0.0002\n",
      "Epoch [16/50], Step [10/19], Loss: 0.0015\n",
      "Epoch [16/50], Step [15/19], Loss: 0.0007\n",
      "Epoch [17/50], Step [5/19], Loss: 0.0001\n",
      "Epoch [17/50], Step [10/19], Loss: 0.0013\n",
      "Epoch [17/50], Step [15/19], Loss: 0.0006\n",
      "Epoch [18/50], Step [5/19], Loss: 0.0001\n",
      "Epoch [18/50], Step [10/19], Loss: 0.0012\n",
      "Epoch [18/50], Step [15/19], Loss: 0.0005\n",
      "Epoch [19/50], Step [5/19], Loss: 0.0001\n",
      "Epoch [19/50], Step [10/19], Loss: 0.0011\n",
      "Epoch [19/50], Step [15/19], Loss: 0.0005\n",
      "Epoch [20/50], Step [5/19], Loss: 0.0001\n",
      "Epoch [20/50], Step [10/19], Loss: 0.0010\n",
      "Epoch [20/50], Step [15/19], Loss: 0.0004\n",
      "Epoch [21/50], Step [5/19], Loss: 0.0001\n",
      "Epoch [21/50], Step [10/19], Loss: 0.0009\n",
      "Epoch [21/50], Step [15/19], Loss: 0.0004\n",
      "Epoch [22/50], Step [5/19], Loss: 0.0001\n",
      "Epoch [22/50], Step [10/19], Loss: 0.0008\n",
      "Epoch [22/50], Step [15/19], Loss: 0.0004\n",
      "Epoch [23/50], Step [5/19], Loss: 0.0001\n",
      "Epoch [23/50], Step [10/19], Loss: 0.0007\n",
      "Epoch [23/50], Step [15/19], Loss: 0.0003\n",
      "Epoch [24/50], Step [5/19], Loss: 0.0001\n",
      "Epoch [24/50], Step [10/19], Loss: 0.0007\n",
      "Epoch [24/50], Step [15/19], Loss: 0.0003\n",
      "Epoch [25/50], Step [5/19], Loss: 0.0001\n",
      "Epoch [25/50], Step [10/19], Loss: 0.0006\n",
      "Epoch [25/50], Step [15/19], Loss: 0.0003\n",
      "Epoch [26/50], Step [5/19], Loss: 0.0001\n",
      "Epoch [26/50], Step [10/19], Loss: 0.0006\n",
      "Epoch [26/50], Step [15/19], Loss: 0.0003\n",
      "Epoch [27/50], Step [5/19], Loss: 0.0001\n",
      "Epoch [27/50], Step [10/19], Loss: 0.0005\n",
      "Epoch [27/50], Step [15/19], Loss: 0.0002\n",
      "Epoch [28/50], Step [5/19], Loss: 0.0001\n",
      "Epoch [28/50], Step [10/19], Loss: 0.0005\n",
      "Epoch [28/50], Step [15/19], Loss: 0.0002\n",
      "Epoch [29/50], Step [5/19], Loss: 0.0001\n",
      "Epoch [29/50], Step [10/19], Loss: 0.0005\n",
      "Epoch [29/50], Step [15/19], Loss: 0.0002\n",
      "Epoch [30/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [30/50], Step [10/19], Loss: 0.0004\n",
      "Epoch [30/50], Step [15/19], Loss: 0.0002\n",
      "Epoch [31/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [31/50], Step [10/19], Loss: 0.0004\n",
      "Epoch [31/50], Step [15/19], Loss: 0.0002\n",
      "Epoch [32/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [32/50], Step [10/19], Loss: 0.0004\n",
      "Epoch [32/50], Step [15/19], Loss: 0.0002\n",
      "Epoch [33/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [33/50], Step [10/19], Loss: 0.0004\n",
      "Epoch [33/50], Step [15/19], Loss: 0.0002\n",
      "Epoch [34/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [34/50], Step [10/19], Loss: 0.0003\n",
      "Epoch [34/50], Step [15/19], Loss: 0.0002\n",
      "Epoch [35/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [35/50], Step [10/19], Loss: 0.0003\n",
      "Epoch [35/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [36/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [36/50], Step [10/19], Loss: 0.0003\n",
      "Epoch [36/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [37/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [37/50], Step [10/19], Loss: 0.0003\n",
      "Epoch [37/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [38/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [38/50], Step [10/19], Loss: 0.0003\n",
      "Epoch [38/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [39/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [39/50], Step [10/19], Loss: 0.0003\n",
      "Epoch [39/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [40/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [40/50], Step [10/19], Loss: 0.0002\n",
      "Epoch [40/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [41/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [41/50], Step [10/19], Loss: 0.0002\n",
      "Epoch [41/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [42/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [42/50], Step [10/19], Loss: 0.0002\n",
      "Epoch [42/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [43/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [43/50], Step [10/19], Loss: 0.0002\n",
      "Epoch [43/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [44/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [44/50], Step [10/19], Loss: 0.0002\n",
      "Epoch [44/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [45/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [45/50], Step [10/19], Loss: 0.0002\n",
      "Epoch [45/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [46/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [46/50], Step [10/19], Loss: 0.0002\n",
      "Epoch [46/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [47/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [47/50], Step [10/19], Loss: 0.0002\n",
      "Epoch [47/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [48/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [48/50], Step [10/19], Loss: 0.0002\n",
      "Epoch [48/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [49/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [49/50], Step [10/19], Loss: 0.0002\n",
      "Epoch [49/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [50/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [50/50], Step [10/19], Loss: 0.0002\n",
      "Epoch [50/50], Step [15/19], Loss: 0.0001\n",
      "Test accuracy of the network: 90.14891179839634 %\n",
      "Train accuracy of the network: 100.0 %\n",
      "Epoch [1/60], Step [5/19], Loss: 0.3543\n",
      "Epoch [1/60], Step [10/19], Loss: 0.5111\n",
      "Epoch [1/60], Step [15/19], Loss: 0.2169\n",
      "Epoch [2/60], Step [5/19], Loss: 0.0395\n",
      "Epoch [2/60], Step [10/19], Loss: 0.1832\n",
      "Epoch [2/60], Step [15/19], Loss: 0.0935\n",
      "Epoch [3/60], Step [5/19], Loss: 0.0094\n",
      "Epoch [3/60], Step [10/19], Loss: 0.0684\n",
      "Epoch [3/60], Step [15/19], Loss: 0.0311\n",
      "Epoch [4/60], Step [5/19], Loss: 0.0038\n",
      "Epoch [4/60], Step [10/19], Loss: 0.0362\n",
      "Epoch [4/60], Step [15/19], Loss: 0.0157\n",
      "Epoch [5/60], Step [5/19], Loss: 0.0021\n",
      "Epoch [5/60], Step [10/19], Loss: 0.0217\n",
      "Epoch [5/60], Step [15/19], Loss: 0.0092\n",
      "Epoch [6/60], Step [5/19], Loss: 0.0013\n",
      "Epoch [6/60], Step [10/19], Loss: 0.0140\n",
      "Epoch [6/60], Step [15/19], Loss: 0.0059\n",
      "Epoch [7/60], Step [5/19], Loss: 0.0009\n",
      "Epoch [7/60], Step [10/19], Loss: 0.0097\n",
      "Epoch [7/60], Step [15/19], Loss: 0.0041\n",
      "Epoch [8/60], Step [5/19], Loss: 0.0007\n",
      "Epoch [8/60], Step [10/19], Loss: 0.0071\n",
      "Epoch [8/60], Step [15/19], Loss: 0.0030\n",
      "Epoch [9/60], Step [5/19], Loss: 0.0005\n",
      "Epoch [9/60], Step [10/19], Loss: 0.0054\n",
      "Epoch [9/60], Step [15/19], Loss: 0.0023\n",
      "Epoch [10/60], Step [5/19], Loss: 0.0004\n",
      "Epoch [10/60], Step [10/19], Loss: 0.0042\n",
      "Epoch [10/60], Step [15/19], Loss: 0.0018\n",
      "Epoch [11/60], Step [5/19], Loss: 0.0003\n",
      "Epoch [11/60], Step [10/19], Loss: 0.0034\n",
      "Epoch [11/60], Step [15/19], Loss: 0.0015\n",
      "Epoch [12/60], Step [5/19], Loss: 0.0003\n",
      "Epoch [12/60], Step [10/19], Loss: 0.0028\n",
      "Epoch [12/60], Step [15/19], Loss: 0.0012\n",
      "Epoch [13/60], Step [5/19], Loss: 0.0002\n",
      "Epoch [13/60], Step [10/19], Loss: 0.0024\n",
      "Epoch [13/60], Step [15/19], Loss: 0.0010\n",
      "Epoch [14/60], Step [5/19], Loss: 0.0002\n",
      "Epoch [14/60], Step [10/19], Loss: 0.0020\n",
      "Epoch [14/60], Step [15/19], Loss: 0.0009\n",
      "Epoch [15/60], Step [5/19], Loss: 0.0002\n",
      "Epoch [15/60], Step [10/19], Loss: 0.0017\n",
      "Epoch [15/60], Step [15/19], Loss: 0.0008\n",
      "Epoch [16/60], Step [5/19], Loss: 0.0002\n",
      "Epoch [16/60], Step [10/19], Loss: 0.0015\n",
      "Epoch [16/60], Step [15/19], Loss: 0.0007\n",
      "Epoch [17/60], Step [5/19], Loss: 0.0001\n",
      "Epoch [17/60], Step [10/19], Loss: 0.0013\n",
      "Epoch [17/60], Step [15/19], Loss: 0.0006\n",
      "Epoch [18/60], Step [5/19], Loss: 0.0001\n",
      "Epoch [18/60], Step [10/19], Loss: 0.0012\n",
      "Epoch [18/60], Step [15/19], Loss: 0.0005\n",
      "Epoch [19/60], Step [5/19], Loss: 0.0001\n",
      "Epoch [19/60], Step [10/19], Loss: 0.0011\n",
      "Epoch [19/60], Step [15/19], Loss: 0.0005\n",
      "Epoch [20/60], Step [5/19], Loss: 0.0001\n",
      "Epoch [20/60], Step [10/19], Loss: 0.0010\n",
      "Epoch [20/60], Step [15/19], Loss: 0.0004\n",
      "Epoch [21/60], Step [5/19], Loss: 0.0001\n",
      "Epoch [21/60], Step [10/19], Loss: 0.0009\n",
      "Epoch [21/60], Step [15/19], Loss: 0.0004\n",
      "Epoch [22/60], Step [5/19], Loss: 0.0001\n",
      "Epoch [22/60], Step [10/19], Loss: 0.0008\n",
      "Epoch [22/60], Step [15/19], Loss: 0.0004\n",
      "Epoch [23/60], Step [5/19], Loss: 0.0001\n",
      "Epoch [23/60], Step [10/19], Loss: 0.0007\n",
      "Epoch [23/60], Step [15/19], Loss: 0.0003\n",
      "Epoch [24/60], Step [5/19], Loss: 0.0001\n",
      "Epoch [24/60], Step [10/19], Loss: 0.0007\n",
      "Epoch [24/60], Step [15/19], Loss: 0.0003\n",
      "Epoch [25/60], Step [5/19], Loss: 0.0001\n",
      "Epoch [25/60], Step [10/19], Loss: 0.0006\n",
      "Epoch [25/60], Step [15/19], Loss: 0.0003\n",
      "Epoch [26/60], Step [5/19], Loss: 0.0001\n",
      "Epoch [26/60], Step [10/19], Loss: 0.0006\n",
      "Epoch [26/60], Step [15/19], Loss: 0.0003\n",
      "Epoch [27/60], Step [5/19], Loss: 0.0001\n",
      "Epoch [27/60], Step [10/19], Loss: 0.0005\n",
      "Epoch [27/60], Step [15/19], Loss: 0.0002\n",
      "Epoch [28/60], Step [5/19], Loss: 0.0001\n",
      "Epoch [28/60], Step [10/19], Loss: 0.0005\n",
      "Epoch [28/60], Step [15/19], Loss: 0.0002\n",
      "Epoch [29/60], Step [5/19], Loss: 0.0001\n",
      "Epoch [29/60], Step [10/19], Loss: 0.0005\n",
      "Epoch [29/60], Step [15/19], Loss: 0.0002\n",
      "Epoch [30/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [30/60], Step [10/19], Loss: 0.0004\n",
      "Epoch [30/60], Step [15/19], Loss: 0.0002\n",
      "Epoch [31/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [31/60], Step [10/19], Loss: 0.0004\n",
      "Epoch [31/60], Step [15/19], Loss: 0.0002\n",
      "Epoch [32/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [32/60], Step [10/19], Loss: 0.0004\n",
      "Epoch [32/60], Step [15/19], Loss: 0.0002\n",
      "Epoch [33/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [33/60], Step [10/19], Loss: 0.0004\n",
      "Epoch [33/60], Step [15/19], Loss: 0.0002\n",
      "Epoch [34/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [34/60], Step [10/19], Loss: 0.0003\n",
      "Epoch [34/60], Step [15/19], Loss: 0.0002\n",
      "Epoch [35/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [35/60], Step [10/19], Loss: 0.0003\n",
      "Epoch [35/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [36/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [36/60], Step [10/19], Loss: 0.0003\n",
      "Epoch [36/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [37/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [37/60], Step [10/19], Loss: 0.0003\n",
      "Epoch [37/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [38/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [38/60], Step [10/19], Loss: 0.0003\n",
      "Epoch [38/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [39/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [39/60], Step [10/19], Loss: 0.0003\n",
      "Epoch [39/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [40/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [40/60], Step [10/19], Loss: 0.0002\n",
      "Epoch [40/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [41/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [41/60], Step [10/19], Loss: 0.0002\n",
      "Epoch [41/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [42/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [42/60], Step [10/19], Loss: 0.0002\n",
      "Epoch [42/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [43/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [43/60], Step [10/19], Loss: 0.0002\n",
      "Epoch [43/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [44/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [44/60], Step [10/19], Loss: 0.0002\n",
      "Epoch [44/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [45/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [45/60], Step [10/19], Loss: 0.0002\n",
      "Epoch [45/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [46/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [46/60], Step [10/19], Loss: 0.0002\n",
      "Epoch [46/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [47/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [47/60], Step [10/19], Loss: 0.0002\n",
      "Epoch [47/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [48/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [48/60], Step [10/19], Loss: 0.0002\n",
      "Epoch [48/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [49/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [49/60], Step [10/19], Loss: 0.0002\n",
      "Epoch [49/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [50/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [50/60], Step [10/19], Loss: 0.0002\n",
      "Epoch [50/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [51/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [51/60], Step [10/19], Loss: 0.0002\n",
      "Epoch [51/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [52/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [52/60], Step [10/19], Loss: 0.0001\n",
      "Epoch [52/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [53/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [53/60], Step [10/19], Loss: 0.0001\n",
      "Epoch [53/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [54/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [54/60], Step [10/19], Loss: 0.0001\n",
      "Epoch [54/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [55/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [55/60], Step [10/19], Loss: 0.0001\n",
      "Epoch [55/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [56/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [56/60], Step [10/19], Loss: 0.0001\n",
      "Epoch [56/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [57/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [57/60], Step [10/19], Loss: 0.0001\n",
      "Epoch [57/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [58/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [58/60], Step [10/19], Loss: 0.0001\n",
      "Epoch [58/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [59/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [59/60], Step [10/19], Loss: 0.0001\n",
      "Epoch [59/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [60/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [60/60], Step [10/19], Loss: 0.0001\n",
      "Epoch [60/60], Step [15/19], Loss: 0.0001\n",
      "Test accuracy of the network: 90.03436426116839 %\n",
      "Train accuracy of the network: 100.0 %\n",
      "Epoch [1/75], Step [5/19], Loss: 0.3543\n",
      "Epoch [1/75], Step [10/19], Loss: 0.5111\n",
      "Epoch [1/75], Step [15/19], Loss: 0.2169\n",
      "Epoch [2/75], Step [5/19], Loss: 0.0395\n",
      "Epoch [2/75], Step [10/19], Loss: 0.1832\n",
      "Epoch [2/75], Step [15/19], Loss: 0.0935\n",
      "Epoch [3/75], Step [5/19], Loss: 0.0094\n",
      "Epoch [3/75], Step [10/19], Loss: 0.0684\n",
      "Epoch [3/75], Step [15/19], Loss: 0.0311\n",
      "Epoch [4/75], Step [5/19], Loss: 0.0038\n",
      "Epoch [4/75], Step [10/19], Loss: 0.0362\n",
      "Epoch [4/75], Step [15/19], Loss: 0.0157\n",
      "Epoch [5/75], Step [5/19], Loss: 0.0021\n",
      "Epoch [5/75], Step [10/19], Loss: 0.0217\n",
      "Epoch [5/75], Step [15/19], Loss: 0.0092\n",
      "Epoch [6/75], Step [5/19], Loss: 0.0013\n",
      "Epoch [6/75], Step [10/19], Loss: 0.0140\n",
      "Epoch [6/75], Step [15/19], Loss: 0.0059\n",
      "Epoch [7/75], Step [5/19], Loss: 0.0009\n",
      "Epoch [7/75], Step [10/19], Loss: 0.0097\n",
      "Epoch [7/75], Step [15/19], Loss: 0.0041\n",
      "Epoch [8/75], Step [5/19], Loss: 0.0007\n",
      "Epoch [8/75], Step [10/19], Loss: 0.0071\n",
      "Epoch [8/75], Step [15/19], Loss: 0.0030\n",
      "Epoch [9/75], Step [5/19], Loss: 0.0005\n",
      "Epoch [9/75], Step [10/19], Loss: 0.0054\n",
      "Epoch [9/75], Step [15/19], Loss: 0.0023\n",
      "Epoch [10/75], Step [5/19], Loss: 0.0004\n",
      "Epoch [10/75], Step [10/19], Loss: 0.0042\n",
      "Epoch [10/75], Step [15/19], Loss: 0.0018\n",
      "Epoch [11/75], Step [5/19], Loss: 0.0003\n",
      "Epoch [11/75], Step [10/19], Loss: 0.0034\n",
      "Epoch [11/75], Step [15/19], Loss: 0.0015\n",
      "Epoch [12/75], Step [5/19], Loss: 0.0003\n",
      "Epoch [12/75], Step [10/19], Loss: 0.0028\n",
      "Epoch [12/75], Step [15/19], Loss: 0.0012\n",
      "Epoch [13/75], Step [5/19], Loss: 0.0002\n",
      "Epoch [13/75], Step [10/19], Loss: 0.0024\n",
      "Epoch [13/75], Step [15/19], Loss: 0.0010\n",
      "Epoch [14/75], Step [5/19], Loss: 0.0002\n",
      "Epoch [14/75], Step [10/19], Loss: 0.0020\n",
      "Epoch [14/75], Step [15/19], Loss: 0.0009\n",
      "Epoch [15/75], Step [5/19], Loss: 0.0002\n",
      "Epoch [15/75], Step [10/19], Loss: 0.0017\n",
      "Epoch [15/75], Step [15/19], Loss: 0.0008\n",
      "Epoch [16/75], Step [5/19], Loss: 0.0002\n",
      "Epoch [16/75], Step [10/19], Loss: 0.0015\n",
      "Epoch [16/75], Step [15/19], Loss: 0.0007\n",
      "Epoch [17/75], Step [5/19], Loss: 0.0001\n",
      "Epoch [17/75], Step [10/19], Loss: 0.0013\n",
      "Epoch [17/75], Step [15/19], Loss: 0.0006\n",
      "Epoch [18/75], Step [5/19], Loss: 0.0001\n",
      "Epoch [18/75], Step [10/19], Loss: 0.0012\n",
      "Epoch [18/75], Step [15/19], Loss: 0.0005\n",
      "Epoch [19/75], Step [5/19], Loss: 0.0001\n",
      "Epoch [19/75], Step [10/19], Loss: 0.0011\n",
      "Epoch [19/75], Step [15/19], Loss: 0.0005\n",
      "Epoch [20/75], Step [5/19], Loss: 0.0001\n",
      "Epoch [20/75], Step [10/19], Loss: 0.0010\n",
      "Epoch [20/75], Step [15/19], Loss: 0.0004\n",
      "Epoch [21/75], Step [5/19], Loss: 0.0001\n",
      "Epoch [21/75], Step [10/19], Loss: 0.0009\n",
      "Epoch [21/75], Step [15/19], Loss: 0.0004\n",
      "Epoch [22/75], Step [5/19], Loss: 0.0001\n",
      "Epoch [22/75], Step [10/19], Loss: 0.0008\n",
      "Epoch [22/75], Step [15/19], Loss: 0.0004\n",
      "Epoch [23/75], Step [5/19], Loss: 0.0001\n",
      "Epoch [23/75], Step [10/19], Loss: 0.0007\n",
      "Epoch [23/75], Step [15/19], Loss: 0.0003\n",
      "Epoch [24/75], Step [5/19], Loss: 0.0001\n",
      "Epoch [24/75], Step [10/19], Loss: 0.0007\n",
      "Epoch [24/75], Step [15/19], Loss: 0.0003\n",
      "Epoch [25/75], Step [5/19], Loss: 0.0001\n",
      "Epoch [25/75], Step [10/19], Loss: 0.0006\n",
      "Epoch [25/75], Step [15/19], Loss: 0.0003\n",
      "Epoch [26/75], Step [5/19], Loss: 0.0001\n",
      "Epoch [26/75], Step [10/19], Loss: 0.0006\n",
      "Epoch [26/75], Step [15/19], Loss: 0.0003\n",
      "Epoch [27/75], Step [5/19], Loss: 0.0001\n",
      "Epoch [27/75], Step [10/19], Loss: 0.0005\n",
      "Epoch [27/75], Step [15/19], Loss: 0.0002\n",
      "Epoch [28/75], Step [5/19], Loss: 0.0001\n",
      "Epoch [28/75], Step [10/19], Loss: 0.0005\n",
      "Epoch [28/75], Step [15/19], Loss: 0.0002\n",
      "Epoch [29/75], Step [5/19], Loss: 0.0001\n",
      "Epoch [29/75], Step [10/19], Loss: 0.0005\n",
      "Epoch [29/75], Step [15/19], Loss: 0.0002\n",
      "Epoch [30/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [30/75], Step [10/19], Loss: 0.0004\n",
      "Epoch [30/75], Step [15/19], Loss: 0.0002\n",
      "Epoch [31/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [31/75], Step [10/19], Loss: 0.0004\n",
      "Epoch [31/75], Step [15/19], Loss: 0.0002\n",
      "Epoch [32/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [32/75], Step [10/19], Loss: 0.0004\n",
      "Epoch [32/75], Step [15/19], Loss: 0.0002\n",
      "Epoch [33/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [33/75], Step [10/19], Loss: 0.0004\n",
      "Epoch [33/75], Step [15/19], Loss: 0.0002\n",
      "Epoch [34/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [34/75], Step [10/19], Loss: 0.0003\n",
      "Epoch [34/75], Step [15/19], Loss: 0.0002\n",
      "Epoch [35/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [35/75], Step [10/19], Loss: 0.0003\n",
      "Epoch [35/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [36/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [36/75], Step [10/19], Loss: 0.0003\n",
      "Epoch [36/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [37/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [37/75], Step [10/19], Loss: 0.0003\n",
      "Epoch [37/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [38/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [38/75], Step [10/19], Loss: 0.0003\n",
      "Epoch [38/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [39/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [39/75], Step [10/19], Loss: 0.0003\n",
      "Epoch [39/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [40/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [40/75], Step [10/19], Loss: 0.0002\n",
      "Epoch [40/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [41/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [41/75], Step [10/19], Loss: 0.0002\n",
      "Epoch [41/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [42/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [42/75], Step [10/19], Loss: 0.0002\n",
      "Epoch [42/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [43/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [43/75], Step [10/19], Loss: 0.0002\n",
      "Epoch [43/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [44/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [44/75], Step [10/19], Loss: 0.0002\n",
      "Epoch [44/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [45/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [45/75], Step [10/19], Loss: 0.0002\n",
      "Epoch [45/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [46/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [46/75], Step [10/19], Loss: 0.0002\n",
      "Epoch [46/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [47/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [47/75], Step [10/19], Loss: 0.0002\n",
      "Epoch [47/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [48/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [48/75], Step [10/19], Loss: 0.0002\n",
      "Epoch [48/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [49/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [49/75], Step [10/19], Loss: 0.0002\n",
      "Epoch [49/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [50/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [50/75], Step [10/19], Loss: 0.0002\n",
      "Epoch [50/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [51/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [51/75], Step [10/19], Loss: 0.0002\n",
      "Epoch [51/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [52/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [52/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [52/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [53/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [53/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [53/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [54/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [54/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [54/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [55/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [55/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [55/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [56/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [56/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [56/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [57/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [57/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [57/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [58/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [58/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [58/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [59/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [59/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [59/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [60/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [60/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [60/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [61/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [61/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [61/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [62/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [62/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [62/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [63/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [63/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [63/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [64/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [64/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [64/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [65/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [65/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [65/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [66/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [66/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [66/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [67/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [67/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [67/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [68/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [68/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [68/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [69/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [69/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [69/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [70/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [70/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [70/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [71/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [71/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [71/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [72/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [72/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [72/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [73/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [73/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [73/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [74/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [74/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [74/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [75/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [75/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [75/75], Step [15/19], Loss: 0.0000\n",
      "Test accuracy of the network: 89.91981672394043 %\n",
      "Train accuracy of the network: 100.0 %\n",
      "Epoch [1/100], Step [5/19], Loss: 0.3543\n",
      "Epoch [1/100], Step [10/19], Loss: 0.5111\n",
      "Epoch [1/100], Step [15/19], Loss: 0.2169\n",
      "Epoch [2/100], Step [5/19], Loss: 0.0395\n",
      "Epoch [2/100], Step [10/19], Loss: 0.1832\n",
      "Epoch [2/100], Step [15/19], Loss: 0.0935\n",
      "Epoch [3/100], Step [5/19], Loss: 0.0094\n",
      "Epoch [3/100], Step [10/19], Loss: 0.0684\n",
      "Epoch [3/100], Step [15/19], Loss: 0.0311\n",
      "Epoch [4/100], Step [5/19], Loss: 0.0038\n",
      "Epoch [4/100], Step [10/19], Loss: 0.0362\n",
      "Epoch [4/100], Step [15/19], Loss: 0.0157\n",
      "Epoch [5/100], Step [5/19], Loss: 0.0021\n",
      "Epoch [5/100], Step [10/19], Loss: 0.0217\n",
      "Epoch [5/100], Step [15/19], Loss: 0.0092\n",
      "Epoch [6/100], Step [5/19], Loss: 0.0013\n",
      "Epoch [6/100], Step [10/19], Loss: 0.0140\n",
      "Epoch [6/100], Step [15/19], Loss: 0.0059\n",
      "Epoch [7/100], Step [5/19], Loss: 0.0009\n",
      "Epoch [7/100], Step [10/19], Loss: 0.0097\n",
      "Epoch [7/100], Step [15/19], Loss: 0.0041\n",
      "Epoch [8/100], Step [5/19], Loss: 0.0007\n",
      "Epoch [8/100], Step [10/19], Loss: 0.0071\n",
      "Epoch [8/100], Step [15/19], Loss: 0.0030\n",
      "Epoch [9/100], Step [5/19], Loss: 0.0005\n",
      "Epoch [9/100], Step [10/19], Loss: 0.0054\n",
      "Epoch [9/100], Step [15/19], Loss: 0.0023\n",
      "Epoch [10/100], Step [5/19], Loss: 0.0004\n",
      "Epoch [10/100], Step [10/19], Loss: 0.0042\n",
      "Epoch [10/100], Step [15/19], Loss: 0.0018\n",
      "Epoch [11/100], Step [5/19], Loss: 0.0003\n",
      "Epoch [11/100], Step [10/19], Loss: 0.0034\n",
      "Epoch [11/100], Step [15/19], Loss: 0.0015\n",
      "Epoch [12/100], Step [5/19], Loss: 0.0003\n",
      "Epoch [12/100], Step [10/19], Loss: 0.0028\n",
      "Epoch [12/100], Step [15/19], Loss: 0.0012\n",
      "Epoch [13/100], Step [5/19], Loss: 0.0002\n",
      "Epoch [13/100], Step [10/19], Loss: 0.0024\n",
      "Epoch [13/100], Step [15/19], Loss: 0.0010\n",
      "Epoch [14/100], Step [5/19], Loss: 0.0002\n",
      "Epoch [14/100], Step [10/19], Loss: 0.0020\n",
      "Epoch [14/100], Step [15/19], Loss: 0.0009\n",
      "Epoch [15/100], Step [5/19], Loss: 0.0002\n",
      "Epoch [15/100], Step [10/19], Loss: 0.0017\n",
      "Epoch [15/100], Step [15/19], Loss: 0.0008\n",
      "Epoch [16/100], Step [5/19], Loss: 0.0002\n",
      "Epoch [16/100], Step [10/19], Loss: 0.0015\n",
      "Epoch [16/100], Step [15/19], Loss: 0.0007\n",
      "Epoch [17/100], Step [5/19], Loss: 0.0001\n",
      "Epoch [17/100], Step [10/19], Loss: 0.0013\n",
      "Epoch [17/100], Step [15/19], Loss: 0.0006\n",
      "Epoch [18/100], Step [5/19], Loss: 0.0001\n",
      "Epoch [18/100], Step [10/19], Loss: 0.0012\n",
      "Epoch [18/100], Step [15/19], Loss: 0.0005\n",
      "Epoch [19/100], Step [5/19], Loss: 0.0001\n",
      "Epoch [19/100], Step [10/19], Loss: 0.0011\n",
      "Epoch [19/100], Step [15/19], Loss: 0.0005\n",
      "Epoch [20/100], Step [5/19], Loss: 0.0001\n",
      "Epoch [20/100], Step [10/19], Loss: 0.0010\n",
      "Epoch [20/100], Step [15/19], Loss: 0.0004\n",
      "Epoch [21/100], Step [5/19], Loss: 0.0001\n",
      "Epoch [21/100], Step [10/19], Loss: 0.0009\n",
      "Epoch [21/100], Step [15/19], Loss: 0.0004\n",
      "Epoch [22/100], Step [5/19], Loss: 0.0001\n",
      "Epoch [22/100], Step [10/19], Loss: 0.0008\n",
      "Epoch [22/100], Step [15/19], Loss: 0.0004\n",
      "Epoch [23/100], Step [5/19], Loss: 0.0001\n",
      "Epoch [23/100], Step [10/19], Loss: 0.0007\n",
      "Epoch [23/100], Step [15/19], Loss: 0.0003\n",
      "Epoch [24/100], Step [5/19], Loss: 0.0001\n",
      "Epoch [24/100], Step [10/19], Loss: 0.0007\n",
      "Epoch [24/100], Step [15/19], Loss: 0.0003\n",
      "Epoch [25/100], Step [5/19], Loss: 0.0001\n",
      "Epoch [25/100], Step [10/19], Loss: 0.0006\n",
      "Epoch [25/100], Step [15/19], Loss: 0.0003\n",
      "Epoch [26/100], Step [5/19], Loss: 0.0001\n",
      "Epoch [26/100], Step [10/19], Loss: 0.0006\n",
      "Epoch [26/100], Step [15/19], Loss: 0.0003\n",
      "Epoch [27/100], Step [5/19], Loss: 0.0001\n",
      "Epoch [27/100], Step [10/19], Loss: 0.0005\n",
      "Epoch [27/100], Step [15/19], Loss: 0.0002\n",
      "Epoch [28/100], Step [5/19], Loss: 0.0001\n",
      "Epoch [28/100], Step [10/19], Loss: 0.0005\n",
      "Epoch [28/100], Step [15/19], Loss: 0.0002\n",
      "Epoch [29/100], Step [5/19], Loss: 0.0001\n",
      "Epoch [29/100], Step [10/19], Loss: 0.0005\n",
      "Epoch [29/100], Step [15/19], Loss: 0.0002\n",
      "Epoch [30/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [30/100], Step [10/19], Loss: 0.0004\n",
      "Epoch [30/100], Step [15/19], Loss: 0.0002\n",
      "Epoch [31/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [31/100], Step [10/19], Loss: 0.0004\n",
      "Epoch [31/100], Step [15/19], Loss: 0.0002\n",
      "Epoch [32/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [32/100], Step [10/19], Loss: 0.0004\n",
      "Epoch [32/100], Step [15/19], Loss: 0.0002\n",
      "Epoch [33/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [33/100], Step [10/19], Loss: 0.0004\n",
      "Epoch [33/100], Step [15/19], Loss: 0.0002\n",
      "Epoch [34/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [34/100], Step [10/19], Loss: 0.0003\n",
      "Epoch [34/100], Step [15/19], Loss: 0.0002\n",
      "Epoch [35/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [35/100], Step [10/19], Loss: 0.0003\n",
      "Epoch [35/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [36/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [36/100], Step [10/19], Loss: 0.0003\n",
      "Epoch [36/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [37/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [37/100], Step [10/19], Loss: 0.0003\n",
      "Epoch [37/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [38/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [38/100], Step [10/19], Loss: 0.0003\n",
      "Epoch [38/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [39/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [39/100], Step [10/19], Loss: 0.0003\n",
      "Epoch [39/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [40/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [40/100], Step [10/19], Loss: 0.0002\n",
      "Epoch [40/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [41/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [41/100], Step [10/19], Loss: 0.0002\n",
      "Epoch [41/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [42/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [42/100], Step [10/19], Loss: 0.0002\n",
      "Epoch [42/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [43/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [43/100], Step [10/19], Loss: 0.0002\n",
      "Epoch [43/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [44/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [44/100], Step [10/19], Loss: 0.0002\n",
      "Epoch [44/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [45/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [45/100], Step [10/19], Loss: 0.0002\n",
      "Epoch [45/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [46/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [46/100], Step [10/19], Loss: 0.0002\n",
      "Epoch [46/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [47/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [47/100], Step [10/19], Loss: 0.0002\n",
      "Epoch [47/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [48/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [48/100], Step [10/19], Loss: 0.0002\n",
      "Epoch [48/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [49/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [49/100], Step [10/19], Loss: 0.0002\n",
      "Epoch [49/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [50/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [50/100], Step [10/19], Loss: 0.0002\n",
      "Epoch [50/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [51/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [51/100], Step [10/19], Loss: 0.0002\n",
      "Epoch [51/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [52/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [52/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [52/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [53/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [53/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [53/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [54/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [54/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [54/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [55/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [55/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [55/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [56/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [56/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [56/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [57/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [57/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [57/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [58/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [58/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [58/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [59/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [59/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [59/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [60/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [60/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [60/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [61/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [61/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [61/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [62/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [62/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [62/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [63/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [63/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [63/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [64/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [64/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [64/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [65/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [65/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [65/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [66/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [66/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [66/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [67/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [67/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [67/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [68/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [68/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [68/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [69/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [69/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [69/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [70/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [70/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [70/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [71/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [71/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [71/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [72/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [72/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [72/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [73/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [73/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [73/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [74/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [74/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [74/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [75/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [75/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [75/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [76/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [76/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [76/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [77/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [77/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [77/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [78/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [78/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [78/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [79/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [79/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [79/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [80/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [80/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [80/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [81/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [81/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [81/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [82/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [82/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [82/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [83/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [83/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [83/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [84/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [84/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [84/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [85/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [85/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [85/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [86/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [86/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [86/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [87/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [87/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [87/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [88/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [88/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [88/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [89/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [89/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [89/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [90/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [90/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [90/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [91/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [91/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [91/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [92/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [92/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [92/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [93/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [93/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [93/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [94/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [94/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [94/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [95/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [95/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [95/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [96/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [96/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [96/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [97/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [97/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [97/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [98/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [98/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [98/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [99/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [99/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [99/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [100/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [100/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [100/100], Step [15/19], Loss: 0.0000\n",
      "Test accuracy of the network: 89.69072164948453 %\n",
      "Train accuracy of the network: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "for num_epoch in num_epochs_used:\n",
    "    test_accuracy, train_accuracy = trainAndTestSimpleModel('corona', num_epochs=num_epoch)\n",
    "    corona_test_accuracies.append(test_accuracy)\n",
    "    corona_train_accuracies.append(train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "ax.plot(num_epochs_used, corona_train_accuracies, 'r-', lw=3, label='Train Accuracy')\n",
    "ax.plot(num_epochs_used, corona_test_accuracies, 'g-', lw=3, label='Test Accuracy')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15052, 4893)\n",
      "Epoch [1/1], Step [500/941], Loss: 0.4891\n",
      "Test accuracy of the network: 70.06319115323855 %\n",
      "Train accuracy of the network: 81.27159181504119 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15052, 4893)\n",
      "Epoch [1/5], Step [500/941], Loss: 0.4891\n",
      "Epoch [2/5], Step [500/941], Loss: 0.4241\n",
      "Epoch [3/5], Step [500/941], Loss: 0.3268\n",
      "Epoch [4/5], Step [500/941], Loss: 0.1347\n",
      "Epoch [5/5], Step [500/941], Loss: 0.0551\n",
      "Test accuracy of the network: 67.9304897314376 %\n",
      "Train accuracy of the network: 94.7315971299495 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15052, 4893)\n",
      "Epoch [1/10], Step [500/941], Loss: 0.4891\n",
      "Epoch [2/10], Step [500/941], Loss: 0.4241\n",
      "Epoch [3/10], Step [500/941], Loss: 0.3268\n",
      "Epoch [4/10], Step [500/941], Loss: 0.1347\n",
      "Epoch [5/10], Step [500/941], Loss: 0.0551\n",
      "Epoch [6/10], Step [500/941], Loss: 0.0201\n",
      "Epoch [7/10], Step [500/941], Loss: 0.0199\n",
      "Epoch [8/10], Step [500/941], Loss: 0.0088\n",
      "Epoch [9/10], Step [500/941], Loss: 0.0036\n",
      "Epoch [10/10], Step [500/941], Loss: 0.0031\n",
      "Test accuracy of the network: 70.22116903633491 %\n",
      "Train accuracy of the network: 98.61812383736381 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15052, 4893)\n",
      "Epoch [1/20], Step [500/941], Loss: 0.4891\n",
      "Epoch [2/20], Step [500/941], Loss: 0.4241\n",
      "Epoch [3/20], Step [500/941], Loss: 0.3268\n",
      "Epoch [4/20], Step [500/941], Loss: 0.1347\n",
      "Epoch [5/20], Step [500/941], Loss: 0.0551\n",
      "Epoch [6/20], Step [500/941], Loss: 0.0201\n",
      "Epoch [7/20], Step [500/941], Loss: 0.0199\n",
      "Epoch [8/20], Step [500/941], Loss: 0.0088\n",
      "Epoch [9/20], Step [500/941], Loss: 0.0036\n",
      "Epoch [10/20], Step [500/941], Loss: 0.0031\n",
      "Epoch [11/20], Step [500/941], Loss: 0.0043\n",
      "Epoch [12/20], Step [500/941], Loss: 0.0037\n",
      "Epoch [13/20], Step [500/941], Loss: 0.0086\n",
      "Epoch [14/20], Step [500/941], Loss: 0.0017\n",
      "Epoch [15/20], Step [500/941], Loss: 0.0020\n",
      "Epoch [16/20], Step [500/941], Loss: 0.0028\n",
      "Epoch [17/20], Step [500/941], Loss: 0.0019\n",
      "Epoch [18/20], Step [500/941], Loss: 0.0001\n",
      "Epoch [19/20], Step [500/941], Loss: 0.0002\n",
      "Epoch [20/20], Step [500/941], Loss: 0.0001\n",
      "Test accuracy of the network: 68.64139020537125 %\n",
      "Train accuracy of the network: 99.95349455221897 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15052, 4893)\n",
      "Epoch [1/30], Step [500/941], Loss: 0.4891\n",
      "Epoch [2/30], Step [500/941], Loss: 0.4241\n",
      "Epoch [3/30], Step [500/941], Loss: 0.3268\n",
      "Epoch [4/30], Step [500/941], Loss: 0.1347\n",
      "Epoch [5/30], Step [500/941], Loss: 0.0551\n",
      "Epoch [6/30], Step [500/941], Loss: 0.0201\n",
      "Epoch [7/30], Step [500/941], Loss: 0.0199\n",
      "Epoch [8/30], Step [500/941], Loss: 0.0088\n",
      "Epoch [9/30], Step [500/941], Loss: 0.0036\n",
      "Epoch [10/30], Step [500/941], Loss: 0.0031\n",
      "Epoch [11/30], Step [500/941], Loss: 0.0043\n",
      "Epoch [12/30], Step [500/941], Loss: 0.0037\n",
      "Epoch [13/30], Step [500/941], Loss: 0.0086\n",
      "Epoch [14/30], Step [500/941], Loss: 0.0017\n",
      "Epoch [15/30], Step [500/941], Loss: 0.0020\n",
      "Epoch [16/30], Step [500/941], Loss: 0.0028\n",
      "Epoch [17/30], Step [500/941], Loss: 0.0019\n",
      "Epoch [18/30], Step [500/941], Loss: 0.0001\n",
      "Epoch [19/30], Step [500/941], Loss: 0.0002\n",
      "Epoch [20/30], Step [500/941], Loss: 0.0001\n",
      "Epoch [21/30], Step [500/941], Loss: 0.0000\n",
      "Epoch [22/30], Step [500/941], Loss: 0.0000\n",
      "Epoch [23/30], Step [500/941], Loss: 0.0000\n",
      "Epoch [24/30], Step [500/941], Loss: 0.0000\n",
      "Epoch [25/30], Step [500/941], Loss: 0.0000\n",
      "Epoch [26/30], Step [500/941], Loss: 0.0000\n",
      "Epoch [27/30], Step [500/941], Loss: 0.0000\n",
      "Epoch [28/30], Step [500/941], Loss: 0.0000\n",
      "Epoch [29/30], Step [500/941], Loss: 0.0000\n",
      "Epoch [30/30], Step [500/941], Loss: 0.0000\n",
      "Test accuracy of the network: 69.74723538704582 %\n",
      "Train accuracy of the network: 99.96013818761627 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15052, 4893)\n",
      "Epoch [1/40], Step [500/941], Loss: 0.4891\n",
      "Epoch [2/40], Step [500/941], Loss: 0.4241\n",
      "Epoch [3/40], Step [500/941], Loss: 0.3268\n",
      "Epoch [4/40], Step [500/941], Loss: 0.1347\n",
      "Epoch [5/40], Step [500/941], Loss: 0.0551\n",
      "Epoch [6/40], Step [500/941], Loss: 0.0201\n",
      "Epoch [7/40], Step [500/941], Loss: 0.0199\n",
      "Epoch [8/40], Step [500/941], Loss: 0.0088\n",
      "Epoch [9/40], Step [500/941], Loss: 0.0036\n",
      "Epoch [10/40], Step [500/941], Loss: 0.0031\n",
      "Epoch [11/40], Step [500/941], Loss: 0.0043\n",
      "Epoch [12/40], Step [500/941], Loss: 0.0037\n",
      "Epoch [13/40], Step [500/941], Loss: 0.0086\n",
      "Epoch [14/40], Step [500/941], Loss: 0.0017\n",
      "Epoch [15/40], Step [500/941], Loss: 0.0020\n",
      "Epoch [16/40], Step [500/941], Loss: 0.0028\n",
      "Epoch [17/40], Step [500/941], Loss: 0.0019\n",
      "Epoch [18/40], Step [500/941], Loss: 0.0001\n",
      "Epoch [19/40], Step [500/941], Loss: 0.0002\n",
      "Epoch [20/40], Step [500/941], Loss: 0.0001\n",
      "Epoch [21/40], Step [500/941], Loss: 0.0000\n",
      "Epoch [22/40], Step [500/941], Loss: 0.0000\n",
      "Epoch [23/40], Step [500/941], Loss: 0.0000\n",
      "Epoch [24/40], Step [500/941], Loss: 0.0000\n",
      "Epoch [25/40], Step [500/941], Loss: 0.0000\n",
      "Epoch [26/40], Step [500/941], Loss: 0.0000\n",
      "Epoch [27/40], Step [500/941], Loss: 0.0000\n",
      "Epoch [28/40], Step [500/941], Loss: 0.0000\n",
      "Epoch [29/40], Step [500/941], Loss: 0.0000\n",
      "Epoch [30/40], Step [500/941], Loss: 0.0000\n",
      "Epoch [31/40], Step [500/941], Loss: 0.0095\n",
      "Epoch [32/40], Step [500/941], Loss: 0.0250\n",
      "Epoch [33/40], Step [500/941], Loss: 0.0004\n",
      "Epoch [34/40], Step [500/941], Loss: 0.0003\n",
      "Epoch [35/40], Step [500/941], Loss: 0.0002\n",
      "Epoch [36/40], Step [500/941], Loss: 0.0001\n",
      "Epoch [37/40], Step [500/941], Loss: 0.0001\n",
      "Epoch [38/40], Step [500/941], Loss: 0.0000\n",
      "Epoch [39/40], Step [500/941], Loss: 0.0000\n",
      "Epoch [40/40], Step [500/941], Loss: 0.0000\n",
      "Test accuracy of the network: 69.27330173775671 %\n",
      "Train accuracy of the network: 99.96678182301355 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15052, 4893)\n",
      "Epoch [1/50], Step [500/941], Loss: 0.4891\n",
      "Epoch [2/50], Step [500/941], Loss: 0.4241\n",
      "Epoch [3/50], Step [500/941], Loss: 0.3268\n",
      "Epoch [4/50], Step [500/941], Loss: 0.1347\n",
      "Epoch [5/50], Step [500/941], Loss: 0.0551\n",
      "Epoch [6/50], Step [500/941], Loss: 0.0201\n",
      "Epoch [7/50], Step [500/941], Loss: 0.0199\n",
      "Epoch [8/50], Step [500/941], Loss: 0.0088\n",
      "Epoch [9/50], Step [500/941], Loss: 0.0036\n",
      "Epoch [10/50], Step [500/941], Loss: 0.0031\n",
      "Epoch [11/50], Step [500/941], Loss: 0.0043\n",
      "Epoch [12/50], Step [500/941], Loss: 0.0037\n",
      "Epoch [13/50], Step [500/941], Loss: 0.0086\n",
      "Epoch [14/50], Step [500/941], Loss: 0.0017\n",
      "Epoch [15/50], Step [500/941], Loss: 0.0020\n",
      "Epoch [16/50], Step [500/941], Loss: 0.0028\n",
      "Epoch [17/50], Step [500/941], Loss: 0.0019\n",
      "Epoch [18/50], Step [500/941], Loss: 0.0001\n",
      "Epoch [19/50], Step [500/941], Loss: 0.0002\n",
      "Epoch [20/50], Step [500/941], Loss: 0.0001\n",
      "Epoch [21/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [22/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [23/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [24/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [25/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [26/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [27/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [28/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [29/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [30/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [31/50], Step [500/941], Loss: 0.0095\n",
      "Epoch [32/50], Step [500/941], Loss: 0.0250\n",
      "Epoch [33/50], Step [500/941], Loss: 0.0004\n",
      "Epoch [34/50], Step [500/941], Loss: 0.0003\n",
      "Epoch [35/50], Step [500/941], Loss: 0.0002\n",
      "Epoch [36/50], Step [500/941], Loss: 0.0001\n",
      "Epoch [37/50], Step [500/941], Loss: 0.0001\n",
      "Epoch [38/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [39/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [40/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [41/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [42/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [43/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [44/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [45/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [46/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [47/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [48/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [49/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [50/50], Step [500/941], Loss: 0.0000\n",
      "Test accuracy of the network: 69.3522906793049 %\n",
      "Train accuracy of the network: 99.98006909380813 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15052, 4893)\n",
      "Epoch [1/60], Step [500/941], Loss: 0.4891\n",
      "Epoch [2/60], Step [500/941], Loss: 0.4241\n",
      "Epoch [3/60], Step [500/941], Loss: 0.3268\n",
      "Epoch [4/60], Step [500/941], Loss: 0.1347\n",
      "Epoch [5/60], Step [500/941], Loss: 0.0551\n",
      "Epoch [6/60], Step [500/941], Loss: 0.0201\n",
      "Epoch [7/60], Step [500/941], Loss: 0.0199\n",
      "Epoch [8/60], Step [500/941], Loss: 0.0088\n",
      "Epoch [9/60], Step [500/941], Loss: 0.0036\n",
      "Epoch [10/60], Step [500/941], Loss: 0.0031\n",
      "Epoch [11/60], Step [500/941], Loss: 0.0043\n",
      "Epoch [12/60], Step [500/941], Loss: 0.0037\n",
      "Epoch [13/60], Step [500/941], Loss: 0.0086\n",
      "Epoch [14/60], Step [500/941], Loss: 0.0017\n",
      "Epoch [15/60], Step [500/941], Loss: 0.0020\n",
      "Epoch [16/60], Step [500/941], Loss: 0.0028\n",
      "Epoch [17/60], Step [500/941], Loss: 0.0019\n",
      "Epoch [18/60], Step [500/941], Loss: 0.0001\n",
      "Epoch [19/60], Step [500/941], Loss: 0.0002\n",
      "Epoch [20/60], Step [500/941], Loss: 0.0001\n",
      "Epoch [21/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [22/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [23/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [24/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [25/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [26/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [27/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [28/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [29/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [30/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [31/60], Step [500/941], Loss: 0.0095\n",
      "Epoch [32/60], Step [500/941], Loss: 0.0250\n",
      "Epoch [33/60], Step [500/941], Loss: 0.0004\n",
      "Epoch [34/60], Step [500/941], Loss: 0.0003\n",
      "Epoch [35/60], Step [500/941], Loss: 0.0002\n",
      "Epoch [36/60], Step [500/941], Loss: 0.0001\n",
      "Epoch [37/60], Step [500/941], Loss: 0.0001\n",
      "Epoch [38/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [39/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [40/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [41/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [42/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [43/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [44/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [45/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [46/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [47/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [48/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [49/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [50/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [51/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [52/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [53/60], Step [500/941], Loss: 0.0193\n",
      "Epoch [54/60], Step [500/941], Loss: 0.0001\n",
      "Epoch [55/60], Step [500/941], Loss: 0.0001\n",
      "Epoch [56/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [57/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [58/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [59/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [60/60], Step [500/941], Loss: 0.0000\n",
      "Test accuracy of the network: 68.79936808846762 %\n",
      "Train accuracy of the network: 99.98006909380813 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15052, 4893)\n",
      "Epoch [1/75], Step [500/941], Loss: 0.4891\n",
      "Epoch [2/75], Step [500/941], Loss: 0.4241\n",
      "Epoch [3/75], Step [500/941], Loss: 0.3268\n",
      "Epoch [4/75], Step [500/941], Loss: 0.1347\n",
      "Epoch [5/75], Step [500/941], Loss: 0.0551\n",
      "Epoch [6/75], Step [500/941], Loss: 0.0201\n",
      "Epoch [7/75], Step [500/941], Loss: 0.0199\n",
      "Epoch [8/75], Step [500/941], Loss: 0.0088\n",
      "Epoch [9/75], Step [500/941], Loss: 0.0036\n",
      "Epoch [10/75], Step [500/941], Loss: 0.0031\n",
      "Epoch [11/75], Step [500/941], Loss: 0.0043\n",
      "Epoch [12/75], Step [500/941], Loss: 0.0037\n",
      "Epoch [13/75], Step [500/941], Loss: 0.0086\n",
      "Epoch [14/75], Step [500/941], Loss: 0.0017\n",
      "Epoch [15/75], Step [500/941], Loss: 0.0020\n",
      "Epoch [16/75], Step [500/941], Loss: 0.0028\n",
      "Epoch [17/75], Step [500/941], Loss: 0.0019\n",
      "Epoch [18/75], Step [500/941], Loss: 0.0001\n",
      "Epoch [19/75], Step [500/941], Loss: 0.0002\n",
      "Epoch [20/75], Step [500/941], Loss: 0.0001\n",
      "Epoch [21/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [22/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [23/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [24/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [25/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [26/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [27/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [28/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [29/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [30/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [31/75], Step [500/941], Loss: 0.0095\n",
      "Epoch [32/75], Step [500/941], Loss: 0.0250\n",
      "Epoch [33/75], Step [500/941], Loss: 0.0004\n",
      "Epoch [34/75], Step [500/941], Loss: 0.0003\n",
      "Epoch [35/75], Step [500/941], Loss: 0.0002\n",
      "Epoch [36/75], Step [500/941], Loss: 0.0001\n",
      "Epoch [37/75], Step [500/941], Loss: 0.0001\n",
      "Epoch [38/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [39/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [40/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [41/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [42/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [43/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [44/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [45/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [46/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [47/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [48/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [49/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [50/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [51/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [52/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [53/75], Step [500/941], Loss: 0.0193\n",
      "Epoch [54/75], Step [500/941], Loss: 0.0001\n",
      "Epoch [55/75], Step [500/941], Loss: 0.0001\n",
      "Epoch [56/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [57/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [58/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [59/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [60/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [61/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [62/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [63/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [64/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [65/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [66/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [67/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [68/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [69/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [70/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [71/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [72/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [73/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [74/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [75/75], Step [500/941], Loss: 0.0000\n",
      "Test accuracy of the network: 69.66824644549763 %\n",
      "Train accuracy of the network: 99.98671272920542 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15052, 4893)\n",
      "Epoch [1/100], Step [500/941], Loss: 0.4891\n",
      "Epoch [2/100], Step [500/941], Loss: 0.4241\n",
      "Epoch [3/100], Step [500/941], Loss: 0.3268\n",
      "Epoch [4/100], Step [500/941], Loss: 0.1347\n",
      "Epoch [5/100], Step [500/941], Loss: 0.0551\n",
      "Epoch [6/100], Step [500/941], Loss: 0.0201\n",
      "Epoch [7/100], Step [500/941], Loss: 0.0199\n",
      "Epoch [8/100], Step [500/941], Loss: 0.0088\n",
      "Epoch [9/100], Step [500/941], Loss: 0.0036\n",
      "Epoch [10/100], Step [500/941], Loss: 0.0031\n",
      "Epoch [11/100], Step [500/941], Loss: 0.0043\n",
      "Epoch [12/100], Step [500/941], Loss: 0.0037\n",
      "Epoch [13/100], Step [500/941], Loss: 0.0086\n",
      "Epoch [14/100], Step [500/941], Loss: 0.0017\n",
      "Epoch [15/100], Step [500/941], Loss: 0.0020\n",
      "Epoch [16/100], Step [500/941], Loss: 0.0028\n",
      "Epoch [17/100], Step [500/941], Loss: 0.0019\n",
      "Epoch [18/100], Step [500/941], Loss: 0.0001\n",
      "Epoch [19/100], Step [500/941], Loss: 0.0002\n",
      "Epoch [20/100], Step [500/941], Loss: 0.0001\n",
      "Epoch [21/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [22/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [23/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [24/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [25/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [26/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [27/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [28/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [29/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [30/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [31/100], Step [500/941], Loss: 0.0095\n",
      "Epoch [32/100], Step [500/941], Loss: 0.0250\n",
      "Epoch [33/100], Step [500/941], Loss: 0.0004\n",
      "Epoch [34/100], Step [500/941], Loss: 0.0003\n",
      "Epoch [35/100], Step [500/941], Loss: 0.0002\n",
      "Epoch [36/100], Step [500/941], Loss: 0.0001\n",
      "Epoch [37/100], Step [500/941], Loss: 0.0001\n",
      "Epoch [38/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [39/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [40/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [41/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [42/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [43/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [44/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [45/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [46/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [47/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [48/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [49/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [50/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [51/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [52/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [53/100], Step [500/941], Loss: 0.0193\n",
      "Epoch [54/100], Step [500/941], Loss: 0.0001\n",
      "Epoch [55/100], Step [500/941], Loss: 0.0001\n",
      "Epoch [56/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [57/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [58/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [59/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [60/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [61/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [62/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [63/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [64/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [65/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [66/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [67/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [68/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [69/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [70/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [71/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [72/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [73/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [74/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [75/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [76/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [77/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [78/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [79/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [80/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [81/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [82/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [83/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [84/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [85/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [86/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [87/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [88/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [89/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [90/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [91/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [92/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [93/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [94/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [95/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [96/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [97/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [98/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [99/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [100/100], Step [500/941], Loss: 0.0000\n",
      "Test accuracy of the network: 69.66824644549763 %\n",
      "Train accuracy of the network: 99.98006909380813 %\n"
     ]
    }
   ],
   "source": [
    "liar_test_accuracies = []\n",
    "liar_train_accuracies = []\n",
    "\n",
    "for num_epoch in num_epochs_used:\n",
    "    test_accuracy, train_accuracy = trainAndTestSimpleModel('liar', num_epochs=num_epoch, print_epoch_mod=500)\n",
    "    liar_test_accuracies.append(test_accuracy)\n",
    "    liar_train_accuracies.append(train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "ax.plot(num_epochs_used, liar_train_accuracies, 'r-', lw=3, label='Train Accuracy')\n",
    "ax.plot(num_epochs_used, liar_test_accuracies, 'g-', lw=3, label='Test Accuracy')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15212, 4975)\n",
      "Epoch [1/1], Step [500/951], Loss: 0.6513\n",
      "Test accuracy of the network: 80.74003795066413 %\n",
      "Train accuracy of the network: 77.62950302392848 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15212, 4975)\n",
      "Epoch [1/5], Step [500/951], Loss: 0.6513\n",
      "Epoch [2/5], Step [500/951], Loss: 0.5977\n",
      "Epoch [3/5], Step [500/951], Loss: 0.3836\n",
      "Epoch [4/5], Step [500/951], Loss: 0.2220\n",
      "Epoch [5/5], Step [500/951], Loss: 0.0589\n",
      "Test accuracy of the network: 79.88614800759014 %\n",
      "Train accuracy of the network: 92.93978438075204 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15212, 4975)\n",
      "Epoch [1/10], Step [500/951], Loss: 0.6513\n",
      "Epoch [2/10], Step [500/951], Loss: 0.5977\n",
      "Epoch [3/10], Step [500/951], Loss: 0.3836\n",
      "Epoch [4/10], Step [500/951], Loss: 0.2220\n",
      "Epoch [5/10], Step [500/951], Loss: 0.0589\n",
      "Epoch [6/10], Step [500/951], Loss: 0.0261\n",
      "Epoch [7/10], Step [500/951], Loss: 0.0139\n",
      "Epoch [8/10], Step [500/951], Loss: 0.0210\n",
      "Epoch [9/10], Step [500/951], Loss: 0.0070\n",
      "Epoch [10/10], Step [500/951], Loss: 0.0077\n",
      "Test accuracy of the network: 78.17836812144212 %\n",
      "Train accuracy of the network: 98.27767551932685 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15212, 4975)\n",
      "Epoch [1/20], Step [500/951], Loss: 0.6513\n",
      "Epoch [2/20], Step [500/951], Loss: 0.5977\n",
      "Epoch [3/20], Step [500/951], Loss: 0.3836\n",
      "Epoch [4/20], Step [500/951], Loss: 0.2220\n",
      "Epoch [5/20], Step [500/951], Loss: 0.0589\n",
      "Epoch [6/20], Step [500/951], Loss: 0.0261\n",
      "Epoch [7/20], Step [500/951], Loss: 0.0139\n",
      "Epoch [8/20], Step [500/951], Loss: 0.0210\n",
      "Epoch [9/20], Step [500/951], Loss: 0.0070\n",
      "Epoch [10/20], Step [500/951], Loss: 0.0077\n",
      "Epoch [11/20], Step [500/951], Loss: 0.0067\n",
      "Epoch [12/20], Step [500/951], Loss: 0.0013\n",
      "Epoch [13/20], Step [500/951], Loss: 0.0026\n",
      "Epoch [14/20], Step [500/951], Loss: 0.0028\n",
      "Epoch [15/20], Step [500/951], Loss: 0.0065\n",
      "Epoch [16/20], Step [500/951], Loss: 0.0011\n",
      "Epoch [17/20], Step [500/951], Loss: 0.0004\n",
      "Epoch [18/20], Step [500/951], Loss: 0.0003\n",
      "Epoch [19/20], Step [500/951], Loss: 0.0001\n",
      "Epoch [20/20], Step [500/951], Loss: 0.0004\n",
      "Test accuracy of the network: 83.01707779886148 %\n",
      "Train accuracy of the network: 99.9671312122009 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15212, 4975)\n",
      "Epoch [1/30], Step [500/951], Loss: 0.6513\n",
      "Epoch [2/30], Step [500/951], Loss: 0.5977\n",
      "Epoch [3/30], Step [500/951], Loss: 0.3836\n",
      "Epoch [4/30], Step [500/951], Loss: 0.2220\n",
      "Epoch [5/30], Step [500/951], Loss: 0.0589\n",
      "Epoch [6/30], Step [500/951], Loss: 0.0261\n",
      "Epoch [7/30], Step [500/951], Loss: 0.0139\n",
      "Epoch [8/30], Step [500/951], Loss: 0.0210\n",
      "Epoch [9/30], Step [500/951], Loss: 0.0070\n",
      "Epoch [10/30], Step [500/951], Loss: 0.0077\n",
      "Epoch [11/30], Step [500/951], Loss: 0.0067\n",
      "Epoch [12/30], Step [500/951], Loss: 0.0013\n",
      "Epoch [13/30], Step [500/951], Loss: 0.0026\n",
      "Epoch [14/30], Step [500/951], Loss: 0.0028\n",
      "Epoch [15/30], Step [500/951], Loss: 0.0065\n",
      "Epoch [16/30], Step [500/951], Loss: 0.0011\n",
      "Epoch [17/30], Step [500/951], Loss: 0.0004\n",
      "Epoch [18/30], Step [500/951], Loss: 0.0003\n",
      "Epoch [19/30], Step [500/951], Loss: 0.0001\n",
      "Epoch [20/30], Step [500/951], Loss: 0.0004\n",
      "Epoch [21/30], Step [500/951], Loss: 0.0000\n",
      "Epoch [22/30], Step [500/951], Loss: 0.0001\n",
      "Epoch [23/30], Step [500/951], Loss: 0.0000\n",
      "Epoch [24/30], Step [500/951], Loss: 0.0000\n",
      "Epoch [25/30], Step [500/951], Loss: 0.0000\n",
      "Epoch [26/30], Step [500/951], Loss: 0.0000\n",
      "Epoch [27/30], Step [500/951], Loss: 0.0000\n",
      "Epoch [28/30], Step [500/951], Loss: 0.0000\n",
      "Epoch [29/30], Step [500/951], Loss: 0.0000\n",
      "Epoch [30/30], Step [500/951], Loss: 0.0000\n",
      "Test accuracy of the network: 80.92979127134726 %\n",
      "Train accuracy of the network: 99.99342624244018 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15212, 4975)\n",
      "Epoch [1/40], Step [500/951], Loss: 0.6513\n",
      "Epoch [2/40], Step [500/951], Loss: 0.5977\n",
      "Epoch [3/40], Step [500/951], Loss: 0.3836\n",
      "Epoch [4/40], Step [500/951], Loss: 0.2220\n",
      "Epoch [5/40], Step [500/951], Loss: 0.0589\n",
      "Epoch [6/40], Step [500/951], Loss: 0.0261\n",
      "Epoch [7/40], Step [500/951], Loss: 0.0139\n",
      "Epoch [8/40], Step [500/951], Loss: 0.0210\n",
      "Epoch [9/40], Step [500/951], Loss: 0.0070\n",
      "Epoch [10/40], Step [500/951], Loss: 0.0077\n",
      "Epoch [11/40], Step [500/951], Loss: 0.0067\n",
      "Epoch [12/40], Step [500/951], Loss: 0.0013\n",
      "Epoch [13/40], Step [500/951], Loss: 0.0026\n",
      "Epoch [14/40], Step [500/951], Loss: 0.0028\n",
      "Epoch [15/40], Step [500/951], Loss: 0.0065\n",
      "Epoch [16/40], Step [500/951], Loss: 0.0011\n",
      "Epoch [17/40], Step [500/951], Loss: 0.0004\n",
      "Epoch [18/40], Step [500/951], Loss: 0.0003\n",
      "Epoch [19/40], Step [500/951], Loss: 0.0001\n",
      "Epoch [20/40], Step [500/951], Loss: 0.0004\n",
      "Epoch [21/40], Step [500/951], Loss: 0.0000\n",
      "Epoch [22/40], Step [500/951], Loss: 0.0001\n",
      "Epoch [23/40], Step [500/951], Loss: 0.0000\n",
      "Epoch [24/40], Step [500/951], Loss: 0.0000\n",
      "Epoch [25/40], Step [500/951], Loss: 0.0000\n",
      "Epoch [26/40], Step [500/951], Loss: 0.0000\n",
      "Epoch [27/40], Step [500/951], Loss: 0.0000\n",
      "Epoch [28/40], Step [500/951], Loss: 0.0000\n",
      "Epoch [29/40], Step [500/951], Loss: 0.0000\n",
      "Epoch [30/40], Step [500/951], Loss: 0.0000\n",
      "Epoch [31/40], Step [500/951], Loss: 0.0000\n",
      "Epoch [32/40], Step [500/951], Loss: 0.0000\n",
      "Epoch [33/40], Step [500/951], Loss: 0.0000\n",
      "Epoch [34/40], Step [500/951], Loss: 0.0059\n",
      "Epoch [35/40], Step [500/951], Loss: 0.0002\n",
      "Epoch [36/40], Step [500/951], Loss: 0.0002\n",
      "Epoch [37/40], Step [500/951], Loss: 0.0001\n",
      "Epoch [38/40], Step [500/951], Loss: 0.0000\n",
      "Epoch [39/40], Step [500/951], Loss: 0.0000\n",
      "Epoch [40/40], Step [500/951], Loss: 0.0000\n",
      "Test accuracy of the network: 80.92979127134726 %\n",
      "Train accuracy of the network: 99.99342624244018 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15212, 4975)\n",
      "Epoch [1/50], Step [500/951], Loss: 0.6513\n",
      "Epoch [2/50], Step [500/951], Loss: 0.5977\n",
      "Epoch [3/50], Step [500/951], Loss: 0.3836\n",
      "Epoch [4/50], Step [500/951], Loss: 0.2220\n",
      "Epoch [5/50], Step [500/951], Loss: 0.0589\n",
      "Epoch [6/50], Step [500/951], Loss: 0.0261\n",
      "Epoch [7/50], Step [500/951], Loss: 0.0139\n",
      "Epoch [8/50], Step [500/951], Loss: 0.0210\n",
      "Epoch [9/50], Step [500/951], Loss: 0.0070\n",
      "Epoch [10/50], Step [500/951], Loss: 0.0077\n",
      "Epoch [11/50], Step [500/951], Loss: 0.0067\n",
      "Epoch [12/50], Step [500/951], Loss: 0.0013\n",
      "Epoch [13/50], Step [500/951], Loss: 0.0026\n",
      "Epoch [14/50], Step [500/951], Loss: 0.0028\n",
      "Epoch [15/50], Step [500/951], Loss: 0.0065\n",
      "Epoch [16/50], Step [500/951], Loss: 0.0011\n",
      "Epoch [17/50], Step [500/951], Loss: 0.0004\n",
      "Epoch [18/50], Step [500/951], Loss: 0.0003\n",
      "Epoch [19/50], Step [500/951], Loss: 0.0001\n",
      "Epoch [20/50], Step [500/951], Loss: 0.0004\n",
      "Epoch [21/50], Step [500/951], Loss: 0.0000\n",
      "Epoch [22/50], Step [500/951], Loss: 0.0001\n",
      "Epoch [23/50], Step [500/951], Loss: 0.0000\n",
      "Epoch [24/50], Step [500/951], Loss: 0.0000\n",
      "Epoch [25/50], Step [500/951], Loss: 0.0000\n",
      "Epoch [26/50], Step [500/951], Loss: 0.0000\n",
      "Epoch [27/50], Step [500/951], Loss: 0.0000\n",
      "Epoch [28/50], Step [500/951], Loss: 0.0000\n",
      "Epoch [29/50], Step [500/951], Loss: 0.0000\n",
      "Epoch [30/50], Step [500/951], Loss: 0.0000\n",
      "Epoch [31/50], Step [500/951], Loss: 0.0000\n",
      "Epoch [32/50], Step [500/951], Loss: 0.0000\n",
      "Epoch [33/50], Step [500/951], Loss: 0.0000\n",
      "Epoch [34/50], Step [500/951], Loss: 0.0059\n",
      "Epoch [35/50], Step [500/951], Loss: 0.0002\n",
      "Epoch [36/50], Step [500/951], Loss: 0.0002\n",
      "Epoch [37/50], Step [500/951], Loss: 0.0001\n",
      "Epoch [38/50], Step [500/951], Loss: 0.0000\n",
      "Epoch [39/50], Step [500/951], Loss: 0.0000\n",
      "Epoch [40/50], Step [500/951], Loss: 0.0000\n",
      "Epoch [41/50], Step [500/951], Loss: 0.0000\n",
      "Epoch [42/50], Step [500/951], Loss: 0.0000\n",
      "Epoch [43/50], Step [500/951], Loss: 0.0000\n",
      "Epoch [44/50], Step [500/951], Loss: 0.0000\n",
      "Epoch [45/50], Step [500/951], Loss: 0.0000\n",
      "Epoch [46/50], Step [500/951], Loss: 0.0000\n",
      "Epoch [47/50], Step [500/951], Loss: 0.0000\n",
      "Epoch [48/50], Step [500/951], Loss: 0.0000\n",
      "Epoch [49/50], Step [500/951], Loss: 0.0000\n",
      "Epoch [50/50], Step [500/951], Loss: 0.0000\n",
      "Test accuracy of the network: 81.49905123339659 %\n",
      "Train accuracy of the network: 100.0 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15212, 4975)\n",
      "Epoch [1/60], Step [500/951], Loss: 0.6513\n",
      "Epoch [2/60], Step [500/951], Loss: 0.5977\n",
      "Epoch [3/60], Step [500/951], Loss: 0.3836\n",
      "Epoch [4/60], Step [500/951], Loss: 0.2220\n",
      "Epoch [5/60], Step [500/951], Loss: 0.0589\n",
      "Epoch [6/60], Step [500/951], Loss: 0.0261\n",
      "Epoch [7/60], Step [500/951], Loss: 0.0139\n",
      "Epoch [8/60], Step [500/951], Loss: 0.0210\n",
      "Epoch [9/60], Step [500/951], Loss: 0.0070\n",
      "Epoch [10/60], Step [500/951], Loss: 0.0077\n",
      "Epoch [11/60], Step [500/951], Loss: 0.0067\n",
      "Epoch [12/60], Step [500/951], Loss: 0.0013\n",
      "Epoch [13/60], Step [500/951], Loss: 0.0026\n",
      "Epoch [14/60], Step [500/951], Loss: 0.0028\n",
      "Epoch [15/60], Step [500/951], Loss: 0.0065\n",
      "Epoch [16/60], Step [500/951], Loss: 0.0011\n",
      "Epoch [17/60], Step [500/951], Loss: 0.0004\n",
      "Epoch [18/60], Step [500/951], Loss: 0.0003\n",
      "Epoch [19/60], Step [500/951], Loss: 0.0001\n",
      "Epoch [20/60], Step [500/951], Loss: 0.0004\n",
      "Epoch [21/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [22/60], Step [500/951], Loss: 0.0001\n",
      "Epoch [23/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [24/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [25/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [26/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [27/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [28/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [29/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [30/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [31/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [32/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [33/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [34/60], Step [500/951], Loss: 0.0059\n",
      "Epoch [35/60], Step [500/951], Loss: 0.0002\n",
      "Epoch [36/60], Step [500/951], Loss: 0.0002\n",
      "Epoch [37/60], Step [500/951], Loss: 0.0001\n",
      "Epoch [38/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [39/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [40/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [41/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [42/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [43/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [44/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [45/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [46/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [47/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [48/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [49/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [50/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [51/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [52/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [53/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [54/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [55/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [56/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [57/60], Step [500/951], Loss: 0.0025\n",
      "Epoch [58/60], Step [500/951], Loss: 0.0012\n",
      "Epoch [59/60], Step [500/951], Loss: 0.0001\n",
      "Epoch [60/60], Step [500/951], Loss: 0.0001\n",
      "Test accuracy of the network: 79.12713472485768 %\n",
      "Train accuracy of the network: 100.0 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15212, 4975)\n",
      "Epoch [1/75], Step [500/951], Loss: 0.6513\n",
      "Epoch [2/75], Step [500/951], Loss: 0.5977\n",
      "Epoch [3/75], Step [500/951], Loss: 0.3836\n",
      "Epoch [4/75], Step [500/951], Loss: 0.2220\n",
      "Epoch [5/75], Step [500/951], Loss: 0.0589\n",
      "Epoch [6/75], Step [500/951], Loss: 0.0261\n",
      "Epoch [7/75], Step [500/951], Loss: 0.0139\n",
      "Epoch [8/75], Step [500/951], Loss: 0.0210\n",
      "Epoch [9/75], Step [500/951], Loss: 0.0070\n",
      "Epoch [10/75], Step [500/951], Loss: 0.0077\n",
      "Epoch [11/75], Step [500/951], Loss: 0.0067\n",
      "Epoch [12/75], Step [500/951], Loss: 0.0013\n",
      "Epoch [13/75], Step [500/951], Loss: 0.0026\n",
      "Epoch [14/75], Step [500/951], Loss: 0.0028\n",
      "Epoch [15/75], Step [500/951], Loss: 0.0065\n",
      "Epoch [16/75], Step [500/951], Loss: 0.0011\n",
      "Epoch [17/75], Step [500/951], Loss: 0.0004\n",
      "Epoch [18/75], Step [500/951], Loss: 0.0003\n",
      "Epoch [19/75], Step [500/951], Loss: 0.0001\n",
      "Epoch [20/75], Step [500/951], Loss: 0.0004\n",
      "Epoch [21/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [22/75], Step [500/951], Loss: 0.0001\n",
      "Epoch [23/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [24/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [25/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [26/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [27/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [28/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [29/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [30/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [31/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [32/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [33/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [34/75], Step [500/951], Loss: 0.0059\n",
      "Epoch [35/75], Step [500/951], Loss: 0.0002\n",
      "Epoch [36/75], Step [500/951], Loss: 0.0002\n",
      "Epoch [37/75], Step [500/951], Loss: 0.0001\n",
      "Epoch [38/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [39/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [40/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [41/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [42/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [43/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [44/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [45/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [46/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [47/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [48/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [49/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [50/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [51/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [52/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [53/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [54/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [55/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [56/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [57/75], Step [500/951], Loss: 0.0025\n",
      "Epoch [58/75], Step [500/951], Loss: 0.0012\n",
      "Epoch [59/75], Step [500/951], Loss: 0.0001\n",
      "Epoch [60/75], Step [500/951], Loss: 0.0001\n",
      "Epoch [61/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [62/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [63/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [64/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [65/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [66/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [67/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [68/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [69/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [70/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [71/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [72/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [73/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [74/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [75/75], Step [500/951], Loss: 0.0000\n",
      "Test accuracy of the network: 79.41176470588235 %\n",
      "Train accuracy of the network: 100.0 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15212, 4975)\n",
      "Epoch [1/100], Step [500/951], Loss: 0.6513\n",
      "Epoch [2/100], Step [500/951], Loss: 0.5977\n",
      "Epoch [3/100], Step [500/951], Loss: 0.3836\n",
      "Epoch [4/100], Step [500/951], Loss: 0.2220\n",
      "Epoch [5/100], Step [500/951], Loss: 0.0589\n",
      "Epoch [6/100], Step [500/951], Loss: 0.0261\n",
      "Epoch [7/100], Step [500/951], Loss: 0.0139\n",
      "Epoch [8/100], Step [500/951], Loss: 0.0210\n",
      "Epoch [9/100], Step [500/951], Loss: 0.0070\n",
      "Epoch [10/100], Step [500/951], Loss: 0.0077\n",
      "Epoch [11/100], Step [500/951], Loss: 0.0067\n",
      "Epoch [12/100], Step [500/951], Loss: 0.0013\n",
      "Epoch [13/100], Step [500/951], Loss: 0.0026\n",
      "Epoch [14/100], Step [500/951], Loss: 0.0028\n",
      "Epoch [15/100], Step [500/951], Loss: 0.0065\n",
      "Epoch [16/100], Step [500/951], Loss: 0.0011\n",
      "Epoch [17/100], Step [500/951], Loss: 0.0004\n",
      "Epoch [18/100], Step [500/951], Loss: 0.0003\n",
      "Epoch [19/100], Step [500/951], Loss: 0.0001\n",
      "Epoch [20/100], Step [500/951], Loss: 0.0004\n",
      "Epoch [21/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [22/100], Step [500/951], Loss: 0.0001\n",
      "Epoch [23/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [24/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [25/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [26/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [27/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [28/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [29/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [30/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [31/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [32/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [33/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [34/100], Step [500/951], Loss: 0.0059\n",
      "Epoch [35/100], Step [500/951], Loss: 0.0002\n",
      "Epoch [36/100], Step [500/951], Loss: 0.0002\n",
      "Epoch [37/100], Step [500/951], Loss: 0.0001\n",
      "Epoch [38/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [39/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [40/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [41/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [42/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [43/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [44/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [45/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [46/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [47/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [48/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [49/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [50/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [51/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [52/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [53/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [54/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [55/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [56/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [57/100], Step [500/951], Loss: 0.0025\n",
      "Epoch [58/100], Step [500/951], Loss: 0.0012\n",
      "Epoch [59/100], Step [500/951], Loss: 0.0001\n",
      "Epoch [60/100], Step [500/951], Loss: 0.0001\n",
      "Epoch [61/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [62/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [63/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [64/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [65/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [66/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [67/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [68/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [69/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [70/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [71/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [72/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [73/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [74/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [75/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [76/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [77/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [78/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [79/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [80/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [81/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [82/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [83/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [84/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [85/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [86/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [87/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [88/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [89/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [90/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [91/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [92/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [93/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [94/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [95/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [96/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [97/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [98/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [99/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [100/100], Step [500/951], Loss: 0.0000\n",
      "Test accuracy of the network: 77.41935483870968 %\n",
      "Train accuracy of the network: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "fnn_test_accuracies = []\n",
    "fnn_train_accuracies = []\n",
    "\n",
    "for num_epoch in num_epochs_used:\n",
    "    test_accuracy, train_accuracy = trainAndTestSimpleModel('fnn', num_epochs=num_epoch, print_epoch_mod=500)\n",
    "    fnn_test_accuracies.append(test_accuracy)\n",
    "    fnn_train_accuracies.append(train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "ax.plot(num_epochs_used, fnn_train_accuracies, 'r-', lw=3, label='Train Accuracy')\n",
    "ax.plot(num_epochs_used, fnn_test_accuracies, 'g-', lw=3, label='Test Accuracy')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoHiddenLayerNeuralNet(nn.Module):\n",
    "    # Feed Forward Neural Network with Two Hidden Layers that Outputs One Neuron (Binary Classification, can't handle more than 2 classes)\n",
    "\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(TwoHiddenLayerNeuralNet, self).__init__()\n",
    "        #Written based off of the tutorial at\n",
    "        #https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/01-basics/feedforward_neural_network/main.py#L37-L49\n",
    "        self.hidden1 = nn.Linear(input_size, hidden_size) \n",
    "        self.hidden2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu = nn.ReLU()   \n",
    "        self.oupt = nn.Linear(hidden_size, 1)   \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.tanh(self.hidden1(x))\n",
    "        out = torch.tanh(self.hidden2(out))\n",
    "        out = torch.sigmoid(self.oupt(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndTestTwoHiddenLayerModel(dataset: str, num_epochs = 5, learning_rate = 0.001, print_epoch_mod = 5):\n",
    "    '''    \n",
    "    used this article for help in writing the tensor parts of code so it works with the model\n",
    "    https://medium.com/analytics-vidhya/part-1-sentiment-analysis-in-pytorch-82b35edb40b8\n",
    "    \n",
    "    Train and tests, calculates both training and test accuracy, models that use TwoHiddenLayerNeuralNet.\n",
    "    '''\n",
    "    torch.manual_seed(1)\n",
    "    if dataset == 'corona':\n",
    "        X,Y = getCoronaText() #this function will give us the text array (not document term matrix) and Y\n",
    "        X_train,Y_train, vectorizer_train = getCoronaVocabulary(True)\n",
    "    elif dataset == 'liar':\n",
    "        X,Y = getLiarText()\n",
    "        X_train,Y_train, vectorizer_train = getLiarVocabulary(True)\n",
    "    elif dataset == 'fnn':\n",
    "        X,Y = getFNNText()\n",
    "        X_train,Y_train, vectorizer_train = getFNNVocabulary(True)\n",
    "    \n",
    "    #transform our testing dataset to match the vocabulary for the training dataset\n",
    "    #transform will return the document-term matrix for X based on training dataset\n",
    "    x_test = vectorizer_train.transform(X)\n",
    "\n",
    "    vocabsize = X_train.shape[1]\n",
    "    \n",
    "    \n",
    "    #transform our training and test data into tensors for the classifier to learn off of\n",
    "    X_tensor = torch.from_numpy(X_train.todense()).float()\n",
    "    Y_tensor = torch.from_numpy(np.array(Y_train)).float()\n",
    "    \n",
    "    X_test_tensor = torch.from_numpy(x_test.todense()).float()\n",
    "    Y_test_tensor = torch.from_numpy(np.array(Y))\n",
    "    \n",
    "    device = torch.device('cpu')\n",
    "    #use TensorDataset to be able to use our DataLoader\n",
    "    train_data = torch.utils.data.TensorDataset(X_tensor, Y_tensor)\n",
    "    train_loader = torch.utils.data.DataLoader(train_data,batch_size=16, shuffle=False)\n",
    "    train_loader_batch_size_1 = torch.utils.data.DataLoader(train_data,batch_size=1, shuffle=False)\n",
    "    \n",
    "    test_data = torch.utils.data.TensorDataset(X_test_tensor, Y_test_tensor)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data,batch_size=1, shuffle=False)\n",
    "    \n",
    "    #initialize our model\n",
    "    model = TwoHiddenLayerNeuralNet(vocabsize, 200).to(device)\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "    \n",
    "    \n",
    "    total_step = len(train_loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (x_batch, labels) in enumerate(train_loader):\n",
    "    \n",
    "            # Forward pass\n",
    "            # The forward process computes the loss of each iteration on each sample\n",
    "            model.train()\n",
    "            y_pred = model(x_batch)\n",
    "            loss = loss_fn(y_pred, labels.reshape(-1, 1))\n",
    "    \n",
    "            # Backward pass, using the optimizer to update the parameters\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()    #compute gradients\n",
    "            optimizer.step()   #initiate gradient descent\n",
    "    \n",
    "     \n",
    "            # Below, an epoch corresponds to one pass through all of the samples.\n",
    "            # Each training step corresponds to a parameter update using \n",
    "            # a gradient computed on a minibatch of 100 samples \n",
    "            if (i + 1) % print_epoch_mod == 0: \n",
    "                #leaving it on 5 for corona dataset, probably want to change to % 50 or % 100\n",
    "                # for the other datasets so don't get spammed \n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "    \n",
    "    # Test the model\n",
    "    # In the test phase, we don't need to compute gradients (the model has already been learned)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, label in test_loader:\n",
    "            output = model(inputs)\n",
    "            total += 1\n",
    "            if label >= 0.5 and output >= 0.5:\n",
    "                correct += 1\n",
    "            elif label < 0.5 and output < 0.5:\n",
    "                correct += 1\n",
    "            \n",
    "        print('Test accuracy of the network: {} %'.format(100 * correct / total))\n",
    "        test_accuracy = 100 * correct / total\n",
    "        \n",
    "    # Print out training accuracy\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, label in train_loader_batch_size_1:\n",
    "            output = model(inputs)\n",
    "            total += 1\n",
    "            if label >= 0.5 and output >= 0.5:\n",
    "                correct += 1\n",
    "            elif label < 0.5 and output < 0.5:\n",
    "                correct += 1\n",
    "                \n",
    "        print('Train accuracy of the network: {} %'.format(100 * correct / total))\n",
    "        train_accuracy = 100 * correct / total\n",
    "    \n",
    "    return test_accuracy, train_accuracy, model, vectorizer_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15212, 4975)\n",
      "Epoch [1/5], Step [5/951], Loss: 0.6901\n",
      "Epoch [1/5], Step [10/951], Loss: 0.6840\n",
      "Epoch [1/5], Step [15/951], Loss: 0.7481\n",
      "Epoch [1/5], Step [20/951], Loss: 0.6263\n",
      "Epoch [1/5], Step [25/951], Loss: 0.6847\n",
      "Epoch [1/5], Step [30/951], Loss: 0.6256\n",
      "Epoch [1/5], Step [35/951], Loss: 0.6297\n",
      "Epoch [1/5], Step [40/951], Loss: 0.5745\n",
      "Epoch [1/5], Step [45/951], Loss: 0.7295\n",
      "Epoch [1/5], Step [50/951], Loss: 0.6566\n",
      "Epoch [1/5], Step [55/951], Loss: 0.7160\n",
      "Epoch [1/5], Step [60/951], Loss: 0.4535\n",
      "Epoch [1/5], Step [65/951], Loss: 0.6861\n",
      "Epoch [1/5], Step [70/951], Loss: 0.5281\n",
      "Epoch [1/5], Step [75/951], Loss: 0.7352\n",
      "Epoch [1/5], Step [80/951], Loss: 0.5769\n",
      "Epoch [1/5], Step [85/951], Loss: 0.5747\n",
      "Epoch [1/5], Step [90/951], Loss: 0.6902\n",
      "Epoch [1/5], Step [95/951], Loss: 0.6953\n",
      "Epoch [1/5], Step [100/951], Loss: 0.6660\n",
      "Epoch [1/5], Step [105/951], Loss: 0.4773\n",
      "Epoch [1/5], Step [110/951], Loss: 0.8184\n",
      "Epoch [1/5], Step [115/951], Loss: 0.6768\n",
      "Epoch [1/5], Step [120/951], Loss: 0.5586\n",
      "Epoch [1/5], Step [125/951], Loss: 0.5766\n",
      "Epoch [1/5], Step [130/951], Loss: 0.5609\n",
      "Epoch [1/5], Step [135/951], Loss: 0.5855\n",
      "Epoch [1/5], Step [140/951], Loss: 0.5896\n",
      "Epoch [1/5], Step [145/951], Loss: 0.6216\n",
      "Epoch [1/5], Step [150/951], Loss: 0.6174\n",
      "Epoch [1/5], Step [155/951], Loss: 0.5979\n",
      "Epoch [1/5], Step [160/951], Loss: 0.5426\n",
      "Epoch [1/5], Step [165/951], Loss: 0.8330\n",
      "Epoch [1/5], Step [170/951], Loss: 0.5498\n",
      "Epoch [1/5], Step [175/951], Loss: 0.7103\n",
      "Epoch [1/5], Step [180/951], Loss: 0.5468\n",
      "Epoch [1/5], Step [185/951], Loss: 0.7194\n",
      "Epoch [1/5], Step [190/951], Loss: 0.6758\n",
      "Epoch [1/5], Step [195/951], Loss: 0.6533\n",
      "Epoch [1/5], Step [200/951], Loss: 0.6503\n",
      "Epoch [1/5], Step [205/951], Loss: 0.5316\n",
      "Epoch [1/5], Step [210/951], Loss: 0.7806\n",
      "Epoch [1/5], Step [215/951], Loss: 0.6570\n",
      "Epoch [1/5], Step [220/951], Loss: 0.5856\n",
      "Epoch [1/5], Step [225/951], Loss: 0.9463\n",
      "Epoch [1/5], Step [230/951], Loss: 0.7642\n",
      "Epoch [1/5], Step [235/951], Loss: 0.5392\n",
      "Epoch [1/5], Step [240/951], Loss: 0.6211\n",
      "Epoch [1/5], Step [245/951], Loss: 0.6019\n",
      "Epoch [1/5], Step [250/951], Loss: 0.6222\n",
      "Epoch [1/5], Step [255/951], Loss: 0.6124\n",
      "Epoch [1/5], Step [260/951], Loss: 0.6119\n",
      "Epoch [1/5], Step [265/951], Loss: 0.6190\n",
      "Epoch [1/5], Step [270/951], Loss: 0.5388\n",
      "Epoch [1/5], Step [275/951], Loss: 0.6017\n",
      "Epoch [1/5], Step [280/951], Loss: 0.5603\n",
      "Epoch [1/5], Step [285/951], Loss: 0.8504\n",
      "Epoch [1/5], Step [290/951], Loss: 0.6355\n",
      "Epoch [1/5], Step [295/951], Loss: 0.5063\n",
      "Epoch [1/5], Step [300/951], Loss: 0.5011\n",
      "Epoch [1/5], Step [305/951], Loss: 0.4910\n",
      "Epoch [1/5], Step [310/951], Loss: 0.6235\n",
      "Epoch [1/5], Step [315/951], Loss: 0.5466\n",
      "Epoch [1/5], Step [320/951], Loss: 0.6826\n",
      "Epoch [1/5], Step [325/951], Loss: 0.6686\n",
      "Epoch [1/5], Step [330/951], Loss: 0.8386\n",
      "Epoch [1/5], Step [335/951], Loss: 0.4303\n",
      "Epoch [1/5], Step [340/951], Loss: 0.6846\n",
      "Epoch [1/5], Step [345/951], Loss: 0.6371\n",
      "Epoch [1/5], Step [350/951], Loss: 0.5760\n",
      "Epoch [1/5], Step [355/951], Loss: 0.5784\n",
      "Epoch [1/5], Step [360/951], Loss: 0.4817\n",
      "Epoch [1/5], Step [365/951], Loss: 0.5026\n",
      "Epoch [1/5], Step [370/951], Loss: 0.5750\n",
      "Epoch [1/5], Step [375/951], Loss: 0.6852\n",
      "Epoch [1/5], Step [380/951], Loss: 0.6345\n",
      "Epoch [1/5], Step [385/951], Loss: 0.6093\n",
      "Epoch [1/5], Step [390/951], Loss: 0.5461\n",
      "Epoch [1/5], Step [395/951], Loss: 0.4763\n",
      "Epoch [1/5], Step [400/951], Loss: 0.5365\n",
      "Epoch [1/5], Step [405/951], Loss: 0.6781\n",
      "Epoch [1/5], Step [410/951], Loss: 0.4482\n",
      "Epoch [1/5], Step [415/951], Loss: 0.5416\n",
      "Epoch [1/5], Step [420/951], Loss: 0.5531\n",
      "Epoch [1/5], Step [425/951], Loss: 0.6428\n",
      "Epoch [1/5], Step [430/951], Loss: 0.4516\n",
      "Epoch [1/5], Step [435/951], Loss: 0.4518\n",
      "Epoch [1/5], Step [440/951], Loss: 0.4415\n",
      "Epoch [1/5], Step [445/951], Loss: 0.5311\n",
      "Epoch [1/5], Step [450/951], Loss: 0.5289\n",
      "Epoch [1/5], Step [455/951], Loss: 0.4358\n",
      "Epoch [1/5], Step [460/951], Loss: 0.5412\n",
      "Epoch [1/5], Step [465/951], Loss: 0.5388\n",
      "Epoch [1/5], Step [470/951], Loss: 0.6530\n",
      "Epoch [1/5], Step [475/951], Loss: 0.4977\n",
      "Epoch [1/5], Step [480/951], Loss: 0.7188\n",
      "Epoch [1/5], Step [485/951], Loss: 0.6023\n",
      "Epoch [1/5], Step [490/951], Loss: 0.6054\n",
      "Epoch [1/5], Step [495/951], Loss: 0.5457\n",
      "Epoch [1/5], Step [500/951], Loss: 0.6391\n",
      "Epoch [1/5], Step [505/951], Loss: 0.6094\n",
      "Epoch [1/5], Step [510/951], Loss: 0.4700\n",
      "Epoch [1/5], Step [515/951], Loss: 0.6251\n",
      "Epoch [1/5], Step [520/951], Loss: 0.6394\n",
      "Epoch [1/5], Step [525/951], Loss: 0.5482\n",
      "Epoch [1/5], Step [530/951], Loss: 0.5951\n",
      "Epoch [1/5], Step [535/951], Loss: 0.4994\n",
      "Epoch [1/5], Step [540/951], Loss: 0.6288\n",
      "Epoch [1/5], Step [545/951], Loss: 0.7064\n",
      "Epoch [1/5], Step [550/951], Loss: 0.5924\n",
      "Epoch [1/5], Step [555/951], Loss: 0.6187\n",
      "Epoch [1/5], Step [560/951], Loss: 0.5944\n",
      "Epoch [1/5], Step [565/951], Loss: 0.5560\n",
      "Epoch [1/5], Step [570/951], Loss: 0.4936\n",
      "Epoch [1/5], Step [575/951], Loss: 0.5935\n",
      "Epoch [1/5], Step [580/951], Loss: 0.6242\n",
      "Epoch [1/5], Step [585/951], Loss: 0.5806\n",
      "Epoch [1/5], Step [590/951], Loss: 0.5069\n",
      "Epoch [1/5], Step [595/951], Loss: 0.6027\n",
      "Epoch [1/5], Step [600/951], Loss: 0.6886\n",
      "Epoch [1/5], Step [605/951], Loss: 0.5742\n",
      "Epoch [1/5], Step [610/951], Loss: 0.5481\n",
      "Epoch [1/5], Step [615/951], Loss: 0.4892\n",
      "Epoch [1/5], Step [620/951], Loss: 0.5340\n",
      "Epoch [1/5], Step [625/951], Loss: 0.5671\n",
      "Epoch [1/5], Step [630/951], Loss: 0.5657\n",
      "Epoch [1/5], Step [635/951], Loss: 0.7000\n",
      "Epoch [1/5], Step [640/951], Loss: 0.4974\n",
      "Epoch [1/5], Step [645/951], Loss: 0.6359\n",
      "Epoch [1/5], Step [650/951], Loss: 0.6229\n",
      "Epoch [1/5], Step [655/951], Loss: 0.6819\n",
      "Epoch [1/5], Step [660/951], Loss: 0.4948\n",
      "Epoch [1/5], Step [665/951], Loss: 0.5902\n",
      "Epoch [1/5], Step [670/951], Loss: 0.6677\n",
      "Epoch [1/5], Step [675/951], Loss: 0.4818\n",
      "Epoch [1/5], Step [680/951], Loss: 0.6033\n",
      "Epoch [1/5], Step [685/951], Loss: 0.5914\n",
      "Epoch [1/5], Step [690/951], Loss: 0.5290\n",
      "Epoch [1/5], Step [695/951], Loss: 0.5086\n",
      "Epoch [1/5], Step [700/951], Loss: 0.7653\n",
      "Epoch [1/5], Step [705/951], Loss: 0.6585\n",
      "Epoch [1/5], Step [710/951], Loss: 0.5747\n",
      "Epoch [1/5], Step [715/951], Loss: 0.6667\n",
      "Epoch [1/5], Step [720/951], Loss: 0.4913\n",
      "Epoch [1/5], Step [725/951], Loss: 0.6719\n",
      "Epoch [1/5], Step [730/951], Loss: 0.4602\n",
      "Epoch [1/5], Step [735/951], Loss: 0.6654\n",
      "Epoch [1/5], Step [740/951], Loss: 0.8236\n",
      "Epoch [1/5], Step [745/951], Loss: 0.7967\n",
      "Epoch [1/5], Step [750/951], Loss: 0.6142\n",
      "Epoch [1/5], Step [755/951], Loss: 0.6084\n",
      "Epoch [1/5], Step [760/951], Loss: 0.5825\n",
      "Epoch [1/5], Step [765/951], Loss: 0.5493\n",
      "Epoch [1/5], Step [770/951], Loss: 0.5561\n",
      "Epoch [1/5], Step [775/951], Loss: 0.5516\n",
      "Epoch [1/5], Step [780/951], Loss: 0.5628\n",
      "Epoch [1/5], Step [785/951], Loss: 0.8811\n",
      "Epoch [1/5], Step [790/951], Loss: 0.7507\n",
      "Epoch [1/5], Step [795/951], Loss: 0.7230\n",
      "Epoch [1/5], Step [800/951], Loss: 0.3160\n",
      "Epoch [1/5], Step [805/951], Loss: 0.5783\n",
      "Epoch [1/5], Step [810/951], Loss: 0.5679\n",
      "Epoch [1/5], Step [815/951], Loss: 0.5028\n",
      "Epoch [1/5], Step [820/951], Loss: 0.5892\n",
      "Epoch [1/5], Step [825/951], Loss: 0.4592\n",
      "Epoch [1/5], Step [830/951], Loss: 0.4578\n",
      "Epoch [1/5], Step [835/951], Loss: 0.7440\n",
      "Epoch [1/5], Step [840/951], Loss: 0.4589\n",
      "Epoch [1/5], Step [845/951], Loss: 0.4094\n",
      "Epoch [1/5], Step [850/951], Loss: 0.4678\n",
      "Epoch [1/5], Step [855/951], Loss: 0.6669\n",
      "Epoch [1/5], Step [860/951], Loss: 0.5806\n",
      "Epoch [1/5], Step [865/951], Loss: 0.6524\n",
      "Epoch [1/5], Step [870/951], Loss: 0.5593\n",
      "Epoch [1/5], Step [875/951], Loss: 0.5126\n",
      "Epoch [1/5], Step [880/951], Loss: 0.4974\n",
      "Epoch [1/5], Step [885/951], Loss: 0.4575\n",
      "Epoch [1/5], Step [890/951], Loss: 0.7005\n",
      "Epoch [1/5], Step [895/951], Loss: 0.4953\n",
      "Epoch [1/5], Step [900/951], Loss: 0.5096\n",
      "Epoch [1/5], Step [905/951], Loss: 0.4801\n",
      "Epoch [1/5], Step [910/951], Loss: 0.4430\n",
      "Epoch [1/5], Step [915/951], Loss: 0.8647\n",
      "Epoch [1/5], Step [920/951], Loss: 0.5553\n",
      "Epoch [1/5], Step [925/951], Loss: 0.5391\n",
      "Epoch [1/5], Step [930/951], Loss: 0.4363\n",
      "Epoch [1/5], Step [935/951], Loss: 0.5643\n",
      "Epoch [1/5], Step [940/951], Loss: 0.5996\n",
      "Epoch [1/5], Step [945/951], Loss: 0.6122\n",
      "Epoch [1/5], Step [950/951], Loss: 0.7109\n",
      "Epoch [2/5], Step [5/951], Loss: 0.7208\n",
      "Epoch [2/5], Step [10/951], Loss: 0.3222\n",
      "Epoch [2/5], Step [15/951], Loss: 0.4300\n",
      "Epoch [2/5], Step [20/951], Loss: 0.5669\n",
      "Epoch [2/5], Step [25/951], Loss: 0.4874\n",
      "Epoch [2/5], Step [30/951], Loss: 0.4889\n",
      "Epoch [2/5], Step [35/951], Loss: 0.4910\n",
      "Epoch [2/5], Step [40/951], Loss: 0.3216\n",
      "Epoch [2/5], Step [45/951], Loss: 0.5472\n",
      "Epoch [2/5], Step [50/951], Loss: 0.4627\n",
      "Epoch [2/5], Step [55/951], Loss: 0.3469\n",
      "Epoch [2/5], Step [60/951], Loss: 0.2574\n",
      "Epoch [2/5], Step [65/951], Loss: 0.5368\n",
      "Epoch [2/5], Step [70/951], Loss: 0.2306\n",
      "Epoch [2/5], Step [75/951], Loss: 0.6722\n",
      "Epoch [2/5], Step [80/951], Loss: 0.4621\n",
      "Epoch [2/5], Step [85/951], Loss: 0.5599\n",
      "Epoch [2/5], Step [90/951], Loss: 0.4938\n",
      "Epoch [2/5], Step [95/951], Loss: 0.8733\n",
      "Epoch [2/5], Step [100/951], Loss: 0.5153\n",
      "Epoch [2/5], Step [105/951], Loss: 0.4081\n",
      "Epoch [2/5], Step [110/951], Loss: 0.8327\n",
      "Epoch [2/5], Step [115/951], Loss: 0.4415\n",
      "Epoch [2/5], Step [120/951], Loss: 0.4340\n",
      "Epoch [2/5], Step [125/951], Loss: 0.6482\n",
      "Epoch [2/5], Step [130/951], Loss: 0.3811\n",
      "Epoch [2/5], Step [135/951], Loss: 0.4240\n",
      "Epoch [2/5], Step [140/951], Loss: 0.3483\n",
      "Epoch [2/5], Step [145/951], Loss: 0.3005\n",
      "Epoch [2/5], Step [150/951], Loss: 0.5004\n",
      "Epoch [2/5], Step [155/951], Loss: 0.4908\n",
      "Epoch [2/5], Step [160/951], Loss: 0.5272\n",
      "Epoch [2/5], Step [165/951], Loss: 0.5185\n",
      "Epoch [2/5], Step [170/951], Loss: 0.3013\n",
      "Epoch [2/5], Step [175/951], Loss: 0.6142\n",
      "Epoch [2/5], Step [180/951], Loss: 0.3842\n",
      "Epoch [2/5], Step [185/951], Loss: 0.4722\n",
      "Epoch [2/5], Step [190/951], Loss: 0.3700\n",
      "Epoch [2/5], Step [195/951], Loss: 0.4989\n",
      "Epoch [2/5], Step [200/951], Loss: 0.5544\n",
      "Epoch [2/5], Step [205/951], Loss: 0.5179\n",
      "Epoch [2/5], Step [210/951], Loss: 0.6509\n",
      "Epoch [2/5], Step [215/951], Loss: 0.6681\n",
      "Epoch [2/5], Step [220/951], Loss: 0.4571\n",
      "Epoch [2/5], Step [225/951], Loss: 0.8692\n",
      "Epoch [2/5], Step [230/951], Loss: 0.6836\n",
      "Epoch [2/5], Step [235/951], Loss: 0.4630\n",
      "Epoch [2/5], Step [240/951], Loss: 0.4436\n",
      "Epoch [2/5], Step [245/951], Loss: 0.4020\n",
      "Epoch [2/5], Step [250/951], Loss: 0.4631\n",
      "Epoch [2/5], Step [255/951], Loss: 0.4613\n",
      "Epoch [2/5], Step [260/951], Loss: 0.4812\n",
      "Epoch [2/5], Step [265/951], Loss: 0.5030\n",
      "Epoch [2/5], Step [270/951], Loss: 0.3668\n",
      "Epoch [2/5], Step [275/951], Loss: 0.4130\n",
      "Epoch [2/5], Step [280/951], Loss: 0.4486\n",
      "Epoch [2/5], Step [285/951], Loss: 0.8319\n",
      "Epoch [2/5], Step [290/951], Loss: 0.4666\n",
      "Epoch [2/5], Step [295/951], Loss: 0.3710\n",
      "Epoch [2/5], Step [300/951], Loss: 0.2970\n",
      "Epoch [2/5], Step [305/951], Loss: 0.3218\n",
      "Epoch [2/5], Step [310/951], Loss: 0.3133\n",
      "Epoch [2/5], Step [315/951], Loss: 0.3449\n",
      "Epoch [2/5], Step [320/951], Loss: 0.3696\n",
      "Epoch [2/5], Step [325/951], Loss: 0.6018\n",
      "Epoch [2/5], Step [330/951], Loss: 0.8207\n",
      "Epoch [2/5], Step [335/951], Loss: 0.1680\n",
      "Epoch [2/5], Step [340/951], Loss: 0.5128\n",
      "Epoch [2/5], Step [345/951], Loss: 0.4750\n",
      "Epoch [2/5], Step [350/951], Loss: 0.3278\n",
      "Epoch [2/5], Step [355/951], Loss: 0.3370\n",
      "Epoch [2/5], Step [360/951], Loss: 0.3237\n",
      "Epoch [2/5], Step [365/951], Loss: 0.4605\n",
      "Epoch [2/5], Step [370/951], Loss: 0.4932\n",
      "Epoch [2/5], Step [375/951], Loss: 0.4876\n",
      "Epoch [2/5], Step [380/951], Loss: 0.4225\n",
      "Epoch [2/5], Step [385/951], Loss: 0.5515\n",
      "Epoch [2/5], Step [390/951], Loss: 0.3490\n",
      "Epoch [2/5], Step [395/951], Loss: 0.3287\n",
      "Epoch [2/5], Step [400/951], Loss: 0.3355\n",
      "Epoch [2/5], Step [405/951], Loss: 0.7199\n",
      "Epoch [2/5], Step [410/951], Loss: 0.3487\n",
      "Epoch [2/5], Step [415/951], Loss: 0.3444\n",
      "Epoch [2/5], Step [420/951], Loss: 0.4648\n",
      "Epoch [2/5], Step [425/951], Loss: 0.3857\n",
      "Epoch [2/5], Step [430/951], Loss: 0.3568\n",
      "Epoch [2/5], Step [435/951], Loss: 0.3459\n",
      "Epoch [2/5], Step [440/951], Loss: 0.2949\n",
      "Epoch [2/5], Step [445/951], Loss: 0.5760\n",
      "Epoch [2/5], Step [450/951], Loss: 0.4403\n",
      "Epoch [2/5], Step [455/951], Loss: 0.2731\n",
      "Epoch [2/5], Step [460/951], Loss: 0.4128\n",
      "Epoch [2/5], Step [465/951], Loss: 0.5707\n",
      "Epoch [2/5], Step [470/951], Loss: 0.6037\n",
      "Epoch [2/5], Step [475/951], Loss: 0.4230\n",
      "Epoch [2/5], Step [480/951], Loss: 0.5292\n",
      "Epoch [2/5], Step [485/951], Loss: 0.4747\n",
      "Epoch [2/5], Step [490/951], Loss: 0.3855\n",
      "Epoch [2/5], Step [495/951], Loss: 0.4050\n",
      "Epoch [2/5], Step [500/951], Loss: 0.5884\n",
      "Epoch [2/5], Step [505/951], Loss: 0.4721\n",
      "Epoch [2/5], Step [510/951], Loss: 0.3536\n",
      "Epoch [2/5], Step [515/951], Loss: 0.5227\n",
      "Epoch [2/5], Step [520/951], Loss: 0.5421\n",
      "Epoch [2/5], Step [525/951], Loss: 0.3446\n",
      "Epoch [2/5], Step [530/951], Loss: 0.4080\n",
      "Epoch [2/5], Step [535/951], Loss: 0.4370\n",
      "Epoch [2/5], Step [540/951], Loss: 0.5250\n",
      "Epoch [2/5], Step [545/951], Loss: 0.6365\n",
      "Epoch [2/5], Step [550/951], Loss: 0.4147\n",
      "Epoch [2/5], Step [555/951], Loss: 0.5676\n",
      "Epoch [2/5], Step [560/951], Loss: 0.4640\n",
      "Epoch [2/5], Step [565/951], Loss: 0.4874\n",
      "Epoch [2/5], Step [570/951], Loss: 0.4108\n",
      "Epoch [2/5], Step [575/951], Loss: 0.4872\n",
      "Epoch [2/5], Step [580/951], Loss: 0.5946\n",
      "Epoch [2/5], Step [585/951], Loss: 0.4235\n",
      "Epoch [2/5], Step [590/951], Loss: 0.4767\n",
      "Epoch [2/5], Step [595/951], Loss: 0.5076\n",
      "Epoch [2/5], Step [600/951], Loss: 0.5918\n",
      "Epoch [2/5], Step [605/951], Loss: 0.5611\n",
      "Epoch [2/5], Step [610/951], Loss: 0.4899\n",
      "Epoch [2/5], Step [615/951], Loss: 0.4266\n",
      "Epoch [2/5], Step [620/951], Loss: 0.3766\n",
      "Epoch [2/5], Step [625/951], Loss: 0.4919\n",
      "Epoch [2/5], Step [630/951], Loss: 0.4503\n",
      "Epoch [2/5], Step [635/951], Loss: 0.4487\n",
      "Epoch [2/5], Step [640/951], Loss: 0.3714\n",
      "Epoch [2/5], Step [645/951], Loss: 0.4267\n",
      "Epoch [2/5], Step [650/951], Loss: 0.4668\n",
      "Epoch [2/5], Step [655/951], Loss: 0.5680\n",
      "Epoch [2/5], Step [660/951], Loss: 0.2808\n",
      "Epoch [2/5], Step [665/951], Loss: 0.5544\n",
      "Epoch [2/5], Step [670/951], Loss: 0.6154\n",
      "Epoch [2/5], Step [675/951], Loss: 0.3620\n",
      "Epoch [2/5], Step [680/951], Loss: 0.4666\n",
      "Epoch [2/5], Step [685/951], Loss: 0.4649\n",
      "Epoch [2/5], Step [690/951], Loss: 0.3415\n",
      "Epoch [2/5], Step [695/951], Loss: 0.3660\n",
      "Epoch [2/5], Step [700/951], Loss: 0.5861\n",
      "Epoch [2/5], Step [705/951], Loss: 0.4815\n",
      "Epoch [2/5], Step [710/951], Loss: 0.4171\n",
      "Epoch [2/5], Step [715/951], Loss: 0.5071\n",
      "Epoch [2/5], Step [720/951], Loss: 0.2622\n",
      "Epoch [2/5], Step [725/951], Loss: 0.6782\n",
      "Epoch [2/5], Step [730/951], Loss: 0.2975\n",
      "Epoch [2/5], Step [735/951], Loss: 0.6056\n",
      "Epoch [2/5], Step [740/951], Loss: 0.8019\n",
      "Epoch [2/5], Step [745/951], Loss: 0.5882\n",
      "Epoch [2/5], Step [750/951], Loss: 0.5228\n",
      "Epoch [2/5], Step [755/951], Loss: 0.5142\n",
      "Epoch [2/5], Step [760/951], Loss: 0.4377\n",
      "Epoch [2/5], Step [765/951], Loss: 0.4134\n",
      "Epoch [2/5], Step [770/951], Loss: 0.4652\n",
      "Epoch [2/5], Step [775/951], Loss: 0.2305\n",
      "Epoch [2/5], Step [780/951], Loss: 0.2032\n",
      "Epoch [2/5], Step [785/951], Loss: 0.7122\n",
      "Epoch [2/5], Step [790/951], Loss: 0.6071\n",
      "Epoch [2/5], Step [795/951], Loss: 0.7471\n",
      "Epoch [2/5], Step [800/951], Loss: 0.2150\n",
      "Epoch [2/5], Step [805/951], Loss: 0.5511\n",
      "Epoch [2/5], Step [810/951], Loss: 0.5669\n",
      "Epoch [2/5], Step [815/951], Loss: 0.3557\n",
      "Epoch [2/5], Step [820/951], Loss: 0.4527\n",
      "Epoch [2/5], Step [825/951], Loss: 0.3512\n",
      "Epoch [2/5], Step [830/951], Loss: 0.3225\n",
      "Epoch [2/5], Step [835/951], Loss: 0.5218\n",
      "Epoch [2/5], Step [840/951], Loss: 0.2811\n",
      "Epoch [2/5], Step [845/951], Loss: 0.2319\n",
      "Epoch [2/5], Step [850/951], Loss: 0.3122\n",
      "Epoch [2/5], Step [855/951], Loss: 0.4100\n",
      "Epoch [2/5], Step [860/951], Loss: 0.4334\n",
      "Epoch [2/5], Step [865/951], Loss: 0.5908\n",
      "Epoch [2/5], Step [870/951], Loss: 0.4256\n",
      "Epoch [2/5], Step [875/951], Loss: 0.4392\n",
      "Epoch [2/5], Step [880/951], Loss: 0.3598\n",
      "Epoch [2/5], Step [885/951], Loss: 0.2701\n",
      "Epoch [2/5], Step [890/951], Loss: 0.5915\n",
      "Epoch [2/5], Step [895/951], Loss: 0.4130\n",
      "Epoch [2/5], Step [900/951], Loss: 0.3878\n",
      "Epoch [2/5], Step [905/951], Loss: 0.2819\n",
      "Epoch [2/5], Step [910/951], Loss: 0.4130\n",
      "Epoch [2/5], Step [915/951], Loss: 0.8020\n",
      "Epoch [2/5], Step [920/951], Loss: 0.4281\n",
      "Epoch [2/5], Step [925/951], Loss: 0.3876\n",
      "Epoch [2/5], Step [930/951], Loss: 0.3121\n",
      "Epoch [2/5], Step [935/951], Loss: 0.3400\n",
      "Epoch [2/5], Step [940/951], Loss: 0.2545\n",
      "Epoch [2/5], Step [945/951], Loss: 0.3997\n",
      "Epoch [2/5], Step [950/951], Loss: 0.5949\n",
      "Epoch [3/5], Step [5/951], Loss: 0.6717\n",
      "Epoch [3/5], Step [10/951], Loss: 0.2101\n",
      "Epoch [3/5], Step [15/951], Loss: 0.3393\n",
      "Epoch [3/5], Step [20/951], Loss: 0.3366\n",
      "Epoch [3/5], Step [25/951], Loss: 0.4611\n",
      "Epoch [3/5], Step [30/951], Loss: 0.2950\n",
      "Epoch [3/5], Step [35/951], Loss: 0.3077\n",
      "Epoch [3/5], Step [40/951], Loss: 0.3450\n",
      "Epoch [3/5], Step [45/951], Loss: 0.3895\n",
      "Epoch [3/5], Step [50/951], Loss: 0.1713\n",
      "Epoch [3/5], Step [55/951], Loss: 0.2471\n",
      "Epoch [3/5], Step [60/951], Loss: 0.2107\n",
      "Epoch [3/5], Step [65/951], Loss: 0.3075\n",
      "Epoch [3/5], Step [70/951], Loss: 0.0936\n",
      "Epoch [3/5], Step [75/951], Loss: 0.2210\n",
      "Epoch [3/5], Step [80/951], Loss: 0.0746\n",
      "Epoch [3/5], Step [85/951], Loss: 0.3191\n",
      "Epoch [3/5], Step [90/951], Loss: 0.2471\n",
      "Epoch [3/5], Step [95/951], Loss: 0.5779\n",
      "Epoch [3/5], Step [100/951], Loss: 0.4463\n",
      "Epoch [3/5], Step [105/951], Loss: 0.1503\n",
      "Epoch [3/5], Step [110/951], Loss: 0.8896\n",
      "Epoch [3/5], Step [115/951], Loss: 0.3243\n",
      "Epoch [3/5], Step [120/951], Loss: 0.3320\n",
      "Epoch [3/5], Step [125/951], Loss: 0.3948\n",
      "Epoch [3/5], Step [130/951], Loss: 0.3271\n",
      "Epoch [3/5], Step [135/951], Loss: 0.1265\n",
      "Epoch [3/5], Step [140/951], Loss: 0.1775\n",
      "Epoch [3/5], Step [145/951], Loss: 0.1178\n",
      "Epoch [3/5], Step [150/951], Loss: 0.3427\n",
      "Epoch [3/5], Step [155/951], Loss: 0.3778\n",
      "Epoch [3/5], Step [160/951], Loss: 0.4288\n",
      "Epoch [3/5], Step [165/951], Loss: 0.2431\n",
      "Epoch [3/5], Step [170/951], Loss: 0.1671\n",
      "Epoch [3/5], Step [175/951], Loss: 0.2868\n",
      "Epoch [3/5], Step [180/951], Loss: 0.2253\n",
      "Epoch [3/5], Step [185/951], Loss: 0.2587\n",
      "Epoch [3/5], Step [190/951], Loss: 0.2331\n",
      "Epoch [3/5], Step [195/951], Loss: 0.1301\n",
      "Epoch [3/5], Step [200/951], Loss: 0.3295\n",
      "Epoch [3/5], Step [205/951], Loss: 0.1754\n",
      "Epoch [3/5], Step [210/951], Loss: 0.4202\n",
      "Epoch [3/5], Step [215/951], Loss: 0.4827\n",
      "Epoch [3/5], Step [220/951], Loss: 0.2825\n",
      "Epoch [3/5], Step [225/951], Loss: 0.5701\n",
      "Epoch [3/5], Step [230/951], Loss: 0.5222\n",
      "Epoch [3/5], Step [235/951], Loss: 0.2930\n",
      "Epoch [3/5], Step [240/951], Loss: 0.2333\n",
      "Epoch [3/5], Step [245/951], Loss: 0.1875\n",
      "Epoch [3/5], Step [250/951], Loss: 0.3219\n",
      "Epoch [3/5], Step [255/951], Loss: 0.3276\n",
      "Epoch [3/5], Step [260/951], Loss: 0.2510\n",
      "Epoch [3/5], Step [265/951], Loss: 0.4310\n",
      "Epoch [3/5], Step [270/951], Loss: 0.1290\n",
      "Epoch [3/5], Step [275/951], Loss: 0.2949\n",
      "Epoch [3/5], Step [280/951], Loss: 0.2666\n",
      "Epoch [3/5], Step [285/951], Loss: 0.3903\n",
      "Epoch [3/5], Step [290/951], Loss: 0.3733\n",
      "Epoch [3/5], Step [295/951], Loss: 0.1816\n",
      "Epoch [3/5], Step [300/951], Loss: 0.2917\n",
      "Epoch [3/5], Step [305/951], Loss: 0.3063\n",
      "Epoch [3/5], Step [310/951], Loss: 0.2096\n",
      "Epoch [3/5], Step [315/951], Loss: 0.1842\n",
      "Epoch [3/5], Step [320/951], Loss: 0.1942\n",
      "Epoch [3/5], Step [325/951], Loss: 0.2653\n",
      "Epoch [3/5], Step [330/951], Loss: 0.4619\n",
      "Epoch [3/5], Step [335/951], Loss: 0.1234\n",
      "Epoch [3/5], Step [340/951], Loss: 0.3408\n",
      "Epoch [3/5], Step [345/951], Loss: 0.3499\n",
      "Epoch [3/5], Step [350/951], Loss: 0.2638\n",
      "Epoch [3/5], Step [355/951], Loss: 0.1350\n",
      "Epoch [3/5], Step [360/951], Loss: 0.1781\n",
      "Epoch [3/5], Step [365/951], Loss: 0.2898\n",
      "Epoch [3/5], Step [370/951], Loss: 0.3765\n",
      "Epoch [3/5], Step [375/951], Loss: 0.3098\n",
      "Epoch [3/5], Step [380/951], Loss: 0.2091\n",
      "Epoch [3/5], Step [385/951], Loss: 0.4583\n",
      "Epoch [3/5], Step [390/951], Loss: 0.2041\n",
      "Epoch [3/5], Step [395/951], Loss: 0.2238\n",
      "Epoch [3/5], Step [400/951], Loss: 0.1160\n",
      "Epoch [3/5], Step [405/951], Loss: 0.7103\n",
      "Epoch [3/5], Step [410/951], Loss: 0.0919\n",
      "Epoch [3/5], Step [415/951], Loss: 0.1883\n",
      "Epoch [3/5], Step [420/951], Loss: 0.3337\n",
      "Epoch [3/5], Step [425/951], Loss: 0.3114\n",
      "Epoch [3/5], Step [430/951], Loss: 0.2440\n",
      "Epoch [3/5], Step [435/951], Loss: 0.2917\n",
      "Epoch [3/5], Step [440/951], Loss: 0.1484\n",
      "Epoch [3/5], Step [445/951], Loss: 0.2247\n",
      "Epoch [3/5], Step [450/951], Loss: 0.1428\n",
      "Epoch [3/5], Step [455/951], Loss: 0.0814\n",
      "Epoch [3/5], Step [460/951], Loss: 0.3369\n",
      "Epoch [3/5], Step [465/951], Loss: 0.1985\n",
      "Epoch [3/5], Step [470/951], Loss: 0.4368\n",
      "Epoch [3/5], Step [475/951], Loss: 0.3220\n",
      "Epoch [3/5], Step [480/951], Loss: 0.4030\n",
      "Epoch [3/5], Step [485/951], Loss: 0.3663\n",
      "Epoch [3/5], Step [490/951], Loss: 0.1073\n",
      "Epoch [3/5], Step [495/951], Loss: 0.2103\n",
      "Epoch [3/5], Step [500/951], Loss: 0.3055\n",
      "Epoch [3/5], Step [505/951], Loss: 0.2029\n",
      "Epoch [3/5], Step [510/951], Loss: 0.1769\n",
      "Epoch [3/5], Step [515/951], Loss: 0.3395\n",
      "Epoch [3/5], Step [520/951], Loss: 0.2505\n",
      "Epoch [3/5], Step [525/951], Loss: 0.1798\n",
      "Epoch [3/5], Step [530/951], Loss: 0.1740\n",
      "Epoch [3/5], Step [535/951], Loss: 0.1709\n",
      "Epoch [3/5], Step [540/951], Loss: 0.1553\n",
      "Epoch [3/5], Step [545/951], Loss: 0.4044\n",
      "Epoch [3/5], Step [550/951], Loss: 0.3020\n",
      "Epoch [3/5], Step [555/951], Loss: 0.5270\n",
      "Epoch [3/5], Step [560/951], Loss: 0.3185\n",
      "Epoch [3/5], Step [565/951], Loss: 0.3493\n",
      "Epoch [3/5], Step [570/951], Loss: 0.2468\n",
      "Epoch [3/5], Step [575/951], Loss: 0.4167\n",
      "Epoch [3/5], Step [580/951], Loss: 0.6568\n",
      "Epoch [3/5], Step [585/951], Loss: 0.3279\n",
      "Epoch [3/5], Step [590/951], Loss: 0.4120\n",
      "Epoch [3/5], Step [595/951], Loss: 0.5621\n",
      "Epoch [3/5], Step [600/951], Loss: 0.4081\n",
      "Epoch [3/5], Step [605/951], Loss: 0.5245\n",
      "Epoch [3/5], Step [610/951], Loss: 0.3068\n",
      "Epoch [3/5], Step [615/951], Loss: 0.3108\n",
      "Epoch [3/5], Step [620/951], Loss: 0.2398\n",
      "Epoch [3/5], Step [625/951], Loss: 0.3865\n",
      "Epoch [3/5], Step [630/951], Loss: 0.4289\n",
      "Epoch [3/5], Step [635/951], Loss: 0.3399\n",
      "Epoch [3/5], Step [640/951], Loss: 0.2156\n",
      "Epoch [3/5], Step [645/951], Loss: 0.2735\n",
      "Epoch [3/5], Step [650/951], Loss: 0.3602\n",
      "Epoch [3/5], Step [655/951], Loss: 0.3481\n",
      "Epoch [3/5], Step [660/951], Loss: 0.1750\n",
      "Epoch [3/5], Step [665/951], Loss: 0.5704\n",
      "Epoch [3/5], Step [670/951], Loss: 0.3989\n",
      "Epoch [3/5], Step [675/951], Loss: 0.2306\n",
      "Epoch [3/5], Step [680/951], Loss: 0.2849\n",
      "Epoch [3/5], Step [685/951], Loss: 0.3443\n",
      "Epoch [3/5], Step [690/951], Loss: 0.1968\n",
      "Epoch [3/5], Step [695/951], Loss: 0.2510\n",
      "Epoch [3/5], Step [700/951], Loss: 0.2418\n",
      "Epoch [3/5], Step [705/951], Loss: 0.3744\n",
      "Epoch [3/5], Step [710/951], Loss: 0.2287\n",
      "Epoch [3/5], Step [715/951], Loss: 0.3018\n",
      "Epoch [3/5], Step [720/951], Loss: 0.2214\n",
      "Epoch [3/5], Step [725/951], Loss: 0.3268\n",
      "Epoch [3/5], Step [730/951], Loss: 0.2275\n",
      "Epoch [3/5], Step [735/951], Loss: 0.4838\n",
      "Epoch [3/5], Step [740/951], Loss: 0.5885\n",
      "Epoch [3/5], Step [745/951], Loss: 0.2427\n",
      "Epoch [3/5], Step [750/951], Loss: 0.3211\n",
      "Epoch [3/5], Step [755/951], Loss: 0.4264\n",
      "Epoch [3/5], Step [760/951], Loss: 0.3282\n",
      "Epoch [3/5], Step [765/951], Loss: 0.3182\n",
      "Epoch [3/5], Step [770/951], Loss: 0.2774\n",
      "Epoch [3/5], Step [775/951], Loss: 0.1792\n",
      "Epoch [3/5], Step [780/951], Loss: 0.0532\n",
      "Epoch [3/5], Step [785/951], Loss: 0.3802\n",
      "Epoch [3/5], Step [790/951], Loss: 0.3028\n",
      "Epoch [3/5], Step [795/951], Loss: 0.4470\n",
      "Epoch [3/5], Step [800/951], Loss: 0.1208\n",
      "Epoch [3/5], Step [805/951], Loss: 0.3929\n",
      "Epoch [3/5], Step [810/951], Loss: 0.3949\n",
      "Epoch [3/5], Step [815/951], Loss: 0.0902\n",
      "Epoch [3/5], Step [820/951], Loss: 0.2215\n",
      "Epoch [3/5], Step [825/951], Loss: 0.3591\n",
      "Epoch [3/5], Step [830/951], Loss: 0.1937\n",
      "Epoch [3/5], Step [835/951], Loss: 0.4140\n",
      "Epoch [3/5], Step [840/951], Loss: 0.2736\n",
      "Epoch [3/5], Step [845/951], Loss: 0.1462\n",
      "Epoch [3/5], Step [850/951], Loss: 0.2310\n",
      "Epoch [3/5], Step [855/951], Loss: 0.1450\n",
      "Epoch [3/5], Step [860/951], Loss: 0.2496\n",
      "Epoch [3/5], Step [865/951], Loss: 0.2986\n",
      "Epoch [3/5], Step [870/951], Loss: 0.2260\n",
      "Epoch [3/5], Step [875/951], Loss: 0.2337\n",
      "Epoch [3/5], Step [880/951], Loss: 0.2204\n",
      "Epoch [3/5], Step [885/951], Loss: 0.0918\n",
      "Epoch [3/5], Step [890/951], Loss: 0.5752\n",
      "Epoch [3/5], Step [895/951], Loss: 0.2600\n",
      "Epoch [3/5], Step [900/951], Loss: 0.2009\n",
      "Epoch [3/5], Step [905/951], Loss: 0.1374\n",
      "Epoch [3/5], Step [910/951], Loss: 0.2753\n",
      "Epoch [3/5], Step [915/951], Loss: 0.4907\n",
      "Epoch [3/5], Step [920/951], Loss: 0.3245\n",
      "Epoch [3/5], Step [925/951], Loss: 0.3118\n",
      "Epoch [3/5], Step [930/951], Loss: 0.1586\n",
      "Epoch [3/5], Step [935/951], Loss: 0.1711\n",
      "Epoch [3/5], Step [940/951], Loss: 0.1910\n",
      "Epoch [3/5], Step [945/951], Loss: 0.3645\n",
      "Epoch [3/5], Step [950/951], Loss: 0.2725\n",
      "Epoch [4/5], Step [5/951], Loss: 0.4151\n",
      "Epoch [4/5], Step [10/951], Loss: 0.1345\n",
      "Epoch [4/5], Step [15/951], Loss: 0.1893\n",
      "Epoch [4/5], Step [20/951], Loss: 0.3553\n",
      "Epoch [4/5], Step [25/951], Loss: 0.4543\n",
      "Epoch [4/5], Step [30/951], Loss: 0.1588\n",
      "Epoch [4/5], Step [35/951], Loss: 0.1892\n",
      "Epoch [4/5], Step [40/951], Loss: 0.1984\n",
      "Epoch [4/5], Step [45/951], Loss: 0.5063\n",
      "Epoch [4/5], Step [50/951], Loss: 0.1881\n",
      "Epoch [4/5], Step [55/951], Loss: 0.5929\n",
      "Epoch [4/5], Step [60/951], Loss: 0.2176\n",
      "Epoch [4/5], Step [65/951], Loss: 0.5651\n",
      "Epoch [4/5], Step [70/951], Loss: 0.0919\n",
      "Epoch [4/5], Step [75/951], Loss: 0.3114\n",
      "Epoch [4/5], Step [80/951], Loss: 0.0995\n",
      "Epoch [4/5], Step [85/951], Loss: 0.2841\n",
      "Epoch [4/5], Step [90/951], Loss: 0.1889\n",
      "Epoch [4/5], Step [95/951], Loss: 0.4375\n",
      "Epoch [4/5], Step [100/951], Loss: 0.2464\n",
      "Epoch [4/5], Step [105/951], Loss: 0.1504\n",
      "Epoch [4/5], Step [110/951], Loss: 0.7651\n",
      "Epoch [4/5], Step [115/951], Loss: 0.1495\n",
      "Epoch [4/5], Step [120/951], Loss: 0.1502\n",
      "Epoch [4/5], Step [125/951], Loss: 0.2982\n",
      "Epoch [4/5], Step [130/951], Loss: 0.3523\n",
      "Epoch [4/5], Step [135/951], Loss: 0.1985\n",
      "Epoch [4/5], Step [140/951], Loss: 0.1484\n",
      "Epoch [4/5], Step [145/951], Loss: 0.0625\n",
      "Epoch [4/5], Step [150/951], Loss: 0.2809\n",
      "Epoch [4/5], Step [155/951], Loss: 0.2960\n",
      "Epoch [4/5], Step [160/951], Loss: 0.3815\n",
      "Epoch [4/5], Step [165/951], Loss: 0.2250\n",
      "Epoch [4/5], Step [170/951], Loss: 0.0889\n",
      "Epoch [4/5], Step [175/951], Loss: 0.4194\n",
      "Epoch [4/5], Step [180/951], Loss: 0.2033\n",
      "Epoch [4/5], Step [185/951], Loss: 0.3833\n",
      "Epoch [4/5], Step [190/951], Loss: 0.2416\n",
      "Epoch [4/5], Step [195/951], Loss: 0.2610\n",
      "Epoch [4/5], Step [200/951], Loss: 0.3777\n",
      "Epoch [4/5], Step [205/951], Loss: 0.0992\n",
      "Epoch [4/5], Step [210/951], Loss: 0.3989\n",
      "Epoch [4/5], Step [215/951], Loss: 0.5308\n",
      "Epoch [4/5], Step [220/951], Loss: 0.1734\n",
      "Epoch [4/5], Step [225/951], Loss: 0.3525\n",
      "Epoch [4/5], Step [230/951], Loss: 0.7082\n",
      "Epoch [4/5], Step [235/951], Loss: 0.1633\n",
      "Epoch [4/5], Step [240/951], Loss: 0.1134\n",
      "Epoch [4/5], Step [245/951], Loss: 0.0693\n",
      "Epoch [4/5], Step [250/951], Loss: 0.1682\n",
      "Epoch [4/5], Step [255/951], Loss: 0.1912\n",
      "Epoch [4/5], Step [260/951], Loss: 0.1430\n",
      "Epoch [4/5], Step [265/951], Loss: 0.1967\n",
      "Epoch [4/5], Step [270/951], Loss: 0.1205\n",
      "Epoch [4/5], Step [275/951], Loss: 0.1754\n",
      "Epoch [4/5], Step [280/951], Loss: 0.2243\n",
      "Epoch [4/5], Step [285/951], Loss: 0.1703\n",
      "Epoch [4/5], Step [290/951], Loss: 0.2059\n",
      "Epoch [4/5], Step [295/951], Loss: 0.0871\n",
      "Epoch [4/5], Step [300/951], Loss: 0.1034\n",
      "Epoch [4/5], Step [305/951], Loss: 0.2492\n",
      "Epoch [4/5], Step [310/951], Loss: 0.0506\n",
      "Epoch [4/5], Step [315/951], Loss: 0.1187\n",
      "Epoch [4/5], Step [320/951], Loss: 0.0722\n",
      "Epoch [4/5], Step [325/951], Loss: 0.1265\n",
      "Epoch [4/5], Step [330/951], Loss: 0.2236\n",
      "Epoch [4/5], Step [335/951], Loss: 0.0274\n",
      "Epoch [4/5], Step [340/951], Loss: 0.2315\n",
      "Epoch [4/5], Step [345/951], Loss: 0.3507\n",
      "Epoch [4/5], Step [350/951], Loss: 0.2691\n",
      "Epoch [4/5], Step [355/951], Loss: 0.2804\n",
      "Epoch [4/5], Step [360/951], Loss: 0.0882\n",
      "Epoch [4/5], Step [365/951], Loss: 0.1572\n",
      "Epoch [4/5], Step [370/951], Loss: 0.2624\n",
      "Epoch [4/5], Step [375/951], Loss: 0.3677\n",
      "Epoch [4/5], Step [380/951], Loss: 0.1706\n",
      "Epoch [4/5], Step [385/951], Loss: 0.4953\n",
      "Epoch [4/5], Step [390/951], Loss: 0.2122\n",
      "Epoch [4/5], Step [395/951], Loss: 0.0827\n",
      "Epoch [4/5], Step [400/951], Loss: 0.0436\n",
      "Epoch [4/5], Step [405/951], Loss: 0.7284\n",
      "Epoch [4/5], Step [410/951], Loss: 0.0456\n",
      "Epoch [4/5], Step [415/951], Loss: 0.0943\n",
      "Epoch [4/5], Step [420/951], Loss: 0.1056\n",
      "Epoch [4/5], Step [425/951], Loss: 0.1419\n",
      "Epoch [4/5], Step [430/951], Loss: 0.0593\n",
      "Epoch [4/5], Step [435/951], Loss: 0.2280\n",
      "Epoch [4/5], Step [440/951], Loss: 0.0704\n",
      "Epoch [4/5], Step [445/951], Loss: 0.1557\n",
      "Epoch [4/5], Step [450/951], Loss: 0.0642\n",
      "Epoch [4/5], Step [455/951], Loss: 0.0276\n",
      "Epoch [4/5], Step [460/951], Loss: 0.2326\n",
      "Epoch [4/5], Step [465/951], Loss: 0.1078\n",
      "Epoch [4/5], Step [470/951], Loss: 0.5280\n",
      "Epoch [4/5], Step [475/951], Loss: 0.1792\n",
      "Epoch [4/5], Step [480/951], Loss: 0.3431\n",
      "Epoch [4/5], Step [485/951], Loss: 0.1146\n",
      "Epoch [4/5], Step [490/951], Loss: 0.1522\n",
      "Epoch [4/5], Step [495/951], Loss: 0.2933\n",
      "Epoch [4/5], Step [500/951], Loss: 0.2669\n",
      "Epoch [4/5], Step [505/951], Loss: 0.1392\n",
      "Epoch [4/5], Step [510/951], Loss: 0.0584\n",
      "Epoch [4/5], Step [515/951], Loss: 0.2275\n",
      "Epoch [4/5], Step [520/951], Loss: 0.0553\n",
      "Epoch [4/5], Step [525/951], Loss: 0.1164\n",
      "Epoch [4/5], Step [530/951], Loss: 0.1417\n",
      "Epoch [4/5], Step [535/951], Loss: 0.0846\n",
      "Epoch [4/5], Step [540/951], Loss: 0.0647\n",
      "Epoch [4/5], Step [545/951], Loss: 0.1208\n",
      "Epoch [4/5], Step [550/951], Loss: 0.1226\n",
      "Epoch [4/5], Step [555/951], Loss: 0.2891\n",
      "Epoch [4/5], Step [560/951], Loss: 0.1118\n",
      "Epoch [4/5], Step [565/951], Loss: 0.4308\n",
      "Epoch [4/5], Step [570/951], Loss: 0.1706\n",
      "Epoch [4/5], Step [575/951], Loss: 0.3934\n",
      "Epoch [4/5], Step [580/951], Loss: 0.3031\n",
      "Epoch [4/5], Step [585/951], Loss: 0.1493\n",
      "Epoch [4/5], Step [590/951], Loss: 0.5882\n",
      "Epoch [4/5], Step [595/951], Loss: 0.3728\n",
      "Epoch [4/5], Step [600/951], Loss: 0.3205\n",
      "Epoch [4/5], Step [605/951], Loss: 0.2275\n",
      "Epoch [4/5], Step [610/951], Loss: 0.4182\n",
      "Epoch [4/5], Step [615/951], Loss: 0.3171\n",
      "Epoch [4/5], Step [620/951], Loss: 0.0723\n",
      "Epoch [4/5], Step [625/951], Loss: 0.1231\n",
      "Epoch [4/5], Step [630/951], Loss: 0.2834\n",
      "Epoch [4/5], Step [635/951], Loss: 0.1746\n",
      "Epoch [4/5], Step [640/951], Loss: 0.0622\n",
      "Epoch [4/5], Step [645/951], Loss: 0.1039\n",
      "Epoch [4/5], Step [650/951], Loss: 0.1180\n",
      "Epoch [4/5], Step [655/951], Loss: 0.0981\n",
      "Epoch [4/5], Step [660/951], Loss: 0.0307\n",
      "Epoch [4/5], Step [665/951], Loss: 0.2458\n",
      "Epoch [4/5], Step [670/951], Loss: 0.1251\n",
      "Epoch [4/5], Step [675/951], Loss: 0.0672\n",
      "Epoch [4/5], Step [680/951], Loss: 0.0898\n",
      "Epoch [4/5], Step [685/951], Loss: 0.0615\n",
      "Epoch [4/5], Step [690/951], Loss: 0.0261\n",
      "Epoch [4/5], Step [695/951], Loss: 0.0776\n",
      "Epoch [4/5], Step [700/951], Loss: 0.3054\n",
      "Epoch [4/5], Step [705/951], Loss: 0.2340\n",
      "Epoch [4/5], Step [710/951], Loss: 0.1489\n",
      "Epoch [4/5], Step [715/951], Loss: 0.3910\n",
      "Epoch [4/5], Step [720/951], Loss: 0.1112\n",
      "Epoch [4/5], Step [725/951], Loss: 0.1381\n",
      "Epoch [4/5], Step [730/951], Loss: 0.1213\n",
      "Epoch [4/5], Step [735/951], Loss: 0.1820\n",
      "Epoch [4/5], Step [740/951], Loss: 0.2406\n",
      "Epoch [4/5], Step [745/951], Loss: 0.0885\n",
      "Epoch [4/5], Step [750/951], Loss: 0.1674\n",
      "Epoch [4/5], Step [755/951], Loss: 0.1212\n",
      "Epoch [4/5], Step [760/951], Loss: 0.1391\n",
      "Epoch [4/5], Step [765/951], Loss: 0.1799\n",
      "Epoch [4/5], Step [770/951], Loss: 0.1058\n",
      "Epoch [4/5], Step [775/951], Loss: 0.3158\n",
      "Epoch [4/5], Step [780/951], Loss: 0.0567\n",
      "Epoch [4/5], Step [785/951], Loss: 0.1355\n",
      "Epoch [4/5], Step [790/951], Loss: 0.1369\n",
      "Epoch [4/5], Step [795/951], Loss: 0.0596\n",
      "Epoch [4/5], Step [800/951], Loss: 0.0169\n",
      "Epoch [4/5], Step [805/951], Loss: 0.1204\n",
      "Epoch [4/5], Step [810/951], Loss: 0.2147\n",
      "Epoch [4/5], Step [815/951], Loss: 0.1192\n",
      "Epoch [4/5], Step [820/951], Loss: 0.1215\n",
      "Epoch [4/5], Step [825/951], Loss: 0.1634\n",
      "Epoch [4/5], Step [830/951], Loss: 0.2313\n",
      "Epoch [4/5], Step [835/951], Loss: 0.2413\n",
      "Epoch [4/5], Step [840/951], Loss: 0.1881\n",
      "Epoch [4/5], Step [845/951], Loss: 0.1153\n",
      "Epoch [4/5], Step [850/951], Loss: 0.2112\n",
      "Epoch [4/5], Step [855/951], Loss: 0.0368\n",
      "Epoch [4/5], Step [860/951], Loss: 0.1380\n",
      "Epoch [4/5], Step [865/951], Loss: 0.0876\n",
      "Epoch [4/5], Step [870/951], Loss: 0.0225\n",
      "Epoch [4/5], Step [875/951], Loss: 0.2987\n",
      "Epoch [4/5], Step [880/951], Loss: 0.1102\n",
      "Epoch [4/5], Step [885/951], Loss: 0.1303\n",
      "Epoch [4/5], Step [890/951], Loss: 0.2772\n",
      "Epoch [4/5], Step [895/951], Loss: 0.0562\n",
      "Epoch [4/5], Step [900/951], Loss: 0.0667\n",
      "Epoch [4/5], Step [905/951], Loss: 0.1353\n",
      "Epoch [4/5], Step [910/951], Loss: 0.0727\n",
      "Epoch [4/5], Step [915/951], Loss: 0.3166\n",
      "Epoch [4/5], Step [920/951], Loss: 0.1682\n",
      "Epoch [4/5], Step [925/951], Loss: 0.0253\n",
      "Epoch [4/5], Step [930/951], Loss: 0.0272\n",
      "Epoch [4/5], Step [935/951], Loss: 0.0128\n",
      "Epoch [4/5], Step [940/951], Loss: 0.0507\n",
      "Epoch [4/5], Step [945/951], Loss: 0.1202\n",
      "Epoch [4/5], Step [950/951], Loss: 0.2078\n",
      "Epoch [5/5], Step [5/951], Loss: 0.1814\n",
      "Epoch [5/5], Step [10/951], Loss: 0.0148\n",
      "Epoch [5/5], Step [15/951], Loss: 0.2363\n",
      "Epoch [5/5], Step [20/951], Loss: 0.1753\n",
      "Epoch [5/5], Step [25/951], Loss: 0.4332\n",
      "Epoch [5/5], Step [30/951], Loss: 0.2166\n",
      "Epoch [5/5], Step [35/951], Loss: 0.2003\n",
      "Epoch [5/5], Step [40/951], Loss: 0.0237\n",
      "Epoch [5/5], Step [45/951], Loss: 0.2724\n",
      "Epoch [5/5], Step [50/951], Loss: 0.2678\n",
      "Epoch [5/5], Step [55/951], Loss: 0.2767\n",
      "Epoch [5/5], Step [60/951], Loss: 0.1263\n",
      "Epoch [5/5], Step [65/951], Loss: 0.5983\n",
      "Epoch [5/5], Step [70/951], Loss: 0.0319\n",
      "Epoch [5/5], Step [75/951], Loss: 0.1156\n",
      "Epoch [5/5], Step [80/951], Loss: 0.1890\n",
      "Epoch [5/5], Step [85/951], Loss: 0.4127\n",
      "Epoch [5/5], Step [90/951], Loss: 0.2264\n",
      "Epoch [5/5], Step [95/951], Loss: 0.1584\n",
      "Epoch [5/5], Step [100/951], Loss: 0.1224\n",
      "Epoch [5/5], Step [105/951], Loss: 0.0434\n",
      "Epoch [5/5], Step [110/951], Loss: 0.7666\n",
      "Epoch [5/5], Step [115/951], Loss: 0.0951\n",
      "Epoch [5/5], Step [120/951], Loss: 0.1460\n",
      "Epoch [5/5], Step [125/951], Loss: 0.1910\n",
      "Epoch [5/5], Step [130/951], Loss: 0.1670\n",
      "Epoch [5/5], Step [135/951], Loss: 0.1159\n",
      "Epoch [5/5], Step [140/951], Loss: 0.1914\n",
      "Epoch [5/5], Step [145/951], Loss: 0.0518\n",
      "Epoch [5/5], Step [150/951], Loss: 0.3870\n",
      "Epoch [5/5], Step [155/951], Loss: 0.1237\n",
      "Epoch [5/5], Step [160/951], Loss: 0.6338\n",
      "Epoch [5/5], Step [165/951], Loss: 0.1921\n",
      "Epoch [5/5], Step [170/951], Loss: 0.1163\n",
      "Epoch [5/5], Step [175/951], Loss: 0.0810\n",
      "Epoch [5/5], Step [180/951], Loss: 0.4356\n",
      "Epoch [5/5], Step [185/951], Loss: 0.1412\n",
      "Epoch [5/5], Step [190/951], Loss: 0.1452\n",
      "Epoch [5/5], Step [195/951], Loss: 0.0959\n",
      "Epoch [5/5], Step [200/951], Loss: 0.6676\n",
      "Epoch [5/5], Step [205/951], Loss: 0.1112\n",
      "Epoch [5/5], Step [210/951], Loss: 0.7321\n",
      "Epoch [5/5], Step [215/951], Loss: 0.1321\n",
      "Epoch [5/5], Step [220/951], Loss: 0.5487\n",
      "Epoch [5/5], Step [225/951], Loss: 0.2589\n",
      "Epoch [5/5], Step [230/951], Loss: 0.5180\n",
      "Epoch [5/5], Step [235/951], Loss: 0.1959\n",
      "Epoch [5/5], Step [240/951], Loss: 0.0380\n",
      "Epoch [5/5], Step [245/951], Loss: 0.2057\n",
      "Epoch [5/5], Step [250/951], Loss: 0.0790\n",
      "Epoch [5/5], Step [255/951], Loss: 0.0545\n",
      "Epoch [5/5], Step [260/951], Loss: 0.0694\n",
      "Epoch [5/5], Step [265/951], Loss: 0.2066\n",
      "Epoch [5/5], Step [270/951], Loss: 0.0370\n",
      "Epoch [5/5], Step [275/951], Loss: 0.1501\n",
      "Epoch [5/5], Step [280/951], Loss: 0.0909\n",
      "Epoch [5/5], Step [285/951], Loss: 0.1237\n",
      "Epoch [5/5], Step [290/951], Loss: 0.1188\n",
      "Epoch [5/5], Step [295/951], Loss: 0.1190\n",
      "Epoch [5/5], Step [300/951], Loss: 0.0573\n",
      "Epoch [5/5], Step [305/951], Loss: 0.0994\n",
      "Epoch [5/5], Step [310/951], Loss: 0.1438\n",
      "Epoch [5/5], Step [315/951], Loss: 0.0496\n",
      "Epoch [5/5], Step [320/951], Loss: 0.0723\n",
      "Epoch [5/5], Step [325/951], Loss: 0.1257\n",
      "Epoch [5/5], Step [330/951], Loss: 0.3379\n",
      "Epoch [5/5], Step [335/951], Loss: 0.1244\n",
      "Epoch [5/5], Step [340/951], Loss: 0.0839\n",
      "Epoch [5/5], Step [345/951], Loss: 0.1012\n",
      "Epoch [5/5], Step [350/951], Loss: 0.0681\n",
      "Epoch [5/5], Step [355/951], Loss: 0.0756\n",
      "Epoch [5/5], Step [360/951], Loss: 0.0532\n",
      "Epoch [5/5], Step [365/951], Loss: 0.0813\n",
      "Epoch [5/5], Step [370/951], Loss: 0.6794\n",
      "Epoch [5/5], Step [375/951], Loss: 0.2753\n",
      "Epoch [5/5], Step [380/951], Loss: 0.5621\n",
      "Epoch [5/5], Step [385/951], Loss: 0.2402\n",
      "Epoch [5/5], Step [390/951], Loss: 0.1166\n",
      "Epoch [5/5], Step [395/951], Loss: 0.2247\n",
      "Epoch [5/5], Step [400/951], Loss: 0.1323\n",
      "Epoch [5/5], Step [405/951], Loss: 0.4023\n",
      "Epoch [5/5], Step [410/951], Loss: 0.0901\n",
      "Epoch [5/5], Step [415/951], Loss: 0.1222\n",
      "Epoch [5/5], Step [420/951], Loss: 0.1629\n",
      "Epoch [5/5], Step [425/951], Loss: 0.0742\n",
      "Epoch [5/5], Step [430/951], Loss: 0.1297\n",
      "Epoch [5/5], Step [435/951], Loss: 0.1066\n",
      "Epoch [5/5], Step [440/951], Loss: 0.1708\n",
      "Epoch [5/5], Step [445/951], Loss: 0.1517\n",
      "Epoch [5/5], Step [450/951], Loss: 0.0642\n",
      "Epoch [5/5], Step [455/951], Loss: 0.0350\n",
      "Epoch [5/5], Step [460/951], Loss: 0.0532\n",
      "Epoch [5/5], Step [465/951], Loss: 0.1852\n",
      "Epoch [5/5], Step [470/951], Loss: 0.2118\n",
      "Epoch [5/5], Step [475/951], Loss: 0.0513\n",
      "Epoch [5/5], Step [480/951], Loss: 0.2620\n",
      "Epoch [5/5], Step [485/951], Loss: 0.0829\n",
      "Epoch [5/5], Step [490/951], Loss: 0.0576\n",
      "Epoch [5/5], Step [495/951], Loss: 0.0381\n",
      "Epoch [5/5], Step [500/951], Loss: 0.1727\n",
      "Epoch [5/5], Step [505/951], Loss: 0.0871\n",
      "Epoch [5/5], Step [510/951], Loss: 0.2587\n",
      "Epoch [5/5], Step [515/951], Loss: 0.1606\n",
      "Epoch [5/5], Step [520/951], Loss: 0.0584\n",
      "Epoch [5/5], Step [525/951], Loss: 0.0178\n",
      "Epoch [5/5], Step [530/951], Loss: 0.1097\n",
      "Epoch [5/5], Step [535/951], Loss: 0.1124\n",
      "Epoch [5/5], Step [540/951], Loss: 0.0126\n",
      "Epoch [5/5], Step [545/951], Loss: 0.0492\n",
      "Epoch [5/5], Step [550/951], Loss: 0.0946\n",
      "Epoch [5/5], Step [555/951], Loss: 0.3814\n",
      "Epoch [5/5], Step [560/951], Loss: 0.0316\n",
      "Epoch [5/5], Step [565/951], Loss: 0.1379\n",
      "Epoch [5/5], Step [570/951], Loss: 0.2269\n",
      "Epoch [5/5], Step [575/951], Loss: 0.3801\n",
      "Epoch [5/5], Step [580/951], Loss: 0.2703\n",
      "Epoch [5/5], Step [585/951], Loss: 0.2013\n",
      "Epoch [5/5], Step [590/951], Loss: 0.4645\n",
      "Epoch [5/5], Step [595/951], Loss: 0.0383\n",
      "Epoch [5/5], Step [600/951], Loss: 0.0853\n",
      "Epoch [5/5], Step [605/951], Loss: 0.0654\n",
      "Epoch [5/5], Step [610/951], Loss: 0.0588\n",
      "Epoch [5/5], Step [615/951], Loss: 0.0790\n",
      "Epoch [5/5], Step [620/951], Loss: 0.0744\n",
      "Epoch [5/5], Step [625/951], Loss: 0.0907\n",
      "Epoch [5/5], Step [630/951], Loss: 0.1413\n",
      "Epoch [5/5], Step [635/951], Loss: 0.0463\n",
      "Epoch [5/5], Step [640/951], Loss: 0.0670\n",
      "Epoch [5/5], Step [645/951], Loss: 0.1074\n",
      "Epoch [5/5], Step [650/951], Loss: 0.1234\n",
      "Epoch [5/5], Step [655/951], Loss: 0.1214\n",
      "Epoch [5/5], Step [660/951], Loss: 0.0324\n",
      "Epoch [5/5], Step [665/951], Loss: 0.0396\n",
      "Epoch [5/5], Step [670/951], Loss: 0.0631\n",
      "Epoch [5/5], Step [675/951], Loss: 0.1133\n",
      "Epoch [5/5], Step [680/951], Loss: 0.0128\n",
      "Epoch [5/5], Step [685/951], Loss: 0.1141\n",
      "Epoch [5/5], Step [690/951], Loss: 0.0195\n",
      "Epoch [5/5], Step [695/951], Loss: 0.0188\n",
      "Epoch [5/5], Step [700/951], Loss: 0.0735\n",
      "Epoch [5/5], Step [705/951], Loss: 0.0545\n",
      "Epoch [5/5], Step [710/951], Loss: 0.0973\n",
      "Epoch [5/5], Step [715/951], Loss: 0.0874\n",
      "Epoch [5/5], Step [720/951], Loss: 0.0271\n",
      "Epoch [5/5], Step [725/951], Loss: 0.3770\n",
      "Epoch [5/5], Step [730/951], Loss: 0.0927\n",
      "Epoch [5/5], Step [735/951], Loss: 0.1262\n",
      "Epoch [5/5], Step [740/951], Loss: 0.4910\n",
      "Epoch [5/5], Step [745/951], Loss: 0.2191\n",
      "Epoch [5/5], Step [750/951], Loss: 0.2120\n",
      "Epoch [5/5], Step [755/951], Loss: 0.0906\n",
      "Epoch [5/5], Step [760/951], Loss: 0.1308\n",
      "Epoch [5/5], Step [765/951], Loss: 0.0902\n",
      "Epoch [5/5], Step [770/951], Loss: 0.1224\n",
      "Epoch [5/5], Step [775/951], Loss: 0.1497\n",
      "Epoch [5/5], Step [780/951], Loss: 0.0245\n",
      "Epoch [5/5], Step [785/951], Loss: 0.0456\n",
      "Epoch [5/5], Step [790/951], Loss: 0.1949\n",
      "Epoch [5/5], Step [795/951], Loss: 0.2716\n",
      "Epoch [5/5], Step [800/951], Loss: 0.0106\n",
      "Epoch [5/5], Step [805/951], Loss: 0.0331\n",
      "Epoch [5/5], Step [810/951], Loss: 0.0786\n",
      "Epoch [5/5], Step [815/951], Loss: 0.0173\n",
      "Epoch [5/5], Step [820/951], Loss: 0.0650\n",
      "Epoch [5/5], Step [825/951], Loss: 0.0367\n",
      "Epoch [5/5], Step [830/951], Loss: 0.1067\n",
      "Epoch [5/5], Step [835/951], Loss: 0.2982\n",
      "Epoch [5/5], Step [840/951], Loss: 0.1540\n",
      "Epoch [5/5], Step [845/951], Loss: 0.2312\n",
      "Epoch [5/5], Step [850/951], Loss: 0.1175\n",
      "Epoch [5/5], Step [855/951], Loss: 0.0695\n",
      "Epoch [5/5], Step [860/951], Loss: 0.1824\n",
      "Epoch [5/5], Step [865/951], Loss: 0.0409\n",
      "Epoch [5/5], Step [870/951], Loss: 0.0634\n",
      "Epoch [5/5], Step [875/951], Loss: 0.0363\n",
      "Epoch [5/5], Step [880/951], Loss: 0.0331\n",
      "Epoch [5/5], Step [885/951], Loss: 0.0265\n",
      "Epoch [5/5], Step [890/951], Loss: 0.1357\n",
      "Epoch [5/5], Step [895/951], Loss: 0.0189\n",
      "Epoch [5/5], Step [900/951], Loss: 0.1991\n",
      "Epoch [5/5], Step [905/951], Loss: 0.1205\n",
      "Epoch [5/5], Step [910/951], Loss: 0.1532\n",
      "Epoch [5/5], Step [915/951], Loss: 0.0752\n",
      "Epoch [5/5], Step [920/951], Loss: 0.2558\n",
      "Epoch [5/5], Step [925/951], Loss: 0.2624\n",
      "Epoch [5/5], Step [930/951], Loss: 0.2493\n",
      "Epoch [5/5], Step [935/951], Loss: 0.0216\n",
      "Epoch [5/5], Step [940/951], Loss: 0.3059\n",
      "Epoch [5/5], Step [945/951], Loss: 0.0134\n",
      "Epoch [5/5], Step [950/951], Loss: 0.0161\n",
      "Test accuracy of the network: 84.44022770398482 %\n",
      "Train accuracy of the network: 83.8417039179595 %\n"
     ]
    }
   ],
   "source": [
    "test_accuracy, train_accuracy, model, vectorizer_train = trainAndTestTwoHiddenLayerModel('fnn', num_epochs=5)\n",
    "torch.save(model, 'fnn_saved_model')\n",
    "pickle.dump(vectorizer_train, open('fnn_vec.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [5/19], Loss: 0.3936\n",
      "Epoch [1/1], Step [10/19], Loss: 0.4929\n",
      "Epoch [1/1], Step [15/19], Loss: 0.1851\n",
      "Test accuracy of the network: 86.368843069874 %\n",
      "Train accuracy of the network: 97.9381443298969 %\n",
      "Epoch [1/5], Step [5/19], Loss: 0.3936\n",
      "Epoch [1/5], Step [10/19], Loss: 0.4929\n",
      "Epoch [1/5], Step [15/19], Loss: 0.1851\n",
      "Epoch [2/5], Step [5/19], Loss: 0.0110\n",
      "Epoch [2/5], Step [10/19], Loss: 0.1077\n",
      "Epoch [2/5], Step [15/19], Loss: 0.0416\n",
      "Epoch [3/5], Step [5/19], Loss: 0.0006\n",
      "Epoch [3/5], Step [10/19], Loss: 0.0101\n",
      "Epoch [3/5], Step [15/19], Loss: 0.0041\n",
      "Epoch [4/5], Step [5/19], Loss: 0.0002\n",
      "Epoch [4/5], Step [10/19], Loss: 0.0032\n",
      "Epoch [4/5], Step [15/19], Loss: 0.0013\n",
      "Epoch [5/5], Step [5/19], Loss: 0.0001\n",
      "Epoch [5/5], Step [10/19], Loss: 0.0017\n",
      "Epoch [5/5], Step [15/19], Loss: 0.0007\n",
      "Test accuracy of the network: 88.43069873997709 %\n",
      "Train accuracy of the network: 100.0 %\n",
      "Epoch [1/10], Step [5/19], Loss: 0.3936\n",
      "Epoch [1/10], Step [10/19], Loss: 0.4929\n",
      "Epoch [1/10], Step [15/19], Loss: 0.1851\n",
      "Epoch [2/10], Step [5/19], Loss: 0.0110\n",
      "Epoch [2/10], Step [10/19], Loss: 0.1077\n",
      "Epoch [2/10], Step [15/19], Loss: 0.0416\n",
      "Epoch [3/10], Step [5/19], Loss: 0.0006\n",
      "Epoch [3/10], Step [10/19], Loss: 0.0101\n",
      "Epoch [3/10], Step [15/19], Loss: 0.0041\n",
      "Epoch [4/10], Step [5/19], Loss: 0.0002\n",
      "Epoch [4/10], Step [10/19], Loss: 0.0032\n",
      "Epoch [4/10], Step [15/19], Loss: 0.0013\n",
      "Epoch [5/10], Step [5/19], Loss: 0.0001\n",
      "Epoch [5/10], Step [10/19], Loss: 0.0017\n",
      "Epoch [5/10], Step [15/19], Loss: 0.0007\n",
      "Epoch [6/10], Step [5/19], Loss: 0.0001\n",
      "Epoch [6/10], Step [10/19], Loss: 0.0011\n",
      "Epoch [6/10], Step [15/19], Loss: 0.0005\n",
      "Epoch [7/10], Step [5/19], Loss: 0.0000\n",
      "Epoch [7/10], Step [10/19], Loss: 0.0008\n",
      "Epoch [7/10], Step [15/19], Loss: 0.0004\n",
      "Epoch [8/10], Step [5/19], Loss: 0.0000\n",
      "Epoch [8/10], Step [10/19], Loss: 0.0006\n",
      "Epoch [8/10], Step [15/19], Loss: 0.0003\n",
      "Epoch [9/10], Step [5/19], Loss: 0.0000\n",
      "Epoch [9/10], Step [10/19], Loss: 0.0005\n",
      "Epoch [9/10], Step [15/19], Loss: 0.0002\n",
      "Epoch [10/10], Step [5/19], Loss: 0.0000\n",
      "Epoch [10/10], Step [10/19], Loss: 0.0004\n",
      "Epoch [10/10], Step [15/19], Loss: 0.0002\n",
      "Test accuracy of the network: 88.54524627720504 %\n",
      "Train accuracy of the network: 100.0 %\n",
      "Epoch [1/20], Step [5/19], Loss: 0.3936\n",
      "Epoch [1/20], Step [10/19], Loss: 0.4929\n",
      "Epoch [1/20], Step [15/19], Loss: 0.1851\n",
      "Epoch [2/20], Step [5/19], Loss: 0.0110\n",
      "Epoch [2/20], Step [10/19], Loss: 0.1077\n",
      "Epoch [2/20], Step [15/19], Loss: 0.0416\n",
      "Epoch [3/20], Step [5/19], Loss: 0.0006\n",
      "Epoch [3/20], Step [10/19], Loss: 0.0101\n",
      "Epoch [3/20], Step [15/19], Loss: 0.0041\n",
      "Epoch [4/20], Step [5/19], Loss: 0.0002\n",
      "Epoch [4/20], Step [10/19], Loss: 0.0032\n",
      "Epoch [4/20], Step [15/19], Loss: 0.0013\n",
      "Epoch [5/20], Step [5/19], Loss: 0.0001\n",
      "Epoch [5/20], Step [10/19], Loss: 0.0017\n",
      "Epoch [5/20], Step [15/19], Loss: 0.0007\n",
      "Epoch [6/20], Step [5/19], Loss: 0.0001\n",
      "Epoch [6/20], Step [10/19], Loss: 0.0011\n",
      "Epoch [6/20], Step [15/19], Loss: 0.0005\n",
      "Epoch [7/20], Step [5/19], Loss: 0.0000\n",
      "Epoch [7/20], Step [10/19], Loss: 0.0008\n",
      "Epoch [7/20], Step [15/19], Loss: 0.0004\n",
      "Epoch [8/20], Step [5/19], Loss: 0.0000\n",
      "Epoch [8/20], Step [10/19], Loss: 0.0006\n",
      "Epoch [8/20], Step [15/19], Loss: 0.0003\n",
      "Epoch [9/20], Step [5/19], Loss: 0.0000\n",
      "Epoch [9/20], Step [10/19], Loss: 0.0005\n",
      "Epoch [9/20], Step [15/19], Loss: 0.0002\n",
      "Epoch [10/20], Step [5/19], Loss: 0.0000\n",
      "Epoch [10/20], Step [10/19], Loss: 0.0004\n",
      "Epoch [10/20], Step [15/19], Loss: 0.0002\n",
      "Epoch [11/20], Step [5/19], Loss: 0.0000\n",
      "Epoch [11/20], Step [10/19], Loss: 0.0004\n",
      "Epoch [11/20], Step [15/19], Loss: 0.0002\n",
      "Epoch [12/20], Step [5/19], Loss: 0.0000\n",
      "Epoch [12/20], Step [10/19], Loss: 0.0003\n",
      "Epoch [12/20], Step [15/19], Loss: 0.0001\n",
      "Epoch [13/20], Step [5/19], Loss: 0.0000\n",
      "Epoch [13/20], Step [10/19], Loss: 0.0003\n",
      "Epoch [13/20], Step [15/19], Loss: 0.0001\n",
      "Epoch [14/20], Step [5/19], Loss: 0.0000\n",
      "Epoch [14/20], Step [10/19], Loss: 0.0002\n",
      "Epoch [14/20], Step [15/19], Loss: 0.0001\n",
      "Epoch [15/20], Step [5/19], Loss: 0.0000\n",
      "Epoch [15/20], Step [10/19], Loss: 0.0002\n",
      "Epoch [15/20], Step [15/19], Loss: 0.0001\n",
      "Epoch [16/20], Step [5/19], Loss: 0.0000\n",
      "Epoch [16/20], Step [10/19], Loss: 0.0002\n",
      "Epoch [16/20], Step [15/19], Loss: 0.0001\n",
      "Epoch [17/20], Step [5/19], Loss: 0.0000\n",
      "Epoch [17/20], Step [10/19], Loss: 0.0002\n",
      "Epoch [17/20], Step [15/19], Loss: 0.0001\n",
      "Epoch [18/20], Step [5/19], Loss: 0.0000\n",
      "Epoch [18/20], Step [10/19], Loss: 0.0002\n",
      "Epoch [18/20], Step [15/19], Loss: 0.0001\n",
      "Epoch [19/20], Step [5/19], Loss: 0.0000\n",
      "Epoch [19/20], Step [10/19], Loss: 0.0001\n",
      "Epoch [19/20], Step [15/19], Loss: 0.0001\n",
      "Epoch [20/20], Step [5/19], Loss: 0.0000\n",
      "Epoch [20/20], Step [10/19], Loss: 0.0001\n",
      "Epoch [20/20], Step [15/19], Loss: 0.0001\n",
      "Test accuracy of the network: 88.77434135166094 %\n",
      "Train accuracy of the network: 100.0 %\n",
      "Epoch [1/30], Step [5/19], Loss: 0.3936\n",
      "Epoch [1/30], Step [10/19], Loss: 0.4929\n",
      "Epoch [1/30], Step [15/19], Loss: 0.1851\n",
      "Epoch [2/30], Step [5/19], Loss: 0.0110\n",
      "Epoch [2/30], Step [10/19], Loss: 0.1077\n",
      "Epoch [2/30], Step [15/19], Loss: 0.0416\n",
      "Epoch [3/30], Step [5/19], Loss: 0.0006\n",
      "Epoch [3/30], Step [10/19], Loss: 0.0101\n",
      "Epoch [3/30], Step [15/19], Loss: 0.0041\n",
      "Epoch [4/30], Step [5/19], Loss: 0.0002\n",
      "Epoch [4/30], Step [10/19], Loss: 0.0032\n",
      "Epoch [4/30], Step [15/19], Loss: 0.0013\n",
      "Epoch [5/30], Step [5/19], Loss: 0.0001\n",
      "Epoch [5/30], Step [10/19], Loss: 0.0017\n",
      "Epoch [5/30], Step [15/19], Loss: 0.0007\n",
      "Epoch [6/30], Step [5/19], Loss: 0.0001\n",
      "Epoch [6/30], Step [10/19], Loss: 0.0011\n",
      "Epoch [6/30], Step [15/19], Loss: 0.0005\n",
      "Epoch [7/30], Step [5/19], Loss: 0.0000\n",
      "Epoch [7/30], Step [10/19], Loss: 0.0008\n",
      "Epoch [7/30], Step [15/19], Loss: 0.0004\n",
      "Epoch [8/30], Step [5/19], Loss: 0.0000\n",
      "Epoch [8/30], Step [10/19], Loss: 0.0006\n",
      "Epoch [8/30], Step [15/19], Loss: 0.0003\n",
      "Epoch [9/30], Step [5/19], Loss: 0.0000\n",
      "Epoch [9/30], Step [10/19], Loss: 0.0005\n",
      "Epoch [9/30], Step [15/19], Loss: 0.0002\n",
      "Epoch [10/30], Step [5/19], Loss: 0.0000\n",
      "Epoch [10/30], Step [10/19], Loss: 0.0004\n",
      "Epoch [10/30], Step [15/19], Loss: 0.0002\n",
      "Epoch [11/30], Step [5/19], Loss: 0.0000\n",
      "Epoch [11/30], Step [10/19], Loss: 0.0004\n",
      "Epoch [11/30], Step [15/19], Loss: 0.0002\n",
      "Epoch [12/30], Step [5/19], Loss: 0.0000\n",
      "Epoch [12/30], Step [10/19], Loss: 0.0003\n",
      "Epoch [12/30], Step [15/19], Loss: 0.0001\n",
      "Epoch [13/30], Step [5/19], Loss: 0.0000\n",
      "Epoch [13/30], Step [10/19], Loss: 0.0003\n",
      "Epoch [13/30], Step [15/19], Loss: 0.0001\n",
      "Epoch [14/30], Step [5/19], Loss: 0.0000\n",
      "Epoch [14/30], Step [10/19], Loss: 0.0002\n",
      "Epoch [14/30], Step [15/19], Loss: 0.0001\n",
      "Epoch [15/30], Step [5/19], Loss: 0.0000\n",
      "Epoch [15/30], Step [10/19], Loss: 0.0002\n",
      "Epoch [15/30], Step [15/19], Loss: 0.0001\n",
      "Epoch [16/30], Step [5/19], Loss: 0.0000\n",
      "Epoch [16/30], Step [10/19], Loss: 0.0002\n",
      "Epoch [16/30], Step [15/19], Loss: 0.0001\n",
      "Epoch [17/30], Step [5/19], Loss: 0.0000\n",
      "Epoch [17/30], Step [10/19], Loss: 0.0002\n",
      "Epoch [17/30], Step [15/19], Loss: 0.0001\n",
      "Epoch [18/30], Step [5/19], Loss: 0.0000\n",
      "Epoch [18/30], Step [10/19], Loss: 0.0002\n",
      "Epoch [18/30], Step [15/19], Loss: 0.0001\n",
      "Epoch [19/30], Step [5/19], Loss: 0.0000\n",
      "Epoch [19/30], Step [10/19], Loss: 0.0001\n",
      "Epoch [19/30], Step [15/19], Loss: 0.0001\n",
      "Epoch [20/30], Step [5/19], Loss: 0.0000\n",
      "Epoch [20/30], Step [10/19], Loss: 0.0001\n",
      "Epoch [20/30], Step [15/19], Loss: 0.0001\n",
      "Epoch [21/30], Step [5/19], Loss: 0.0000\n",
      "Epoch [21/30], Step [10/19], Loss: 0.0001\n",
      "Epoch [21/30], Step [15/19], Loss: 0.0001\n",
      "Epoch [22/30], Step [5/19], Loss: 0.0000\n",
      "Epoch [22/30], Step [10/19], Loss: 0.0001\n",
      "Epoch [22/30], Step [15/19], Loss: 0.0000\n",
      "Epoch [23/30], Step [5/19], Loss: 0.0000\n",
      "Epoch [23/30], Step [10/19], Loss: 0.0001\n",
      "Epoch [23/30], Step [15/19], Loss: 0.0000\n",
      "Epoch [24/30], Step [5/19], Loss: 0.0000\n",
      "Epoch [24/30], Step [10/19], Loss: 0.0001\n",
      "Epoch [24/30], Step [15/19], Loss: 0.0000\n",
      "Epoch [25/30], Step [5/19], Loss: 0.0000\n",
      "Epoch [25/30], Step [10/19], Loss: 0.0001\n",
      "Epoch [25/30], Step [15/19], Loss: 0.0000\n",
      "Epoch [26/30], Step [5/19], Loss: 0.0000\n",
      "Epoch [26/30], Step [10/19], Loss: 0.0001\n",
      "Epoch [26/30], Step [15/19], Loss: 0.0000\n",
      "Epoch [27/30], Step [5/19], Loss: 0.0000\n",
      "Epoch [27/30], Step [10/19], Loss: 0.0001\n",
      "Epoch [27/30], Step [15/19], Loss: 0.0000\n",
      "Epoch [28/30], Step [5/19], Loss: 0.0000\n",
      "Epoch [28/30], Step [10/19], Loss: 0.0001\n",
      "Epoch [28/30], Step [15/19], Loss: 0.0000\n",
      "Epoch [29/30], Step [5/19], Loss: 0.0000\n",
      "Epoch [29/30], Step [10/19], Loss: 0.0001\n",
      "Epoch [29/30], Step [15/19], Loss: 0.0000\n",
      "Epoch [30/30], Step [5/19], Loss: 0.0000\n",
      "Epoch [30/30], Step [10/19], Loss: 0.0001\n",
      "Epoch [30/30], Step [15/19], Loss: 0.0000\n",
      "Test accuracy of the network: 88.65979381443299 %\n",
      "Train accuracy of the network: 100.0 %\n",
      "Epoch [1/40], Step [5/19], Loss: 0.3936\n",
      "Epoch [1/40], Step [10/19], Loss: 0.4929\n",
      "Epoch [1/40], Step [15/19], Loss: 0.1851\n",
      "Epoch [2/40], Step [5/19], Loss: 0.0110\n",
      "Epoch [2/40], Step [10/19], Loss: 0.1077\n",
      "Epoch [2/40], Step [15/19], Loss: 0.0416\n",
      "Epoch [3/40], Step [5/19], Loss: 0.0006\n",
      "Epoch [3/40], Step [10/19], Loss: 0.0101\n",
      "Epoch [3/40], Step [15/19], Loss: 0.0041\n",
      "Epoch [4/40], Step [5/19], Loss: 0.0002\n",
      "Epoch [4/40], Step [10/19], Loss: 0.0032\n",
      "Epoch [4/40], Step [15/19], Loss: 0.0013\n",
      "Epoch [5/40], Step [5/19], Loss: 0.0001\n",
      "Epoch [5/40], Step [10/19], Loss: 0.0017\n",
      "Epoch [5/40], Step [15/19], Loss: 0.0007\n",
      "Epoch [6/40], Step [5/19], Loss: 0.0001\n",
      "Epoch [6/40], Step [10/19], Loss: 0.0011\n",
      "Epoch [6/40], Step [15/19], Loss: 0.0005\n",
      "Epoch [7/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [7/40], Step [10/19], Loss: 0.0008\n",
      "Epoch [7/40], Step [15/19], Loss: 0.0004\n",
      "Epoch [8/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [8/40], Step [10/19], Loss: 0.0006\n",
      "Epoch [8/40], Step [15/19], Loss: 0.0003\n",
      "Epoch [9/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [9/40], Step [10/19], Loss: 0.0005\n",
      "Epoch [9/40], Step [15/19], Loss: 0.0002\n",
      "Epoch [10/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [10/40], Step [10/19], Loss: 0.0004\n",
      "Epoch [10/40], Step [15/19], Loss: 0.0002\n",
      "Epoch [11/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [11/40], Step [10/19], Loss: 0.0004\n",
      "Epoch [11/40], Step [15/19], Loss: 0.0002\n",
      "Epoch [12/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [12/40], Step [10/19], Loss: 0.0003\n",
      "Epoch [12/40], Step [15/19], Loss: 0.0001\n",
      "Epoch [13/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [13/40], Step [10/19], Loss: 0.0003\n",
      "Epoch [13/40], Step [15/19], Loss: 0.0001\n",
      "Epoch [14/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [14/40], Step [10/19], Loss: 0.0002\n",
      "Epoch [14/40], Step [15/19], Loss: 0.0001\n",
      "Epoch [15/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [15/40], Step [10/19], Loss: 0.0002\n",
      "Epoch [15/40], Step [15/19], Loss: 0.0001\n",
      "Epoch [16/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [16/40], Step [10/19], Loss: 0.0002\n",
      "Epoch [16/40], Step [15/19], Loss: 0.0001\n",
      "Epoch [17/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [17/40], Step [10/19], Loss: 0.0002\n",
      "Epoch [17/40], Step [15/19], Loss: 0.0001\n",
      "Epoch [18/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [18/40], Step [10/19], Loss: 0.0002\n",
      "Epoch [18/40], Step [15/19], Loss: 0.0001\n",
      "Epoch [19/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [19/40], Step [10/19], Loss: 0.0001\n",
      "Epoch [19/40], Step [15/19], Loss: 0.0001\n",
      "Epoch [20/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [20/40], Step [10/19], Loss: 0.0001\n",
      "Epoch [20/40], Step [15/19], Loss: 0.0001\n",
      "Epoch [21/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [21/40], Step [10/19], Loss: 0.0001\n",
      "Epoch [21/40], Step [15/19], Loss: 0.0001\n",
      "Epoch [22/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [22/40], Step [10/19], Loss: 0.0001\n",
      "Epoch [22/40], Step [15/19], Loss: 0.0000\n",
      "Epoch [23/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [23/40], Step [10/19], Loss: 0.0001\n",
      "Epoch [23/40], Step [15/19], Loss: 0.0000\n",
      "Epoch [24/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [24/40], Step [10/19], Loss: 0.0001\n",
      "Epoch [24/40], Step [15/19], Loss: 0.0000\n",
      "Epoch [25/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [25/40], Step [10/19], Loss: 0.0001\n",
      "Epoch [25/40], Step [15/19], Loss: 0.0000\n",
      "Epoch [26/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [26/40], Step [10/19], Loss: 0.0001\n",
      "Epoch [26/40], Step [15/19], Loss: 0.0000\n",
      "Epoch [27/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [27/40], Step [10/19], Loss: 0.0001\n",
      "Epoch [27/40], Step [15/19], Loss: 0.0000\n",
      "Epoch [28/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [28/40], Step [10/19], Loss: 0.0001\n",
      "Epoch [28/40], Step [15/19], Loss: 0.0000\n",
      "Epoch [29/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [29/40], Step [10/19], Loss: 0.0001\n",
      "Epoch [29/40], Step [15/19], Loss: 0.0000\n",
      "Epoch [30/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [30/40], Step [10/19], Loss: 0.0001\n",
      "Epoch [30/40], Step [15/19], Loss: 0.0000\n",
      "Epoch [31/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [31/40], Step [10/19], Loss: 0.0001\n",
      "Epoch [31/40], Step [15/19], Loss: 0.0000\n",
      "Epoch [32/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [32/40], Step [10/19], Loss: 0.0001\n",
      "Epoch [32/40], Step [15/19], Loss: 0.0000\n",
      "Epoch [33/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [33/40], Step [10/19], Loss: 0.0001\n",
      "Epoch [33/40], Step [15/19], Loss: 0.0000\n",
      "Epoch [34/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [34/40], Step [10/19], Loss: 0.0000\n",
      "Epoch [34/40], Step [15/19], Loss: 0.0000\n",
      "Epoch [35/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [35/40], Step [10/19], Loss: 0.0000\n",
      "Epoch [35/40], Step [15/19], Loss: 0.0000\n",
      "Epoch [36/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [36/40], Step [10/19], Loss: 0.0000\n",
      "Epoch [36/40], Step [15/19], Loss: 0.0000\n",
      "Epoch [37/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [37/40], Step [10/19], Loss: 0.0000\n",
      "Epoch [37/40], Step [15/19], Loss: 0.0000\n",
      "Epoch [38/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [38/40], Step [10/19], Loss: 0.0000\n",
      "Epoch [38/40], Step [15/19], Loss: 0.0000\n",
      "Epoch [39/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [39/40], Step [10/19], Loss: 0.0000\n",
      "Epoch [39/40], Step [15/19], Loss: 0.0000\n",
      "Epoch [40/40], Step [5/19], Loss: 0.0000\n",
      "Epoch [40/40], Step [10/19], Loss: 0.0000\n",
      "Epoch [40/40], Step [15/19], Loss: 0.0000\n",
      "Test accuracy of the network: 88.88888888888889 %\n",
      "Train accuracy of the network: 100.0 %\n",
      "Epoch [1/50], Step [5/19], Loss: 0.3936\n",
      "Epoch [1/50], Step [10/19], Loss: 0.4929\n",
      "Epoch [1/50], Step [15/19], Loss: 0.1851\n",
      "Epoch [2/50], Step [5/19], Loss: 0.0110\n",
      "Epoch [2/50], Step [10/19], Loss: 0.1077\n",
      "Epoch [2/50], Step [15/19], Loss: 0.0416\n",
      "Epoch [3/50], Step [5/19], Loss: 0.0006\n",
      "Epoch [3/50], Step [10/19], Loss: 0.0101\n",
      "Epoch [3/50], Step [15/19], Loss: 0.0041\n",
      "Epoch [4/50], Step [5/19], Loss: 0.0002\n",
      "Epoch [4/50], Step [10/19], Loss: 0.0032\n",
      "Epoch [4/50], Step [15/19], Loss: 0.0013\n",
      "Epoch [5/50], Step [5/19], Loss: 0.0001\n",
      "Epoch [5/50], Step [10/19], Loss: 0.0017\n",
      "Epoch [5/50], Step [15/19], Loss: 0.0007\n",
      "Epoch [6/50], Step [5/19], Loss: 0.0001\n",
      "Epoch [6/50], Step [10/19], Loss: 0.0011\n",
      "Epoch [6/50], Step [15/19], Loss: 0.0005\n",
      "Epoch [7/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [7/50], Step [10/19], Loss: 0.0008\n",
      "Epoch [7/50], Step [15/19], Loss: 0.0004\n",
      "Epoch [8/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [8/50], Step [10/19], Loss: 0.0006\n",
      "Epoch [8/50], Step [15/19], Loss: 0.0003\n",
      "Epoch [9/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [9/50], Step [10/19], Loss: 0.0005\n",
      "Epoch [9/50], Step [15/19], Loss: 0.0002\n",
      "Epoch [10/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [10/50], Step [10/19], Loss: 0.0004\n",
      "Epoch [10/50], Step [15/19], Loss: 0.0002\n",
      "Epoch [11/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [11/50], Step [10/19], Loss: 0.0004\n",
      "Epoch [11/50], Step [15/19], Loss: 0.0002\n",
      "Epoch [12/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [12/50], Step [10/19], Loss: 0.0003\n",
      "Epoch [12/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [13/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [13/50], Step [10/19], Loss: 0.0003\n",
      "Epoch [13/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [14/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [14/50], Step [10/19], Loss: 0.0002\n",
      "Epoch [14/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [15/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [15/50], Step [10/19], Loss: 0.0002\n",
      "Epoch [15/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [16/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [16/50], Step [10/19], Loss: 0.0002\n",
      "Epoch [16/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [17/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [17/50], Step [10/19], Loss: 0.0002\n",
      "Epoch [17/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [18/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [18/50], Step [10/19], Loss: 0.0002\n",
      "Epoch [18/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [19/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [19/50], Step [10/19], Loss: 0.0001\n",
      "Epoch [19/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [20/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [20/50], Step [10/19], Loss: 0.0001\n",
      "Epoch [20/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [21/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [21/50], Step [10/19], Loss: 0.0001\n",
      "Epoch [21/50], Step [15/19], Loss: 0.0001\n",
      "Epoch [22/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [22/50], Step [10/19], Loss: 0.0001\n",
      "Epoch [22/50], Step [15/19], Loss: 0.0000\n",
      "Epoch [23/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [23/50], Step [10/19], Loss: 0.0001\n",
      "Epoch [23/50], Step [15/19], Loss: 0.0000\n",
      "Epoch [24/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [24/50], Step [10/19], Loss: 0.0001\n",
      "Epoch [24/50], Step [15/19], Loss: 0.0000\n",
      "Epoch [25/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [25/50], Step [10/19], Loss: 0.0001\n",
      "Epoch [25/50], Step [15/19], Loss: 0.0000\n",
      "Epoch [26/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [26/50], Step [10/19], Loss: 0.0001\n",
      "Epoch [26/50], Step [15/19], Loss: 0.0000\n",
      "Epoch [27/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [27/50], Step [10/19], Loss: 0.0001\n",
      "Epoch [27/50], Step [15/19], Loss: 0.0000\n",
      "Epoch [28/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [28/50], Step [10/19], Loss: 0.0001\n",
      "Epoch [28/50], Step [15/19], Loss: 0.0000\n",
      "Epoch [29/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [29/50], Step [10/19], Loss: 0.0001\n",
      "Epoch [29/50], Step [15/19], Loss: 0.0000\n",
      "Epoch [30/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [30/50], Step [10/19], Loss: 0.0001\n",
      "Epoch [30/50], Step [15/19], Loss: 0.0000\n",
      "Epoch [31/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [31/50], Step [10/19], Loss: 0.0001\n",
      "Epoch [31/50], Step [15/19], Loss: 0.0000\n",
      "Epoch [32/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [32/50], Step [10/19], Loss: 0.0001\n",
      "Epoch [32/50], Step [15/19], Loss: 0.0000\n",
      "Epoch [33/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [33/50], Step [10/19], Loss: 0.0001\n",
      "Epoch [33/50], Step [15/19], Loss: 0.0000\n",
      "Epoch [34/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [34/50], Step [10/19], Loss: 0.0000\n",
      "Epoch [34/50], Step [15/19], Loss: 0.0000\n",
      "Epoch [35/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [35/50], Step [10/19], Loss: 0.0000\n",
      "Epoch [35/50], Step [15/19], Loss: 0.0000\n",
      "Epoch [36/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [36/50], Step [10/19], Loss: 0.0000\n",
      "Epoch [36/50], Step [15/19], Loss: 0.0000\n",
      "Epoch [37/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [37/50], Step [10/19], Loss: 0.0000\n",
      "Epoch [37/50], Step [15/19], Loss: 0.0000\n",
      "Epoch [38/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [38/50], Step [10/19], Loss: 0.0000\n",
      "Epoch [38/50], Step [15/19], Loss: 0.0000\n",
      "Epoch [39/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [39/50], Step [10/19], Loss: 0.0000\n",
      "Epoch [39/50], Step [15/19], Loss: 0.0000\n",
      "Epoch [40/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [40/50], Step [10/19], Loss: 0.0000\n",
      "Epoch [40/50], Step [15/19], Loss: 0.0000\n",
      "Epoch [41/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [41/50], Step [10/19], Loss: 0.0000\n",
      "Epoch [41/50], Step [15/19], Loss: 0.0000\n",
      "Epoch [42/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [42/50], Step [10/19], Loss: 0.0000\n",
      "Epoch [42/50], Step [15/19], Loss: 0.0000\n",
      "Epoch [43/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [43/50], Step [10/19], Loss: 0.0000\n",
      "Epoch [43/50], Step [15/19], Loss: 0.0000\n",
      "Epoch [44/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [44/50], Step [10/19], Loss: 0.0000\n",
      "Epoch [44/50], Step [15/19], Loss: 0.0000\n",
      "Epoch [45/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [45/50], Step [10/19], Loss: 0.0000\n",
      "Epoch [45/50], Step [15/19], Loss: 0.0000\n",
      "Epoch [46/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [46/50], Step [10/19], Loss: 0.0000\n",
      "Epoch [46/50], Step [15/19], Loss: 0.0000\n",
      "Epoch [47/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [47/50], Step [10/19], Loss: 0.0000\n",
      "Epoch [47/50], Step [15/19], Loss: 0.0000\n",
      "Epoch [48/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [48/50], Step [10/19], Loss: 0.0000\n",
      "Epoch [48/50], Step [15/19], Loss: 0.0000\n",
      "Epoch [49/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [49/50], Step [10/19], Loss: 0.0000\n",
      "Epoch [49/50], Step [15/19], Loss: 0.0000\n",
      "Epoch [50/50], Step [5/19], Loss: 0.0000\n",
      "Epoch [50/50], Step [10/19], Loss: 0.0000\n",
      "Epoch [50/50], Step [15/19], Loss: 0.0000\n",
      "Test accuracy of the network: 89.00343642611683 %\n",
      "Train accuracy of the network: 100.0 %\n",
      "Epoch [1/60], Step [5/19], Loss: 0.3936\n",
      "Epoch [1/60], Step [10/19], Loss: 0.4929\n",
      "Epoch [1/60], Step [15/19], Loss: 0.1851\n",
      "Epoch [2/60], Step [5/19], Loss: 0.0110\n",
      "Epoch [2/60], Step [10/19], Loss: 0.1077\n",
      "Epoch [2/60], Step [15/19], Loss: 0.0416\n",
      "Epoch [3/60], Step [5/19], Loss: 0.0006\n",
      "Epoch [3/60], Step [10/19], Loss: 0.0101\n",
      "Epoch [3/60], Step [15/19], Loss: 0.0041\n",
      "Epoch [4/60], Step [5/19], Loss: 0.0002\n",
      "Epoch [4/60], Step [10/19], Loss: 0.0032\n",
      "Epoch [4/60], Step [15/19], Loss: 0.0013\n",
      "Epoch [5/60], Step [5/19], Loss: 0.0001\n",
      "Epoch [5/60], Step [10/19], Loss: 0.0017\n",
      "Epoch [5/60], Step [15/19], Loss: 0.0007\n",
      "Epoch [6/60], Step [5/19], Loss: 0.0001\n",
      "Epoch [6/60], Step [10/19], Loss: 0.0011\n",
      "Epoch [6/60], Step [15/19], Loss: 0.0005\n",
      "Epoch [7/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [7/60], Step [10/19], Loss: 0.0008\n",
      "Epoch [7/60], Step [15/19], Loss: 0.0004\n",
      "Epoch [8/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [8/60], Step [10/19], Loss: 0.0006\n",
      "Epoch [8/60], Step [15/19], Loss: 0.0003\n",
      "Epoch [9/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [9/60], Step [10/19], Loss: 0.0005\n",
      "Epoch [9/60], Step [15/19], Loss: 0.0002\n",
      "Epoch [10/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [10/60], Step [10/19], Loss: 0.0004\n",
      "Epoch [10/60], Step [15/19], Loss: 0.0002\n",
      "Epoch [11/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [11/60], Step [10/19], Loss: 0.0004\n",
      "Epoch [11/60], Step [15/19], Loss: 0.0002\n",
      "Epoch [12/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [12/60], Step [10/19], Loss: 0.0003\n",
      "Epoch [12/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [13/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [13/60], Step [10/19], Loss: 0.0003\n",
      "Epoch [13/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [14/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [14/60], Step [10/19], Loss: 0.0002\n",
      "Epoch [14/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [15/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [15/60], Step [10/19], Loss: 0.0002\n",
      "Epoch [15/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [16/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [16/60], Step [10/19], Loss: 0.0002\n",
      "Epoch [16/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [17/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [17/60], Step [10/19], Loss: 0.0002\n",
      "Epoch [17/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [18/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [18/60], Step [10/19], Loss: 0.0002\n",
      "Epoch [18/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [19/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [19/60], Step [10/19], Loss: 0.0001\n",
      "Epoch [19/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [20/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [20/60], Step [10/19], Loss: 0.0001\n",
      "Epoch [20/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [21/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [21/60], Step [10/19], Loss: 0.0001\n",
      "Epoch [21/60], Step [15/19], Loss: 0.0001\n",
      "Epoch [22/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [22/60], Step [10/19], Loss: 0.0001\n",
      "Epoch [22/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [23/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [23/60], Step [10/19], Loss: 0.0001\n",
      "Epoch [23/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [24/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [24/60], Step [10/19], Loss: 0.0001\n",
      "Epoch [24/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [25/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [25/60], Step [10/19], Loss: 0.0001\n",
      "Epoch [25/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [26/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [26/60], Step [10/19], Loss: 0.0001\n",
      "Epoch [26/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [27/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [27/60], Step [10/19], Loss: 0.0001\n",
      "Epoch [27/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [28/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [28/60], Step [10/19], Loss: 0.0001\n",
      "Epoch [28/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [29/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [29/60], Step [10/19], Loss: 0.0001\n",
      "Epoch [29/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [30/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [30/60], Step [10/19], Loss: 0.0001\n",
      "Epoch [30/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [31/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [31/60], Step [10/19], Loss: 0.0001\n",
      "Epoch [31/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [32/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [32/60], Step [10/19], Loss: 0.0001\n",
      "Epoch [32/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [33/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [33/60], Step [10/19], Loss: 0.0001\n",
      "Epoch [33/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [34/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [34/60], Step [10/19], Loss: 0.0000\n",
      "Epoch [34/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [35/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [35/60], Step [10/19], Loss: 0.0000\n",
      "Epoch [35/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [36/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [36/60], Step [10/19], Loss: 0.0000\n",
      "Epoch [36/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [37/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [37/60], Step [10/19], Loss: 0.0000\n",
      "Epoch [37/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [38/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [38/60], Step [10/19], Loss: 0.0000\n",
      "Epoch [38/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [39/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [39/60], Step [10/19], Loss: 0.0000\n",
      "Epoch [39/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [40/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [40/60], Step [10/19], Loss: 0.0000\n",
      "Epoch [40/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [41/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [41/60], Step [10/19], Loss: 0.0000\n",
      "Epoch [41/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [42/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [42/60], Step [10/19], Loss: 0.0000\n",
      "Epoch [42/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [43/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [43/60], Step [10/19], Loss: 0.0000\n",
      "Epoch [43/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [44/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [44/60], Step [10/19], Loss: 0.0000\n",
      "Epoch [44/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [45/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [45/60], Step [10/19], Loss: 0.0000\n",
      "Epoch [45/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [46/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [46/60], Step [10/19], Loss: 0.0000\n",
      "Epoch [46/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [47/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [47/60], Step [10/19], Loss: 0.0000\n",
      "Epoch [47/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [48/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [48/60], Step [10/19], Loss: 0.0000\n",
      "Epoch [48/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [49/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [49/60], Step [10/19], Loss: 0.0000\n",
      "Epoch [49/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [50/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [50/60], Step [10/19], Loss: 0.0000\n",
      "Epoch [50/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [51/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [51/60], Step [10/19], Loss: 0.0000\n",
      "Epoch [51/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [52/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [52/60], Step [10/19], Loss: 0.0000\n",
      "Epoch [52/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [53/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [53/60], Step [10/19], Loss: 0.0000\n",
      "Epoch [53/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [54/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [54/60], Step [10/19], Loss: 0.0000\n",
      "Epoch [54/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [55/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [55/60], Step [10/19], Loss: 0.0000\n",
      "Epoch [55/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [56/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [56/60], Step [10/19], Loss: 0.0000\n",
      "Epoch [56/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [57/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [57/60], Step [10/19], Loss: 0.0000\n",
      "Epoch [57/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [58/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [58/60], Step [10/19], Loss: 0.0000\n",
      "Epoch [58/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [59/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [59/60], Step [10/19], Loss: 0.0000\n",
      "Epoch [59/60], Step [15/19], Loss: 0.0000\n",
      "Epoch [60/60], Step [5/19], Loss: 0.0000\n",
      "Epoch [60/60], Step [10/19], Loss: 0.0000\n",
      "Epoch [60/60], Step [15/19], Loss: 0.0000\n",
      "Test accuracy of the network: 89.46162657502863 %\n",
      "Train accuracy of the network: 100.0 %\n",
      "Epoch [1/75], Step [5/19], Loss: 0.3936\n",
      "Epoch [1/75], Step [10/19], Loss: 0.4929\n",
      "Epoch [1/75], Step [15/19], Loss: 0.1851\n",
      "Epoch [2/75], Step [5/19], Loss: 0.0110\n",
      "Epoch [2/75], Step [10/19], Loss: 0.1077\n",
      "Epoch [2/75], Step [15/19], Loss: 0.0416\n",
      "Epoch [3/75], Step [5/19], Loss: 0.0006\n",
      "Epoch [3/75], Step [10/19], Loss: 0.0101\n",
      "Epoch [3/75], Step [15/19], Loss: 0.0041\n",
      "Epoch [4/75], Step [5/19], Loss: 0.0002\n",
      "Epoch [4/75], Step [10/19], Loss: 0.0032\n",
      "Epoch [4/75], Step [15/19], Loss: 0.0013\n",
      "Epoch [5/75], Step [5/19], Loss: 0.0001\n",
      "Epoch [5/75], Step [10/19], Loss: 0.0017\n",
      "Epoch [5/75], Step [15/19], Loss: 0.0007\n",
      "Epoch [6/75], Step [5/19], Loss: 0.0001\n",
      "Epoch [6/75], Step [10/19], Loss: 0.0011\n",
      "Epoch [6/75], Step [15/19], Loss: 0.0005\n",
      "Epoch [7/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [7/75], Step [10/19], Loss: 0.0008\n",
      "Epoch [7/75], Step [15/19], Loss: 0.0004\n",
      "Epoch [8/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [8/75], Step [10/19], Loss: 0.0006\n",
      "Epoch [8/75], Step [15/19], Loss: 0.0003\n",
      "Epoch [9/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [9/75], Step [10/19], Loss: 0.0005\n",
      "Epoch [9/75], Step [15/19], Loss: 0.0002\n",
      "Epoch [10/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [10/75], Step [10/19], Loss: 0.0004\n",
      "Epoch [10/75], Step [15/19], Loss: 0.0002\n",
      "Epoch [11/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [11/75], Step [10/19], Loss: 0.0004\n",
      "Epoch [11/75], Step [15/19], Loss: 0.0002\n",
      "Epoch [12/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [12/75], Step [10/19], Loss: 0.0003\n",
      "Epoch [12/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [13/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [13/75], Step [10/19], Loss: 0.0003\n",
      "Epoch [13/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [14/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [14/75], Step [10/19], Loss: 0.0002\n",
      "Epoch [14/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [15/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [15/75], Step [10/19], Loss: 0.0002\n",
      "Epoch [15/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [16/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [16/75], Step [10/19], Loss: 0.0002\n",
      "Epoch [16/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [17/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [17/75], Step [10/19], Loss: 0.0002\n",
      "Epoch [17/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [18/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [18/75], Step [10/19], Loss: 0.0002\n",
      "Epoch [18/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [19/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [19/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [19/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [20/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [20/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [20/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [21/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [21/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [21/75], Step [15/19], Loss: 0.0001\n",
      "Epoch [22/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [22/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [22/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [23/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [23/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [23/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [24/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [24/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [24/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [25/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [25/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [25/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [26/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [26/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [26/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [27/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [27/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [27/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [28/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [28/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [28/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [29/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [29/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [29/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [30/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [30/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [30/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [31/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [31/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [31/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [32/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [32/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [32/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [33/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [33/75], Step [10/19], Loss: 0.0001\n",
      "Epoch [33/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [34/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [34/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [34/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [35/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [35/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [35/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [36/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [36/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [36/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [37/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [37/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [37/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [38/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [38/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [38/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [39/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [39/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [39/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [40/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [40/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [40/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [41/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [41/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [41/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [42/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [42/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [42/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [43/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [43/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [43/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [44/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [44/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [44/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [45/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [45/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [45/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [46/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [46/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [46/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [47/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [47/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [47/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [48/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [48/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [48/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [49/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [49/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [49/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [50/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [50/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [50/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [51/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [51/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [51/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [52/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [52/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [52/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [53/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [53/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [53/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [54/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [54/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [54/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [55/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [55/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [55/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [56/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [56/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [56/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [57/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [57/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [57/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [58/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [58/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [58/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [59/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [59/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [59/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [60/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [60/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [60/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [61/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [61/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [61/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [62/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [62/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [62/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [63/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [63/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [63/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [64/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [64/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [64/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [65/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [65/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [65/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [66/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [66/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [66/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [67/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [67/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [67/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [68/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [68/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [68/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [69/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [69/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [69/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [70/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [70/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [70/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [71/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [71/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [71/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [72/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [72/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [72/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [73/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [73/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [73/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [74/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [74/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [74/75], Step [15/19], Loss: 0.0000\n",
      "Epoch [75/75], Step [5/19], Loss: 0.0000\n",
      "Epoch [75/75], Step [10/19], Loss: 0.0000\n",
      "Epoch [75/75], Step [15/19], Loss: 0.0000\n",
      "Test accuracy of the network: 89.57617411225658 %\n",
      "Train accuracy of the network: 100.0 %\n",
      "Epoch [1/100], Step [5/19], Loss: 0.3936\n",
      "Epoch [1/100], Step [10/19], Loss: 0.4929\n",
      "Epoch [1/100], Step [15/19], Loss: 0.1851\n",
      "Epoch [2/100], Step [5/19], Loss: 0.0110\n",
      "Epoch [2/100], Step [10/19], Loss: 0.1077\n",
      "Epoch [2/100], Step [15/19], Loss: 0.0416\n",
      "Epoch [3/100], Step [5/19], Loss: 0.0006\n",
      "Epoch [3/100], Step [10/19], Loss: 0.0101\n",
      "Epoch [3/100], Step [15/19], Loss: 0.0041\n",
      "Epoch [4/100], Step [5/19], Loss: 0.0002\n",
      "Epoch [4/100], Step [10/19], Loss: 0.0032\n",
      "Epoch [4/100], Step [15/19], Loss: 0.0013\n",
      "Epoch [5/100], Step [5/19], Loss: 0.0001\n",
      "Epoch [5/100], Step [10/19], Loss: 0.0017\n",
      "Epoch [5/100], Step [15/19], Loss: 0.0007\n",
      "Epoch [6/100], Step [5/19], Loss: 0.0001\n",
      "Epoch [6/100], Step [10/19], Loss: 0.0011\n",
      "Epoch [6/100], Step [15/19], Loss: 0.0005\n",
      "Epoch [7/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [7/100], Step [10/19], Loss: 0.0008\n",
      "Epoch [7/100], Step [15/19], Loss: 0.0004\n",
      "Epoch [8/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [8/100], Step [10/19], Loss: 0.0006\n",
      "Epoch [8/100], Step [15/19], Loss: 0.0003\n",
      "Epoch [9/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [9/100], Step [10/19], Loss: 0.0005\n",
      "Epoch [9/100], Step [15/19], Loss: 0.0002\n",
      "Epoch [10/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [10/100], Step [10/19], Loss: 0.0004\n",
      "Epoch [10/100], Step [15/19], Loss: 0.0002\n",
      "Epoch [11/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [11/100], Step [10/19], Loss: 0.0004\n",
      "Epoch [11/100], Step [15/19], Loss: 0.0002\n",
      "Epoch [12/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [12/100], Step [10/19], Loss: 0.0003\n",
      "Epoch [12/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [13/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [13/100], Step [10/19], Loss: 0.0003\n",
      "Epoch [13/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [14/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [14/100], Step [10/19], Loss: 0.0002\n",
      "Epoch [14/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [15/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [15/100], Step [10/19], Loss: 0.0002\n",
      "Epoch [15/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [16/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [16/100], Step [10/19], Loss: 0.0002\n",
      "Epoch [16/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [17/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [17/100], Step [10/19], Loss: 0.0002\n",
      "Epoch [17/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [18/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [18/100], Step [10/19], Loss: 0.0002\n",
      "Epoch [18/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [19/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [19/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [19/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [20/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [20/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [20/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [21/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [21/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [21/100], Step [15/19], Loss: 0.0001\n",
      "Epoch [22/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [22/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [22/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [23/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [23/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [23/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [24/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [24/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [24/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [25/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [25/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [25/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [26/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [26/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [26/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [27/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [27/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [27/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [28/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [28/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [28/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [29/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [29/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [29/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [30/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [30/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [30/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [31/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [31/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [31/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [32/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [32/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [32/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [33/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [33/100], Step [10/19], Loss: 0.0001\n",
      "Epoch [33/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [34/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [34/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [34/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [35/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [35/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [35/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [36/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [36/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [36/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [37/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [37/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [37/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [38/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [38/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [38/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [39/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [39/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [39/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [40/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [40/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [40/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [41/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [41/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [41/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [42/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [42/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [42/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [43/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [43/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [43/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [44/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [44/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [44/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [45/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [45/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [45/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [46/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [46/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [46/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [47/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [47/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [47/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [48/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [48/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [48/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [49/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [49/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [49/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [50/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [50/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [50/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [51/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [51/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [51/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [52/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [52/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [52/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [53/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [53/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [53/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [54/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [54/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [54/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [55/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [55/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [55/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [56/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [56/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [56/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [57/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [57/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [57/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [58/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [58/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [58/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [59/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [59/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [59/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [60/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [60/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [60/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [61/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [61/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [61/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [62/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [62/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [62/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [63/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [63/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [63/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [64/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [64/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [64/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [65/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [65/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [65/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [66/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [66/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [66/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [67/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [67/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [67/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [68/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [68/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [68/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [69/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [69/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [69/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [70/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [70/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [70/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [71/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [71/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [71/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [72/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [72/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [72/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [73/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [73/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [73/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [74/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [74/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [74/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [75/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [75/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [75/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [76/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [76/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [76/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [77/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [77/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [77/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [78/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [78/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [78/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [79/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [79/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [79/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [80/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [80/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [80/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [81/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [81/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [81/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [82/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [82/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [82/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [83/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [83/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [83/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [84/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [84/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [84/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [85/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [85/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [85/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [86/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [86/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [86/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [87/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [87/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [87/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [88/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [88/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [88/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [89/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [89/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [89/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [90/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [90/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [90/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [91/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [91/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [91/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [92/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [92/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [92/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [93/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [93/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [93/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [94/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [94/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [94/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [95/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [95/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [95/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [96/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [96/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [96/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [97/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [97/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [97/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [98/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [98/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [98/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [99/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [99/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [99/100], Step [15/19], Loss: 0.0000\n",
      "Epoch [100/100], Step [5/19], Loss: 0.0000\n",
      "Epoch [100/100], Step [10/19], Loss: 0.0000\n",
      "Epoch [100/100], Step [15/19], Loss: 0.0000\n",
      "Test accuracy of the network: 89.69072164948453 %\n",
      "Train accuracy of the network: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "corona_test_accuracies2 = []\n",
    "corona_train_accuracies2 = []\n",
    "\n",
    "for num_epoch in num_epochs_used:\n",
    "    test_accuracy, train_accuracy = trainAndTestTwoHiddenLayerModel('corona', num_epochs=num_epoch)\n",
    "    corona_test_accuracies2.append(test_accuracy)\n",
    "    corona_train_accuracies2.append(train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "ax.plot(num_epochs_used, corona_train_accuracies2, 'r-', lw=3, label='Train Accuracy')\n",
    "ax.plot(num_epochs_used, corona_test_accuracies2, 'g-', lw=3, label='Test Accuracy')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15052, 4893)\n",
      "Epoch [1/1], Step [500/941], Loss: 0.4970\n",
      "Test accuracy of the network: 70.37914691943128 %\n",
      "Train accuracy of the network: 79.83656656922668 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15052, 4893)\n",
      "Epoch [1/5], Step [500/941], Loss: 0.4970\n",
      "Epoch [2/5], Step [500/941], Loss: 0.4629\n",
      "Epoch [3/5], Step [500/941], Loss: 0.1473\n",
      "Epoch [4/5], Step [500/941], Loss: 0.0734\n",
      "Epoch [5/5], Step [500/941], Loss: 0.4773\n",
      "Test accuracy of the network: 69.66824644549763 %\n",
      "Train accuracy of the network: 91.26361945256444 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15052, 4893)\n",
      "Epoch [1/10], Step [500/941], Loss: 0.4970\n",
      "Epoch [2/10], Step [500/941], Loss: 0.4629\n",
      "Epoch [3/10], Step [500/941], Loss: 0.1473\n",
      "Epoch [4/10], Step [500/941], Loss: 0.0734\n",
      "Epoch [5/10], Step [500/941], Loss: 0.4773\n",
      "Epoch [6/10], Step [500/941], Loss: 0.0117\n",
      "Epoch [7/10], Step [500/941], Loss: 0.0128\n",
      "Epoch [8/10], Step [500/941], Loss: 0.0339\n",
      "Epoch [9/10], Step [500/941], Loss: 0.0121\n",
      "Epoch [10/10], Step [500/941], Loss: 0.2970\n",
      "Test accuracy of the network: 70.61611374407583 %\n",
      "Train accuracy of the network: 96.93728408184958 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15052, 4893)\n",
      "Epoch [1/20], Step [500/941], Loss: 0.4970\n",
      "Epoch [2/20], Step [500/941], Loss: 0.4629\n",
      "Epoch [3/20], Step [500/941], Loss: 0.1473\n",
      "Epoch [4/20], Step [500/941], Loss: 0.0734\n",
      "Epoch [5/20], Step [500/941], Loss: 0.4773\n",
      "Epoch [6/20], Step [500/941], Loss: 0.0117\n",
      "Epoch [7/20], Step [500/941], Loss: 0.0128\n",
      "Epoch [8/20], Step [500/941], Loss: 0.0339\n",
      "Epoch [9/20], Step [500/941], Loss: 0.0121\n",
      "Epoch [10/20], Step [500/941], Loss: 0.2970\n",
      "Epoch [11/20], Step [500/941], Loss: 0.0024\n",
      "Epoch [12/20], Step [500/941], Loss: 0.0047\n",
      "Epoch [13/20], Step [500/941], Loss: 0.0063\n",
      "Epoch [14/20], Step [500/941], Loss: 0.0060\n",
      "Epoch [15/20], Step [500/941], Loss: 0.0009\n",
      "Epoch [16/20], Step [500/941], Loss: 0.0033\n",
      "Epoch [17/20], Step [500/941], Loss: 0.0003\n",
      "Epoch [18/20], Step [500/941], Loss: 0.0009\n",
      "Epoch [19/20], Step [500/941], Loss: 0.0103\n",
      "Epoch [20/20], Step [500/941], Loss: 0.0001\n",
      "Test accuracy of the network: 70.06319115323855 %\n",
      "Train accuracy of the network: 99.32234918947648 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15052, 4893)\n",
      "Epoch [1/30], Step [500/941], Loss: 0.4970\n",
      "Epoch [2/30], Step [500/941], Loss: 0.4629\n",
      "Epoch [3/30], Step [500/941], Loss: 0.1473\n",
      "Epoch [4/30], Step [500/941], Loss: 0.0734\n",
      "Epoch [5/30], Step [500/941], Loss: 0.4773\n",
      "Epoch [6/30], Step [500/941], Loss: 0.0117\n",
      "Epoch [7/30], Step [500/941], Loss: 0.0128\n",
      "Epoch [8/30], Step [500/941], Loss: 0.0339\n",
      "Epoch [9/30], Step [500/941], Loss: 0.0121\n",
      "Epoch [10/30], Step [500/941], Loss: 0.2970\n",
      "Epoch [11/30], Step [500/941], Loss: 0.0024\n",
      "Epoch [12/30], Step [500/941], Loss: 0.0047\n",
      "Epoch [13/30], Step [500/941], Loss: 0.0063\n",
      "Epoch [14/30], Step [500/941], Loss: 0.0060\n",
      "Epoch [15/30], Step [500/941], Loss: 0.0009\n",
      "Epoch [16/30], Step [500/941], Loss: 0.0033\n",
      "Epoch [17/30], Step [500/941], Loss: 0.0003\n",
      "Epoch [18/30], Step [500/941], Loss: 0.0009\n",
      "Epoch [19/30], Step [500/941], Loss: 0.0103\n",
      "Epoch [20/30], Step [500/941], Loss: 0.0001\n",
      "Epoch [21/30], Step [500/941], Loss: 0.0000\n",
      "Epoch [22/30], Step [500/941], Loss: 0.0319\n",
      "Epoch [23/30], Step [500/941], Loss: 0.0006\n",
      "Epoch [24/30], Step [500/941], Loss: 0.0001\n",
      "Epoch [25/30], Step [500/941], Loss: 0.0000\n",
      "Epoch [26/30], Step [500/941], Loss: 0.0001\n",
      "Epoch [27/30], Step [500/941], Loss: 0.0001\n",
      "Epoch [28/30], Step [500/941], Loss: 0.0001\n",
      "Epoch [29/30], Step [500/941], Loss: 0.0002\n",
      "Epoch [30/30], Step [500/941], Loss: 0.0001\n",
      "Test accuracy of the network: 69.90521327014218 %\n",
      "Train accuracy of the network: 99.96013818761627 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15052, 4893)\n",
      "Epoch [1/40], Step [500/941], Loss: 0.4970\n",
      "Epoch [2/40], Step [500/941], Loss: 0.4629\n",
      "Epoch [3/40], Step [500/941], Loss: 0.1473\n",
      "Epoch [4/40], Step [500/941], Loss: 0.0734\n",
      "Epoch [5/40], Step [500/941], Loss: 0.4773\n",
      "Epoch [6/40], Step [500/941], Loss: 0.0117\n",
      "Epoch [7/40], Step [500/941], Loss: 0.0128\n",
      "Epoch [8/40], Step [500/941], Loss: 0.0339\n",
      "Epoch [9/40], Step [500/941], Loss: 0.0121\n",
      "Epoch [10/40], Step [500/941], Loss: 0.2970\n",
      "Epoch [11/40], Step [500/941], Loss: 0.0024\n",
      "Epoch [12/40], Step [500/941], Loss: 0.0047\n",
      "Epoch [13/40], Step [500/941], Loss: 0.0063\n",
      "Epoch [14/40], Step [500/941], Loss: 0.0060\n",
      "Epoch [15/40], Step [500/941], Loss: 0.0009\n",
      "Epoch [16/40], Step [500/941], Loss: 0.0033\n",
      "Epoch [17/40], Step [500/941], Loss: 0.0003\n",
      "Epoch [18/40], Step [500/941], Loss: 0.0009\n",
      "Epoch [19/40], Step [500/941], Loss: 0.0103\n",
      "Epoch [20/40], Step [500/941], Loss: 0.0001\n",
      "Epoch [21/40], Step [500/941], Loss: 0.0000\n",
      "Epoch [22/40], Step [500/941], Loss: 0.0319\n",
      "Epoch [23/40], Step [500/941], Loss: 0.0006\n",
      "Epoch [24/40], Step [500/941], Loss: 0.0001\n",
      "Epoch [25/40], Step [500/941], Loss: 0.0000\n",
      "Epoch [26/40], Step [500/941], Loss: 0.0001\n",
      "Epoch [27/40], Step [500/941], Loss: 0.0001\n",
      "Epoch [28/40], Step [500/941], Loss: 0.0001\n",
      "Epoch [29/40], Step [500/941], Loss: 0.0002\n",
      "Epoch [30/40], Step [500/941], Loss: 0.0001\n",
      "Epoch [31/40], Step [500/941], Loss: 0.0000\n",
      "Epoch [32/40], Step [500/941], Loss: 0.0034\n",
      "Epoch [33/40], Step [500/941], Loss: 0.0000\n",
      "Epoch [34/40], Step [500/941], Loss: 0.0047\n",
      "Epoch [35/40], Step [500/941], Loss: 0.0000\n",
      "Epoch [36/40], Step [500/941], Loss: 0.0011\n",
      "Epoch [37/40], Step [500/941], Loss: 0.0000\n",
      "Epoch [38/40], Step [500/941], Loss: 0.0000\n",
      "Epoch [39/40], Step [500/941], Loss: 0.0000\n",
      "Epoch [40/40], Step [500/941], Loss: 0.0000\n",
      "Test accuracy of the network: 70.14218009478672 %\n",
      "Train accuracy of the network: 99.95349455221897 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15052, 4893)\n",
      "Epoch [1/50], Step [500/941], Loss: 0.4970\n",
      "Epoch [2/50], Step [500/941], Loss: 0.4629\n",
      "Epoch [3/50], Step [500/941], Loss: 0.1473\n",
      "Epoch [4/50], Step [500/941], Loss: 0.0734\n",
      "Epoch [5/50], Step [500/941], Loss: 0.4773\n",
      "Epoch [6/50], Step [500/941], Loss: 0.0117\n",
      "Epoch [7/50], Step [500/941], Loss: 0.0128\n",
      "Epoch [8/50], Step [500/941], Loss: 0.0339\n",
      "Epoch [9/50], Step [500/941], Loss: 0.0121\n",
      "Epoch [10/50], Step [500/941], Loss: 0.2970\n",
      "Epoch [11/50], Step [500/941], Loss: 0.0024\n",
      "Epoch [12/50], Step [500/941], Loss: 0.0047\n",
      "Epoch [13/50], Step [500/941], Loss: 0.0063\n",
      "Epoch [14/50], Step [500/941], Loss: 0.0060\n",
      "Epoch [15/50], Step [500/941], Loss: 0.0009\n",
      "Epoch [16/50], Step [500/941], Loss: 0.0033\n",
      "Epoch [17/50], Step [500/941], Loss: 0.0003\n",
      "Epoch [18/50], Step [500/941], Loss: 0.0009\n",
      "Epoch [19/50], Step [500/941], Loss: 0.0103\n",
      "Epoch [20/50], Step [500/941], Loss: 0.0001\n",
      "Epoch [21/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [22/50], Step [500/941], Loss: 0.0319\n",
      "Epoch [23/50], Step [500/941], Loss: 0.0006\n",
      "Epoch [24/50], Step [500/941], Loss: 0.0001\n",
      "Epoch [25/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [26/50], Step [500/941], Loss: 0.0001\n",
      "Epoch [27/50], Step [500/941], Loss: 0.0001\n",
      "Epoch [28/50], Step [500/941], Loss: 0.0001\n",
      "Epoch [29/50], Step [500/941], Loss: 0.0002\n",
      "Epoch [30/50], Step [500/941], Loss: 0.0001\n",
      "Epoch [31/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [32/50], Step [500/941], Loss: 0.0034\n",
      "Epoch [33/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [34/50], Step [500/941], Loss: 0.0047\n",
      "Epoch [35/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [36/50], Step [500/941], Loss: 0.0011\n",
      "Epoch [37/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [38/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [39/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [40/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [41/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [42/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [43/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [44/50], Step [500/941], Loss: 0.1773\n",
      "Epoch [45/50], Step [500/941], Loss: 0.0061\n",
      "Epoch [46/50], Step [500/941], Loss: 0.0001\n",
      "Epoch [47/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [48/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [49/50], Step [500/941], Loss: 0.0000\n",
      "Epoch [50/50], Step [500/941], Loss: 0.0000\n",
      "Test accuracy of the network: 71.48499210110585 %\n",
      "Train accuracy of the network: 99.98006909380813 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15052, 4893)\n",
      "Epoch [1/60], Step [500/941], Loss: 0.4970\n",
      "Epoch [2/60], Step [500/941], Loss: 0.4629\n",
      "Epoch [3/60], Step [500/941], Loss: 0.1473\n",
      "Epoch [4/60], Step [500/941], Loss: 0.0734\n",
      "Epoch [5/60], Step [500/941], Loss: 0.4773\n",
      "Epoch [6/60], Step [500/941], Loss: 0.0117\n",
      "Epoch [7/60], Step [500/941], Loss: 0.0128\n",
      "Epoch [8/60], Step [500/941], Loss: 0.0339\n",
      "Epoch [9/60], Step [500/941], Loss: 0.0121\n",
      "Epoch [10/60], Step [500/941], Loss: 0.2970\n",
      "Epoch [11/60], Step [500/941], Loss: 0.0024\n",
      "Epoch [12/60], Step [500/941], Loss: 0.0047\n",
      "Epoch [13/60], Step [500/941], Loss: 0.0063\n",
      "Epoch [14/60], Step [500/941], Loss: 0.0060\n",
      "Epoch [15/60], Step [500/941], Loss: 0.0009\n",
      "Epoch [16/60], Step [500/941], Loss: 0.0033\n",
      "Epoch [17/60], Step [500/941], Loss: 0.0003\n",
      "Epoch [18/60], Step [500/941], Loss: 0.0009\n",
      "Epoch [19/60], Step [500/941], Loss: 0.0103\n",
      "Epoch [20/60], Step [500/941], Loss: 0.0001\n",
      "Epoch [21/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [22/60], Step [500/941], Loss: 0.0319\n",
      "Epoch [23/60], Step [500/941], Loss: 0.0006\n",
      "Epoch [24/60], Step [500/941], Loss: 0.0001\n",
      "Epoch [25/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [26/60], Step [500/941], Loss: 0.0001\n",
      "Epoch [27/60], Step [500/941], Loss: 0.0001\n",
      "Epoch [28/60], Step [500/941], Loss: 0.0001\n",
      "Epoch [29/60], Step [500/941], Loss: 0.0002\n",
      "Epoch [30/60], Step [500/941], Loss: 0.0001\n",
      "Epoch [31/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [32/60], Step [500/941], Loss: 0.0034\n",
      "Epoch [33/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [34/60], Step [500/941], Loss: 0.0047\n",
      "Epoch [35/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [36/60], Step [500/941], Loss: 0.0011\n",
      "Epoch [37/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [38/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [39/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [40/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [41/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [42/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [43/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [44/60], Step [500/941], Loss: 0.1773\n",
      "Epoch [45/60], Step [500/941], Loss: 0.0061\n",
      "Epoch [46/60], Step [500/941], Loss: 0.0001\n",
      "Epoch [47/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [48/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [49/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [50/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [51/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [52/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [53/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [54/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [55/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [56/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [57/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [58/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [59/60], Step [500/941], Loss: 0.0000\n",
      "Epoch [60/60], Step [500/941], Loss: 0.0000\n",
      "Test accuracy of the network: 70.61611374407583 %\n",
      "Train accuracy of the network: 99.97342545841084 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15052, 4893)\n",
      "Epoch [1/75], Step [500/941], Loss: 0.4970\n",
      "Epoch [2/75], Step [500/941], Loss: 0.4629\n",
      "Epoch [3/75], Step [500/941], Loss: 0.1473\n",
      "Epoch [4/75], Step [500/941], Loss: 0.0734\n",
      "Epoch [5/75], Step [500/941], Loss: 0.4773\n",
      "Epoch [6/75], Step [500/941], Loss: 0.0117\n",
      "Epoch [7/75], Step [500/941], Loss: 0.0128\n",
      "Epoch [8/75], Step [500/941], Loss: 0.0339\n",
      "Epoch [9/75], Step [500/941], Loss: 0.0121\n",
      "Epoch [10/75], Step [500/941], Loss: 0.2970\n",
      "Epoch [11/75], Step [500/941], Loss: 0.0024\n",
      "Epoch [12/75], Step [500/941], Loss: 0.0047\n",
      "Epoch [13/75], Step [500/941], Loss: 0.0063\n",
      "Epoch [14/75], Step [500/941], Loss: 0.0060\n",
      "Epoch [15/75], Step [500/941], Loss: 0.0009\n",
      "Epoch [16/75], Step [500/941], Loss: 0.0033\n",
      "Epoch [17/75], Step [500/941], Loss: 0.0003\n",
      "Epoch [18/75], Step [500/941], Loss: 0.0009\n",
      "Epoch [19/75], Step [500/941], Loss: 0.0103\n",
      "Epoch [20/75], Step [500/941], Loss: 0.0001\n",
      "Epoch [21/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [22/75], Step [500/941], Loss: 0.0319\n",
      "Epoch [23/75], Step [500/941], Loss: 0.0006\n",
      "Epoch [24/75], Step [500/941], Loss: 0.0001\n",
      "Epoch [25/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [26/75], Step [500/941], Loss: 0.0001\n",
      "Epoch [27/75], Step [500/941], Loss: 0.0001\n",
      "Epoch [28/75], Step [500/941], Loss: 0.0001\n",
      "Epoch [29/75], Step [500/941], Loss: 0.0002\n",
      "Epoch [30/75], Step [500/941], Loss: 0.0001\n",
      "Epoch [31/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [32/75], Step [500/941], Loss: 0.0034\n",
      "Epoch [33/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [34/75], Step [500/941], Loss: 0.0047\n",
      "Epoch [35/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [36/75], Step [500/941], Loss: 0.0011\n",
      "Epoch [37/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [38/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [39/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [40/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [41/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [42/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [43/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [44/75], Step [500/941], Loss: 0.1773\n",
      "Epoch [45/75], Step [500/941], Loss: 0.0061\n",
      "Epoch [46/75], Step [500/941], Loss: 0.0001\n",
      "Epoch [47/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [48/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [49/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [50/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [51/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [52/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [53/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [54/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [55/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [56/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [57/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [58/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [59/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [60/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [61/75], Step [500/941], Loss: 0.0002\n",
      "Epoch [62/75], Step [500/941], Loss: 0.0006\n",
      "Epoch [63/75], Step [500/941], Loss: 0.0002\n",
      "Epoch [64/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [65/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [66/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [67/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [68/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [69/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [70/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [71/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [72/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [73/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [74/75], Step [500/941], Loss: 0.0000\n",
      "Epoch [75/75], Step [500/941], Loss: 0.0000\n",
      "Test accuracy of the network: 68.4044233807267 %\n",
      "Train accuracy of the network: 99.98006909380813 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15052, 4893)\n",
      "Epoch [1/100], Step [500/941], Loss: 0.4970\n",
      "Epoch [2/100], Step [500/941], Loss: 0.4629\n",
      "Epoch [3/100], Step [500/941], Loss: 0.1473\n",
      "Epoch [4/100], Step [500/941], Loss: 0.0734\n",
      "Epoch [5/100], Step [500/941], Loss: 0.4773\n",
      "Epoch [6/100], Step [500/941], Loss: 0.0117\n",
      "Epoch [7/100], Step [500/941], Loss: 0.0128\n",
      "Epoch [8/100], Step [500/941], Loss: 0.0339\n",
      "Epoch [9/100], Step [500/941], Loss: 0.0121\n",
      "Epoch [10/100], Step [500/941], Loss: 0.2970\n",
      "Epoch [11/100], Step [500/941], Loss: 0.0024\n",
      "Epoch [12/100], Step [500/941], Loss: 0.0047\n",
      "Epoch [13/100], Step [500/941], Loss: 0.0063\n",
      "Epoch [14/100], Step [500/941], Loss: 0.0060\n",
      "Epoch [15/100], Step [500/941], Loss: 0.0009\n",
      "Epoch [16/100], Step [500/941], Loss: 0.0033\n",
      "Epoch [17/100], Step [500/941], Loss: 0.0003\n",
      "Epoch [18/100], Step [500/941], Loss: 0.0009\n",
      "Epoch [19/100], Step [500/941], Loss: 0.0103\n",
      "Epoch [20/100], Step [500/941], Loss: 0.0001\n",
      "Epoch [21/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [22/100], Step [500/941], Loss: 0.0319\n",
      "Epoch [23/100], Step [500/941], Loss: 0.0006\n",
      "Epoch [24/100], Step [500/941], Loss: 0.0001\n",
      "Epoch [25/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [26/100], Step [500/941], Loss: 0.0001\n",
      "Epoch [27/100], Step [500/941], Loss: 0.0001\n",
      "Epoch [28/100], Step [500/941], Loss: 0.0001\n",
      "Epoch [29/100], Step [500/941], Loss: 0.0002\n",
      "Epoch [30/100], Step [500/941], Loss: 0.0001\n",
      "Epoch [31/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [32/100], Step [500/941], Loss: 0.0034\n",
      "Epoch [33/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [34/100], Step [500/941], Loss: 0.0047\n",
      "Epoch [35/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [36/100], Step [500/941], Loss: 0.0011\n",
      "Epoch [37/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [38/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [39/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [40/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [41/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [42/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [43/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [44/100], Step [500/941], Loss: 0.1773\n",
      "Epoch [45/100], Step [500/941], Loss: 0.0061\n",
      "Epoch [46/100], Step [500/941], Loss: 0.0001\n",
      "Epoch [47/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [48/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [49/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [50/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [51/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [52/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [53/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [54/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [55/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [56/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [57/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [58/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [59/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [60/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [61/100], Step [500/941], Loss: 0.0002\n",
      "Epoch [62/100], Step [500/941], Loss: 0.0006\n",
      "Epoch [63/100], Step [500/941], Loss: 0.0002\n",
      "Epoch [64/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [65/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [66/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [67/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [68/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [69/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [70/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [71/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [72/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [73/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [74/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [75/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [76/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [77/100], Step [500/941], Loss: 0.2411\n",
      "Epoch [78/100], Step [500/941], Loss: 0.0002\n",
      "Epoch [79/100], Step [500/941], Loss: 0.0001\n",
      "Epoch [80/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [81/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [82/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [83/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [84/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [85/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [86/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [87/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [88/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [89/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [90/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [91/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [92/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [93/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [94/100], Step [500/941], Loss: 0.0063\n",
      "Epoch [95/100], Step [500/941], Loss: 0.0039\n",
      "Epoch [96/100], Step [500/941], Loss: 0.0001\n",
      "Epoch [97/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [98/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [99/100], Step [500/941], Loss: 0.0000\n",
      "Epoch [100/100], Step [500/941], Loss: 0.0000\n",
      "Test accuracy of the network: 69.19431279620854 %\n",
      "Train accuracy of the network: 99.98006909380813 %\n"
     ]
    }
   ],
   "source": [
    "liar_test_accuracies2 = []\n",
    "liar_train_accuracies2 = []\n",
    "\n",
    "for num_epoch in num_epochs_used:\n",
    "    test_accuracy, train_accuracy = trainAndTestTwoHiddenLayerModel('liar', num_epochs=num_epoch, print_epoch_mod=500)\n",
    "    liar_test_accuracies2.append(test_accuracy)\n",
    "    liar_train_accuracies2.append(train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "ax.plot(num_epochs_used, liar_train_accuracies2, 'r-', lw=3, label='Train Accuracy')\n",
    "ax.plot(num_epochs_used, liar_test_accuracies2, 'g-', lw=3, label='Test Accuracy')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15212, 4975)\n",
      "Epoch [1/1], Step [500/951], Loss: 0.6391\n",
      "Test accuracy of the network: 79.88614800759014 %\n",
      "Train accuracy of the network: 77.55719169077044 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15212, 4975)\n",
      "Epoch [1/5], Step [500/951], Loss: 0.6391\n",
      "Epoch [2/5], Step [500/951], Loss: 0.5884\n",
      "Epoch [3/5], Step [500/951], Loss: 0.3055\n",
      "Epoch [4/5], Step [500/951], Loss: 0.2669\n",
      "Epoch [5/5], Step [500/951], Loss: 0.1727\n",
      "Test accuracy of the network: 84.44022770398482 %\n",
      "Train accuracy of the network: 83.8417039179595 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15212, 4975)\n",
      "Epoch [1/10], Step [500/951], Loss: 0.6391\n",
      "Epoch [2/10], Step [500/951], Loss: 0.5884\n",
      "Epoch [3/10], Step [500/951], Loss: 0.3055\n",
      "Epoch [4/10], Step [500/951], Loss: 0.2669\n",
      "Epoch [5/10], Step [500/951], Loss: 0.1727\n",
      "Epoch [6/10], Step [500/951], Loss: 0.0664\n",
      "Epoch [7/10], Step [500/951], Loss: 0.1533\n",
      "Epoch [8/10], Step [500/951], Loss: 0.0221\n",
      "Epoch [9/10], Step [500/951], Loss: 0.0766\n",
      "Epoch [10/10], Step [500/951], Loss: 0.0127\n",
      "Test accuracy of the network: 76.280834914611 %\n",
      "Train accuracy of the network: 91.80909808046279 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15212, 4975)\n",
      "Epoch [1/20], Step [500/951], Loss: 0.6391\n",
      "Epoch [2/20], Step [500/951], Loss: 0.5884\n",
      "Epoch [3/20], Step [500/951], Loss: 0.3055\n",
      "Epoch [4/20], Step [500/951], Loss: 0.2669\n",
      "Epoch [5/20], Step [500/951], Loss: 0.1727\n",
      "Epoch [6/20], Step [500/951], Loss: 0.0664\n",
      "Epoch [7/20], Step [500/951], Loss: 0.1533\n",
      "Epoch [8/20], Step [500/951], Loss: 0.0221\n",
      "Epoch [9/20], Step [500/951], Loss: 0.0766\n",
      "Epoch [10/20], Step [500/951], Loss: 0.0127\n",
      "Epoch [11/20], Step [500/951], Loss: 0.0515\n",
      "Epoch [12/20], Step [500/951], Loss: 0.0257\n",
      "Epoch [13/20], Step [500/951], Loss: 0.0005\n",
      "Epoch [14/20], Step [500/951], Loss: 0.0011\n",
      "Epoch [15/20], Step [500/951], Loss: 0.0039\n",
      "Epoch [16/20], Step [500/951], Loss: 0.0090\n",
      "Epoch [17/20], Step [500/951], Loss: 0.0027\n",
      "Epoch [18/20], Step [500/951], Loss: 0.0072\n",
      "Epoch [19/20], Step [500/951], Loss: 0.0042\n",
      "Epoch [20/20], Step [500/951], Loss: 0.0012\n",
      "Test accuracy of the network: 78.55787476280835 %\n",
      "Train accuracy of the network: 98.45516697344202 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15212, 4975)\n",
      "Epoch [1/30], Step [500/951], Loss: 0.6391\n",
      "Epoch [2/30], Step [500/951], Loss: 0.5884\n",
      "Epoch [3/30], Step [500/951], Loss: 0.3055\n",
      "Epoch [4/30], Step [500/951], Loss: 0.2669\n",
      "Epoch [5/30], Step [500/951], Loss: 0.1727\n",
      "Epoch [6/30], Step [500/951], Loss: 0.0664\n",
      "Epoch [7/30], Step [500/951], Loss: 0.1533\n",
      "Epoch [8/30], Step [500/951], Loss: 0.0221\n",
      "Epoch [9/30], Step [500/951], Loss: 0.0766\n",
      "Epoch [10/30], Step [500/951], Loss: 0.0127\n",
      "Epoch [11/30], Step [500/951], Loss: 0.0515\n",
      "Epoch [12/30], Step [500/951], Loss: 0.0257\n",
      "Epoch [13/30], Step [500/951], Loss: 0.0005\n",
      "Epoch [14/30], Step [500/951], Loss: 0.0011\n",
      "Epoch [15/30], Step [500/951], Loss: 0.0039\n",
      "Epoch [16/30], Step [500/951], Loss: 0.0090\n",
      "Epoch [17/30], Step [500/951], Loss: 0.0027\n",
      "Epoch [18/30], Step [500/951], Loss: 0.0072\n",
      "Epoch [19/30], Step [500/951], Loss: 0.0042\n",
      "Epoch [20/30], Step [500/951], Loss: 0.0012\n",
      "Epoch [21/30], Step [500/951], Loss: 0.0006\n",
      "Epoch [22/30], Step [500/951], Loss: 0.0001\n",
      "Epoch [23/30], Step [500/951], Loss: 0.0003\n",
      "Epoch [24/30], Step [500/951], Loss: 0.0002\n",
      "Epoch [25/30], Step [500/951], Loss: 0.0002\n",
      "Epoch [26/30], Step [500/951], Loss: 0.0002\n",
      "Epoch [27/30], Step [500/951], Loss: 0.0059\n",
      "Epoch [28/30], Step [500/951], Loss: 0.0008\n",
      "Epoch [29/30], Step [500/951], Loss: 0.0007\n",
      "Epoch [30/30], Step [500/951], Loss: 0.0006\n",
      "Test accuracy of the network: 83.49146110056925 %\n",
      "Train accuracy of the network: 98.43544570076256 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15212, 4975)\n",
      "Epoch [1/40], Step [500/951], Loss: 0.6391\n",
      "Epoch [2/40], Step [500/951], Loss: 0.5884\n",
      "Epoch [3/40], Step [500/951], Loss: 0.3055\n",
      "Epoch [4/40], Step [500/951], Loss: 0.2669\n",
      "Epoch [5/40], Step [500/951], Loss: 0.1727\n",
      "Epoch [6/40], Step [500/951], Loss: 0.0664\n",
      "Epoch [7/40], Step [500/951], Loss: 0.1533\n",
      "Epoch [8/40], Step [500/951], Loss: 0.0221\n",
      "Epoch [9/40], Step [500/951], Loss: 0.0766\n",
      "Epoch [10/40], Step [500/951], Loss: 0.0127\n",
      "Epoch [11/40], Step [500/951], Loss: 0.0515\n",
      "Epoch [12/40], Step [500/951], Loss: 0.0257\n",
      "Epoch [13/40], Step [500/951], Loss: 0.0005\n",
      "Epoch [14/40], Step [500/951], Loss: 0.0011\n",
      "Epoch [15/40], Step [500/951], Loss: 0.0039\n",
      "Epoch [16/40], Step [500/951], Loss: 0.0090\n",
      "Epoch [17/40], Step [500/951], Loss: 0.0027\n",
      "Epoch [18/40], Step [500/951], Loss: 0.0072\n",
      "Epoch [19/40], Step [500/951], Loss: 0.0042\n",
      "Epoch [20/40], Step [500/951], Loss: 0.0012\n",
      "Epoch [21/40], Step [500/951], Loss: 0.0006\n",
      "Epoch [22/40], Step [500/951], Loss: 0.0001\n",
      "Epoch [23/40], Step [500/951], Loss: 0.0003\n",
      "Epoch [24/40], Step [500/951], Loss: 0.0002\n",
      "Epoch [25/40], Step [500/951], Loss: 0.0002\n",
      "Epoch [26/40], Step [500/951], Loss: 0.0002\n",
      "Epoch [27/40], Step [500/951], Loss: 0.0059\n",
      "Epoch [28/40], Step [500/951], Loss: 0.0008\n",
      "Epoch [29/40], Step [500/951], Loss: 0.0007\n",
      "Epoch [30/40], Step [500/951], Loss: 0.0006\n",
      "Epoch [31/40], Step [500/951], Loss: 0.0002\n",
      "Epoch [32/40], Step [500/951], Loss: 0.0019\n",
      "Epoch [33/40], Step [500/951], Loss: 0.0002\n",
      "Epoch [34/40], Step [500/951], Loss: 0.0001\n",
      "Epoch [35/40], Step [500/951], Loss: 0.0000\n",
      "Epoch [36/40], Step [500/951], Loss: 0.0001\n",
      "Epoch [37/40], Step [500/951], Loss: 0.0002\n",
      "Epoch [38/40], Step [500/951], Loss: 0.0001\n",
      "Epoch [39/40], Step [500/951], Loss: 0.0003\n",
      "Epoch [40/40], Step [500/951], Loss: 0.0001\n",
      "Test accuracy of the network: 78.27324478178367 %\n",
      "Train accuracy of the network: 99.90139363660268 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15212, 4975)\n",
      "Epoch [1/50], Step [500/951], Loss: 0.6391\n",
      "Epoch [2/50], Step [500/951], Loss: 0.5884\n",
      "Epoch [3/50], Step [500/951], Loss: 0.3055\n",
      "Epoch [4/50], Step [500/951], Loss: 0.2669\n",
      "Epoch [5/50], Step [500/951], Loss: 0.1727\n",
      "Epoch [6/50], Step [500/951], Loss: 0.0664\n",
      "Epoch [7/50], Step [500/951], Loss: 0.1533\n",
      "Epoch [8/50], Step [500/951], Loss: 0.0221\n",
      "Epoch [9/50], Step [500/951], Loss: 0.0766\n",
      "Epoch [10/50], Step [500/951], Loss: 0.0127\n",
      "Epoch [11/50], Step [500/951], Loss: 0.0515\n",
      "Epoch [12/50], Step [500/951], Loss: 0.0257\n",
      "Epoch [13/50], Step [500/951], Loss: 0.0005\n",
      "Epoch [14/50], Step [500/951], Loss: 0.0011\n",
      "Epoch [15/50], Step [500/951], Loss: 0.0039\n",
      "Epoch [16/50], Step [500/951], Loss: 0.0090\n",
      "Epoch [17/50], Step [500/951], Loss: 0.0027\n",
      "Epoch [18/50], Step [500/951], Loss: 0.0072\n",
      "Epoch [19/50], Step [500/951], Loss: 0.0042\n",
      "Epoch [20/50], Step [500/951], Loss: 0.0012\n",
      "Epoch [21/50], Step [500/951], Loss: 0.0006\n",
      "Epoch [22/50], Step [500/951], Loss: 0.0001\n",
      "Epoch [23/50], Step [500/951], Loss: 0.0003\n",
      "Epoch [24/50], Step [500/951], Loss: 0.0002\n",
      "Epoch [25/50], Step [500/951], Loss: 0.0002\n",
      "Epoch [26/50], Step [500/951], Loss: 0.0002\n",
      "Epoch [27/50], Step [500/951], Loss: 0.0059\n",
      "Epoch [28/50], Step [500/951], Loss: 0.0008\n",
      "Epoch [29/50], Step [500/951], Loss: 0.0007\n",
      "Epoch [30/50], Step [500/951], Loss: 0.0006\n",
      "Epoch [31/50], Step [500/951], Loss: 0.0002\n",
      "Epoch [32/50], Step [500/951], Loss: 0.0019\n",
      "Epoch [33/50], Step [500/951], Loss: 0.0002\n",
      "Epoch [34/50], Step [500/951], Loss: 0.0001\n",
      "Epoch [35/50], Step [500/951], Loss: 0.0000\n",
      "Epoch [36/50], Step [500/951], Loss: 0.0001\n",
      "Epoch [37/50], Step [500/951], Loss: 0.0002\n",
      "Epoch [38/50], Step [500/951], Loss: 0.0001\n",
      "Epoch [39/50], Step [500/951], Loss: 0.0003\n",
      "Epoch [40/50], Step [500/951], Loss: 0.0001\n",
      "Epoch [41/50], Step [500/951], Loss: 0.0000\n",
      "Epoch [42/50], Step [500/951], Loss: 0.0000\n",
      "Epoch [43/50], Step [500/951], Loss: 0.0000\n",
      "Epoch [44/50], Step [500/951], Loss: 0.0000\n",
      "Epoch [45/50], Step [500/951], Loss: 0.0001\n",
      "Epoch [46/50], Step [500/951], Loss: 0.0176\n",
      "Epoch [47/50], Step [500/951], Loss: 0.0002\n",
      "Epoch [48/50], Step [500/951], Loss: 0.0010\n",
      "Epoch [49/50], Step [500/951], Loss: 0.0000\n",
      "Epoch [50/50], Step [500/951], Loss: 0.0005\n",
      "Test accuracy of the network: 79.60151802656546 %\n",
      "Train accuracy of the network: 100.0 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15212, 4975)\n",
      "Epoch [1/60], Step [500/951], Loss: 0.6391\n",
      "Epoch [2/60], Step [500/951], Loss: 0.5884\n",
      "Epoch [3/60], Step [500/951], Loss: 0.3055\n",
      "Epoch [4/60], Step [500/951], Loss: 0.2669\n",
      "Epoch [5/60], Step [500/951], Loss: 0.1727\n",
      "Epoch [6/60], Step [500/951], Loss: 0.0664\n",
      "Epoch [7/60], Step [500/951], Loss: 0.1533\n",
      "Epoch [8/60], Step [500/951], Loss: 0.0221\n",
      "Epoch [9/60], Step [500/951], Loss: 0.0766\n",
      "Epoch [10/60], Step [500/951], Loss: 0.0127\n",
      "Epoch [11/60], Step [500/951], Loss: 0.0515\n",
      "Epoch [12/60], Step [500/951], Loss: 0.0257\n",
      "Epoch [13/60], Step [500/951], Loss: 0.0005\n",
      "Epoch [14/60], Step [500/951], Loss: 0.0011\n",
      "Epoch [15/60], Step [500/951], Loss: 0.0039\n",
      "Epoch [16/60], Step [500/951], Loss: 0.0090\n",
      "Epoch [17/60], Step [500/951], Loss: 0.0027\n",
      "Epoch [18/60], Step [500/951], Loss: 0.0072\n",
      "Epoch [19/60], Step [500/951], Loss: 0.0042\n",
      "Epoch [20/60], Step [500/951], Loss: 0.0012\n",
      "Epoch [21/60], Step [500/951], Loss: 0.0006\n",
      "Epoch [22/60], Step [500/951], Loss: 0.0001\n",
      "Epoch [23/60], Step [500/951], Loss: 0.0003\n",
      "Epoch [24/60], Step [500/951], Loss: 0.0002\n",
      "Epoch [25/60], Step [500/951], Loss: 0.0002\n",
      "Epoch [26/60], Step [500/951], Loss: 0.0002\n",
      "Epoch [27/60], Step [500/951], Loss: 0.0059\n",
      "Epoch [28/60], Step [500/951], Loss: 0.0008\n",
      "Epoch [29/60], Step [500/951], Loss: 0.0007\n",
      "Epoch [30/60], Step [500/951], Loss: 0.0006\n",
      "Epoch [31/60], Step [500/951], Loss: 0.0002\n",
      "Epoch [32/60], Step [500/951], Loss: 0.0019\n",
      "Epoch [33/60], Step [500/951], Loss: 0.0002\n",
      "Epoch [34/60], Step [500/951], Loss: 0.0001\n",
      "Epoch [35/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [36/60], Step [500/951], Loss: 0.0001\n",
      "Epoch [37/60], Step [500/951], Loss: 0.0002\n",
      "Epoch [38/60], Step [500/951], Loss: 0.0001\n",
      "Epoch [39/60], Step [500/951], Loss: 0.0003\n",
      "Epoch [40/60], Step [500/951], Loss: 0.0001\n",
      "Epoch [41/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [42/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [43/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [44/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [45/60], Step [500/951], Loss: 0.0001\n",
      "Epoch [46/60], Step [500/951], Loss: 0.0176\n",
      "Epoch [47/60], Step [500/951], Loss: 0.0002\n",
      "Epoch [48/60], Step [500/951], Loss: 0.0010\n",
      "Epoch [49/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [50/60], Step [500/951], Loss: 0.0005\n",
      "Epoch [51/60], Step [500/951], Loss: 0.0001\n",
      "Epoch [52/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [53/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [54/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [55/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [56/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [57/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [58/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [59/60], Step [500/951], Loss: 0.0000\n",
      "Epoch [60/60], Step [500/951], Loss: 0.0000\n",
      "Test accuracy of the network: 80.83491461100569 %\n",
      "Train accuracy of the network: 100.0 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15212, 4975)\n",
      "Epoch [1/75], Step [500/951], Loss: 0.6391\n",
      "Epoch [2/75], Step [500/951], Loss: 0.5884\n",
      "Epoch [3/75], Step [500/951], Loss: 0.3055\n",
      "Epoch [4/75], Step [500/951], Loss: 0.2669\n",
      "Epoch [5/75], Step [500/951], Loss: 0.1727\n",
      "Epoch [6/75], Step [500/951], Loss: 0.0664\n",
      "Epoch [7/75], Step [500/951], Loss: 0.1533\n",
      "Epoch [8/75], Step [500/951], Loss: 0.0221\n",
      "Epoch [9/75], Step [500/951], Loss: 0.0766\n",
      "Epoch [10/75], Step [500/951], Loss: 0.0127\n",
      "Epoch [11/75], Step [500/951], Loss: 0.0515\n",
      "Epoch [12/75], Step [500/951], Loss: 0.0257\n",
      "Epoch [13/75], Step [500/951], Loss: 0.0005\n",
      "Epoch [14/75], Step [500/951], Loss: 0.0011\n",
      "Epoch [15/75], Step [500/951], Loss: 0.0039\n",
      "Epoch [16/75], Step [500/951], Loss: 0.0090\n",
      "Epoch [17/75], Step [500/951], Loss: 0.0027\n",
      "Epoch [18/75], Step [500/951], Loss: 0.0072\n",
      "Epoch [19/75], Step [500/951], Loss: 0.0042\n",
      "Epoch [20/75], Step [500/951], Loss: 0.0012\n",
      "Epoch [21/75], Step [500/951], Loss: 0.0006\n",
      "Epoch [22/75], Step [500/951], Loss: 0.0001\n",
      "Epoch [23/75], Step [500/951], Loss: 0.0003\n",
      "Epoch [24/75], Step [500/951], Loss: 0.0002\n",
      "Epoch [25/75], Step [500/951], Loss: 0.0002\n",
      "Epoch [26/75], Step [500/951], Loss: 0.0002\n",
      "Epoch [27/75], Step [500/951], Loss: 0.0059\n",
      "Epoch [28/75], Step [500/951], Loss: 0.0008\n",
      "Epoch [29/75], Step [500/951], Loss: 0.0007\n",
      "Epoch [30/75], Step [500/951], Loss: 0.0006\n",
      "Epoch [31/75], Step [500/951], Loss: 0.0002\n",
      "Epoch [32/75], Step [500/951], Loss: 0.0019\n",
      "Epoch [33/75], Step [500/951], Loss: 0.0002\n",
      "Epoch [34/75], Step [500/951], Loss: 0.0001\n",
      "Epoch [35/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [36/75], Step [500/951], Loss: 0.0001\n",
      "Epoch [37/75], Step [500/951], Loss: 0.0002\n",
      "Epoch [38/75], Step [500/951], Loss: 0.0001\n",
      "Epoch [39/75], Step [500/951], Loss: 0.0003\n",
      "Epoch [40/75], Step [500/951], Loss: 0.0001\n",
      "Epoch [41/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [42/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [43/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [44/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [45/75], Step [500/951], Loss: 0.0001\n",
      "Epoch [46/75], Step [500/951], Loss: 0.0176\n",
      "Epoch [47/75], Step [500/951], Loss: 0.0002\n",
      "Epoch [48/75], Step [500/951], Loss: 0.0010\n",
      "Epoch [49/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [50/75], Step [500/951], Loss: 0.0005\n",
      "Epoch [51/75], Step [500/951], Loss: 0.0001\n",
      "Epoch [52/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [53/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [54/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [55/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [56/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [57/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [58/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [59/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [60/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [61/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [62/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [63/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [64/75], Step [500/951], Loss: 0.0003\n",
      "Epoch [65/75], Step [500/951], Loss: 0.0005\n",
      "Epoch [66/75], Step [500/951], Loss: 0.0004\n",
      "Epoch [67/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [68/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [69/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [70/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [71/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [72/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [73/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [74/75], Step [500/951], Loss: 0.0000\n",
      "Epoch [75/75], Step [500/951], Loss: 0.0000\n",
      "Test accuracy of the network: 81.21442125237192 %\n",
      "Train accuracy of the network: 99.99342624244018 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (15212, 4975)\n",
      "Epoch [1/100], Step [500/951], Loss: 0.6391\n",
      "Epoch [2/100], Step [500/951], Loss: 0.5884\n",
      "Epoch [3/100], Step [500/951], Loss: 0.3055\n",
      "Epoch [4/100], Step [500/951], Loss: 0.2669\n",
      "Epoch [5/100], Step [500/951], Loss: 0.1727\n",
      "Epoch [6/100], Step [500/951], Loss: 0.0664\n",
      "Epoch [7/100], Step [500/951], Loss: 0.1533\n",
      "Epoch [8/100], Step [500/951], Loss: 0.0221\n",
      "Epoch [9/100], Step [500/951], Loss: 0.0766\n",
      "Epoch [10/100], Step [500/951], Loss: 0.0127\n",
      "Epoch [11/100], Step [500/951], Loss: 0.0515\n",
      "Epoch [12/100], Step [500/951], Loss: 0.0257\n",
      "Epoch [13/100], Step [500/951], Loss: 0.0005\n",
      "Epoch [14/100], Step [500/951], Loss: 0.0011\n",
      "Epoch [15/100], Step [500/951], Loss: 0.0039\n",
      "Epoch [16/100], Step [500/951], Loss: 0.0090\n",
      "Epoch [17/100], Step [500/951], Loss: 0.0027\n",
      "Epoch [18/100], Step [500/951], Loss: 0.0072\n",
      "Epoch [19/100], Step [500/951], Loss: 0.0042\n",
      "Epoch [20/100], Step [500/951], Loss: 0.0012\n",
      "Epoch [21/100], Step [500/951], Loss: 0.0006\n",
      "Epoch [22/100], Step [500/951], Loss: 0.0001\n",
      "Epoch [23/100], Step [500/951], Loss: 0.0003\n",
      "Epoch [24/100], Step [500/951], Loss: 0.0002\n",
      "Epoch [25/100], Step [500/951], Loss: 0.0002\n",
      "Epoch [26/100], Step [500/951], Loss: 0.0002\n",
      "Epoch [27/100], Step [500/951], Loss: 0.0059\n",
      "Epoch [28/100], Step [500/951], Loss: 0.0008\n",
      "Epoch [29/100], Step [500/951], Loss: 0.0007\n",
      "Epoch [30/100], Step [500/951], Loss: 0.0006\n",
      "Epoch [31/100], Step [500/951], Loss: 0.0002\n",
      "Epoch [32/100], Step [500/951], Loss: 0.0019\n",
      "Epoch [33/100], Step [500/951], Loss: 0.0002\n",
      "Epoch [34/100], Step [500/951], Loss: 0.0001\n",
      "Epoch [35/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [36/100], Step [500/951], Loss: 0.0001\n",
      "Epoch [37/100], Step [500/951], Loss: 0.0002\n",
      "Epoch [38/100], Step [500/951], Loss: 0.0001\n",
      "Epoch [39/100], Step [500/951], Loss: 0.0003\n",
      "Epoch [40/100], Step [500/951], Loss: 0.0001\n",
      "Epoch [41/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [42/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [43/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [44/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [45/100], Step [500/951], Loss: 0.0001\n",
      "Epoch [46/100], Step [500/951], Loss: 0.0176\n",
      "Epoch [47/100], Step [500/951], Loss: 0.0002\n",
      "Epoch [48/100], Step [500/951], Loss: 0.0010\n",
      "Epoch [49/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [50/100], Step [500/951], Loss: 0.0005\n",
      "Epoch [51/100], Step [500/951], Loss: 0.0001\n",
      "Epoch [52/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [53/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [54/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [55/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [56/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [57/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [58/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [59/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [60/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [61/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [62/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [63/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [64/100], Step [500/951], Loss: 0.0003\n",
      "Epoch [65/100], Step [500/951], Loss: 0.0005\n",
      "Epoch [66/100], Step [500/951], Loss: 0.0004\n",
      "Epoch [67/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [68/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [69/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [70/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [71/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [72/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [73/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [74/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [75/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [76/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [77/100], Step [500/951], Loss: 0.0341\n",
      "Epoch [78/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [79/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [80/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [81/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [82/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [83/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [84/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [85/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [86/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [87/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [88/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [89/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [90/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [91/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [92/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [93/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [94/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [95/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [96/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [97/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [98/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [99/100], Step [500/951], Loss: 0.0000\n",
      "Epoch [100/100], Step [500/951], Loss: 0.0000\n",
      "Test accuracy of the network: 78.17836812144212 %\n",
      "Train accuracy of the network: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "fnn_test_accuracies2 = []\n",
    "fnn_train_accuracies2 = []\n",
    "\n",
    "for num_epoch in num_epochs_used:\n",
    "    test_accuracy, train_accuracy = trainAndTestTwoHiddenLayerModel('fnn', num_epochs=num_epoch, print_epoch_mod=500)\n",
    "    fnn_test_accuracies2.append(test_accuracy)\n",
    "    fnn_train_accuracies2.append(train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "ax.plot(num_epochs_used, fnn_train_accuracies2, 'r-', lw=3, label='Train Accuracy')\n",
    "ax.plot(num_epochs_used, fnn_test_accuracies2, 'g-', lw=3, label='Test Accuracy')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
