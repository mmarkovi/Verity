{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../datasets/corona_fake.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b50272724af0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'../preprocessing/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcombineMultipleDatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgetAllText\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetAllVocabulary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetAllText2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0municode_literals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdivision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\CynSchool\\CS 175\\Verity\\preprocessing\\combineMultipleDatasets.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#nltk.download('stopwords')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcovidPreprocess\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgetCoronaVocabulary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetCoronaText\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_whole_Corona_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mliarPreprocess\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgetLiarVocabulary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetLiarText\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfnnPreprocess\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgetFNNVocabulary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetFNNText\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\CynSchool\\CS 175\\Verity\\preprocessing\\covidPreprocess.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m#nltk.download('stopwords')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mcoronafile\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../../datasets/corona_fake.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../datasets/corona_fake.csv'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import simplejson as json\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import * \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "from sklearn import linear_model \n",
    "from sklearn import metrics \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re \n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../preprocessing/')\n",
    "\n",
    "from combineMultipleDatasets import getAllText, getAllVocabulary, getAllText2\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_classification():\n",
    "    # should add comments defining what the inputs are what the function does\n",
    "    # function creates a logistic classifier that classifies whether a review is positive (1) or negative (0)\n",
    "    # X are the input variables, in this case, vectors that represent the text of Yelp reviews; X is a vector\n",
    "    # Y are the target variables associated with the input variables, here they represent whether a review from X is\n",
    "    # positive (1) or negative (0); Y is a vector (or a list representing a vector)\n",
    "    # test_fraction is the proportion of the dataset which is to be test data\n",
    "\n",
    "#     X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_fraction, random_state=42)\n",
    "    X_train, Y_train, vectorizerTrain = getAllText2(isTrain=True)\n",
    "    ### CUT DOWN TO HAVE SAME AMOUNT OF FEATURES AS X_TEST\n",
    "    X_train = X_train[:, :4519]\n",
    "    print(X_train.shape)\n",
    "    print(Y_train.shape)\n",
    "    X_test, Y_test, vectorizerTest = getAllText2(isTrain=False)\n",
    "    print(X_test.shape)\n",
    "    print(Y_test.shape)\n",
    "    #  set the state of the random number generator so that we get the same results across runs when testing our code\n",
    "\n",
    "    print('Number of training examples: ', X_train.shape[0])\n",
    "    print('Number of testing examples: ', X_test.shape[0])\n",
    "    print('Vocabulary size: ', X_train.shape[1])\n",
    "\n",
    "\n",
    "    # Specify the logistic classifier model with an l2 penalty for regularization and with fit_intercept turned on\n",
    "    classifier = linear_model.LogisticRegression(penalty='l2', fit_intercept=True)\n",
    "\n",
    "    # Train a logistic regression classifier and evaluate accuracy on the training data\n",
    "    print('\\nTraining a model with', X_train.shape[0], 'examples.....')\n",
    "    # fit classification model\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    train_predictions = classifier.predict(X_train)\n",
    "    train_accuracy = metrics.accuracy_score(Y_train, train_predictions)\n",
    "    print('\\nTraining:')\n",
    "    print(' accuracy:',format( 100*train_accuracy , '.2f') )\n",
    "\n",
    "    # Compute and print accuracy and AUC on the test data\n",
    "    print('\\nTesting: ')\n",
    "    test_predictions = classifier.predict(X_test)\n",
    "    test_accuracy = metrics.accuracy_score(Y_test, test_predictions)\n",
    "    print(' accuracy:', format( 100*test_accuracy , '.2f') )\n",
    "\n",
    "    # get class_probabilities for class 1\n",
    "    class_probabilities = classifier.predict_proba(X_test)[:, 1]\n",
    "    test_auc_score = metrics.roc_auc_score(Y_test, class_probabilities)\n",
    "    print(' AUC value:', format( 100*test_auc_score , '.2f') )\n",
    "\n",
    "    return(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "(30555, 4519)\n",
      "(30555,)\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "(3193, 4519)\n",
      "(3193,)\n",
      "Number of training examples:  30555\n",
      "Number of testing examples:  3193\n",
      "Vocabulary size:  4519\n",
      "\n",
      "Training a model with 30555 examples.....\n",
      "\n",
      "Training:\n",
      " accuracy: 100.00\n",
      "\n",
      "Testing: \n",
      " accuracy: 78.33\n",
      " AUC value: 69.41\n"
     ]
    }
   ],
   "source": [
    "logistic_classifier = logistic_classification() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGeneralNeuralNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        #Written based off of the tutorial at\n",
    "        #https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/01-basics/feedforward_neural_network/main.py#L37-L49\n",
    "        self.hidden1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()   \n",
    "        self.hOutput1 = nn.Linear(hidden_size, num_classes)  \n",
    "        self.softmax = nn.Softmax(dim = 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.hidden1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.hOutput1(out)\n",
    "#         out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainSimpleModel(num_epochs = 5, learning_rate = 0.001, print_epoch_mod = 5):\n",
    "    '''\n",
    "    gets around 63-71% for corona and Liar datasets, around 80-83% on FNN\n",
    "    \n",
    "    used this article for help in writing the tensor parts of code so it works with the model\n",
    "    https://medium.com/analytics-vidhya/part-1-sentiment-analysis-in-pytorch-82b35edb40b8\n",
    "    '''\n",
    "    DEBUG_MODE = False\n",
    "\n",
    "    torch.manual_seed(1)\n",
    "#     if dataset == 'corona':\n",
    "#         X,Y = getCoronaText() #this function will give us the text array (not document term matrix) and Y\n",
    "#         X_train,Y_train, vectorizer_train = getCoronaVocabulary(True)\n",
    "#     elif dataset == 'liar':\n",
    "#         X,Y = getLiarText()\n",
    "#         X_train,Y_train, vectorizer_train = getLiarVocabulary(True)\n",
    "#     elif dataset == 'fnn':\n",
    "#         X,Y = getFNNText()\n",
    "#         X_train,Y_train, vectorizer_train = getFNNVocabulary(True)\n",
    "\n",
    "    X, Y, vectorizer_test = getAllText()\n",
    "    X_train, Y_train, vectorizer_train = getAllVocabulary(True)\n",
    "    \n",
    "    #transform our testing dataset to match the vocabulary for the training dataset\n",
    "    #transform will return the document-term matrix for X based on training dataset\n",
    "    x_test = vectorizer_train.transform(X)\n",
    "    \n",
    "    #sample test on logistic classifier\n",
    "    '''classifier = LogisticRegression()\n",
    "    classifier.fit(X_train,Y_train)\n",
    "    score = classifier.score(x_test,Y)\n",
    "    print(score)'''\n",
    "    \n",
    "    vocabsize = X_train.shape[1]\n",
    "    \n",
    "    \n",
    "    # transform our training and test data into tensors for the classifier to learn off of\n",
    "    X_tensor = torch.from_numpy(X_train.todense()).float()\n",
    "    Y_tensor = torch.from_numpy(np.array(Y_train))\n",
    "    \n",
    "    X_test_tensor = torch.from_numpy(x_test.todense()).float()\n",
    "    Y_test_tensor = torch.from_numpy(np.array(Y))\n",
    "    \n",
    "    device = torch.device(\"cpu\")\n",
    "    # use TensorDataset to be able to use our DataLoader\n",
    "    train_data = torch.utils.data.TensorDataset(X_tensor, Y_tensor)\n",
    "    # train_loader = torch.utils.data.DataLoader(train_data,batch_size=16, shuffle=True)\n",
    "    train_loader = torch.utils.data.DataLoader(train_data,batch_size=16, shuffle=False)\n",
    "    \n",
    "    test_data = torch.utils.data.TensorDataset(X_test_tensor, Y_test_tensor)\n",
    "    # test_loader = torch.utils.data.DataLoader(test_data,batch_size=16, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data,batch_size=16, shuffle=False)\n",
    "    \n",
    "    #initialize our model\n",
    "    model = SimpleGeneralNeuralNet(vocabsize, 200, 2).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "    \n",
    "    \n",
    "    total_step = len(train_loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (x_batch, labels) in enumerate(train_loader):\n",
    "    \n",
    "            # Forward pass\n",
    "            # The forward process computes the loss of each iteration on each sample\n",
    "            model.train()\n",
    "            y_pred = model(x_batch)\n",
    "            #need to transform labels to long datatype using .long() or it complains it's an int\n",
    "            loss = criterion(y_pred, labels.long())\n",
    "    \n",
    "            # Backward pass, using the optimizer to update the parameters\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()    #compute gradients\n",
    "            optimizer.step()   #initiate gradient descent\n",
    "    \n",
    "     \n",
    "            # Below, an epoch corresponds to one pass through all of the samples.\n",
    "            # Each training step corresponds to a parameter update using \n",
    "            # a gradient computed on a minibatch of 100 samples\n",
    "            if DEBUG_MODE:\n",
    "                if (i + 1) % print_epoch_mod == 0: \n",
    "                    # leaving it on 5 for corona dataset, probably want to change to % 50 or % 100\n",
    "                    # for the other datasets so don't get spammed \n",
    "                    print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                        .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "    \n",
    "    # Test the model\n",
    "    # In the test phase, we don't need to compute gradients (the model has already been learned)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        print('Test accuracy of the network: {} %'.format(100 * correct / total))\n",
    "        test_accuracy = 100 * correct / total\n",
    "        \n",
    "    # Print out training accuracy\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in train_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        print('Train accuracy of the network: {} %'.format(100 * correct / total))\n",
    "        train_accuracy = 100 * correct / total\n",
    "\n",
    "#     return train_loader, test_loader, model\n",
    "    return test_accuracy, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (30555, 4932)\n",
      "Test accuracy of the network: 90.72972126526777 %\n",
      "Train accuracy of the network: 99.77745049909998 %\n"
     ]
    }
   ],
   "source": [
    "test_accuracy, train_accuracy = trainSimpleModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs_used = [5, 10, 20, 30, 40, 50, 60, 75, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (30555, 4932)\n",
      "Test accuracy of the network: 90.72972126526777 %\n",
      "Train accuracy of the network: 99.77745049909998 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (30555, 4932)\n",
      "Test accuracy of the network: 95.02035703100532 %\n",
      "Train accuracy of the network: 99.99345442644412 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (30555, 4932)\n",
      "Test accuracy of the network: 97.99561540870654 %\n",
      "Train accuracy of the network: 100.0 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (30555, 4932)\n",
      "Test accuracy of the network: 98.12088944566239 %\n",
      "Train accuracy of the network: 100.0 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (30555, 4932)\n",
      "Test accuracy of the network: 98.12088944566239 %\n",
      "Train accuracy of the network: 100.0 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (30555, 4932)\n",
      "Test accuracy of the network: 98.12088944566239 %\n",
      "Train accuracy of the network: 100.0 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (30555, 4932)\n",
      "Test accuracy of the network: 98.12088944566239 %\n",
      "Train accuracy of the network: 100.0 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (30555, 4932)\n",
      "Test accuracy of the network: 98.12088944566239 %\n",
      "Train accuracy of the network: 100.0 %\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "\n",
      "Extracting tokens....\n",
      "Data shape for text:  (30555, 4932)\n",
      "Test accuracy of the network: 98.12088944566239 %\n",
      "Train accuracy of the network: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "test_accuracies = []\n",
    "train_accuracies = []\n",
    "\n",
    "for num_epoch in num_epochs_used:\n",
    "    test_accuracy, train_accuracy = trainSimpleModel(num_epochs=num_epoch)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    train_accuracies.append(train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "ax.plot(num_epochs_used, train_accuracies, 'r-', lw=3, label='Train Accuracy')\n",
    "ax.plot(num_epochs_used, test_accuracies, 'g-', lw=3, label='Test Accuracy')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
